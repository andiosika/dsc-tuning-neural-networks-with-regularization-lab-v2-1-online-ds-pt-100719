{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll use a train-test partition as well as a validation set to get better insights about how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Apply early stopping criteria with a neural network \n",
    "- Apply L1, L2, and dropout regularization on a neural network  \n",
    "- Examine the effects of training with more data on a neural network  \n",
    "\n",
    "\n",
    "## Load the Data\n",
    "\n",
    "Run the following cell to import some of the libraries and classes you'll need in this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in the file `'Bank_complaints.csv'`. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preview the dataset\n",
    "df = pd.read_csv('Bank_complaints.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools such as regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* Train - test split\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels \n",
    "\n",
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training neural networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your model's performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "- Generate a random sample of 10,000 observations using seed 123 for consistency of results. \n",
    "- Split this sample into `X` and `y` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p...\n",
       "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3  Student loan  Navient has sytematically and illegally failed...\n",
       "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the data\n",
    "df_sample = df.sample(1000, random_state=123)\n",
    "\n",
    "# Split the data into X and y\n",
    "y = df['Product']\n",
    "X = df['Consumer complaint narrative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "- Split the data into training and test sets \n",
    "- Assign 1500 obervations to the test set and use 42 as the seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1500, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set \n",
    "\n",
    "As mentioned in the previous lesson, it is good practice to set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test set can then be used to determine an unbiased perforance of the model. \n",
    "\n",
    "Run the cell below to further divide the training data into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing before building a neural network model. \n",
    "\n",
    "- Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "- Transform the training, validate, and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "# Only keep the 2000 most common words \n",
    "\n",
    "tokenizer = Tokenizer(num_words=2000) \n",
    "tokenizer.fit_on_texts(X_train_final)\n",
    "\n",
    "X_train_tokens = tokenizer.texts_to_matrix(X_train_final, mode='binary')\n",
    "X_val_tokens = tokenizer.texts_to_matrix(X_val, mode='binary')\n",
    "X_test_tokens = tokenizer.texts_to_matrix(X_test, mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero. \n",
    "\n",
    "Transform the training, validate, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57500,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49369                   Mortgage\n",
       "666                 Student loan\n",
       "21394    Bank account or service\n",
       "2291                Student loan\n",
       "13262                Credit card\n",
       "                  ...           \n",
       "28669    Bank account or service\n",
       "56614           Credit reporting\n",
       "23180    Bank account or service\n",
       "9289                Student loan\n",
       "22534    Bank account or service\n",
       "Name: Product, Length: 57500, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = to_categorical(lb.transform(y_train_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57500, 7, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 0., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 0.],\n",
       "       [0., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 0.],\n",
       "       [0., 1., 1., ..., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the product labels to numerical values\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final)\n",
    "\n",
    "y_train_lb = to_categorical(lb.transform(y_train_final))[:, :, 1]\n",
    "y_val_lb = to_categorical(lb.transform(y_val))[:, :, 1]\n",
    "y_test_lb = to_categorical(lb.transform(y_test))[:, :, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Baseline Model \n",
    "\n",
    "Rebuild a fully connected (Dense) layer network:  \n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions (since you are dealing with a multiclass problem, classifying the complaints into 7 classes) \n",
    "- Use a `'softmax'` activation function for the output layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a baseline neural network model using Keras\n",
    "random.seed(123)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "baseline_model = models.Sequential()\n",
    "\n",
    "# Two layers with relu activation\n",
    "baseline_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "baseline_model.add(layers.Dense(25, activation='relu'))\n",
    "\n",
    "# One layer with softmax activation \n",
    "baseline_model.add(layers.Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model\n",
    "\n",
    "Compile this model with: \n",
    "\n",
    "- a stochastic gradient descent optimizer \n",
    "- `'categorical_crossentropy'` as the loss function \n",
    "- a focus on `'accuracy'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "baseline_model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "- Train the model for 150 epochs in mini-batches of 256 samples \n",
    "- Include the `validation_data` argument to ensure you keep track of the validation loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 1.8541 - accuracy: 0.2629 - val_loss: 1.7119 - val_accuracy: 0.3910\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 1.5228 - accuracy: 0.4894 - val_loss: 1.3462 - val_accuracy: 0.5540\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 1.1882 - accuracy: 0.6195 - val_loss: 1.0641 - val_accuracy: 0.6400\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.9648 - accuracy: 0.6784 - val_loss: 0.8935 - val_accuracy: 0.6910\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.8348 - accuracy: 0.7108 - val_loss: 0.8034 - val_accuracy: 0.7080\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.7560 - accuracy: 0.7320 - val_loss: 0.7432 - val_accuracy: 0.7110\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.7037 - accuracy: 0.7478 - val_loss: 0.7047 - val_accuracy: 0.7290\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.6664 - accuracy: 0.7601 - val_loss: 0.6784 - val_accuracy: 0.7420\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.6380 - accuracy: 0.7690 - val_loss: 0.6600 - val_accuracy: 0.7490\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6157 - accuracy: 0.7765 - val_loss: 0.6457 - val_accuracy: 0.7550\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5972 - accuracy: 0.7831 - val_loss: 0.6255 - val_accuracy: 0.7740\n",
      "Epoch 12/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.5815 - accuracy: 0.7888 - val_loss: 0.6160 - val_accuracy: 0.7720\n",
      "Epoch 13/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.5680 - accuracy: 0.7941 - val_loss: 0.6055 - val_accuracy: 0.7780\n",
      "Epoch 14/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.5562 - accuracy: 0.7992 - val_loss: 0.5959 - val_accuracy: 0.7800\n",
      "Epoch 15/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.5456 - accuracy: 0.8024 - val_loss: 0.5971 - val_accuracy: 0.7760\n",
      "Epoch 16/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.5359 - accuracy: 0.8065 - val_loss: 0.5862 - val_accuracy: 0.7800\n",
      "Epoch 17/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.5273 - accuracy: 0.8097 - val_loss: 0.5813 - val_accuracy: 0.7880\n",
      "Epoch 18/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.5194 - accuracy: 0.8129 - val_loss: 0.5825 - val_accuracy: 0.7860\n",
      "Epoch 19/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.5120 - accuracy: 0.8161 - val_loss: 0.5779 - val_accuracy: 0.7880\n",
      "Epoch 20/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.5053 - accuracy: 0.8186 - val_loss: 0.5694 - val_accuracy: 0.7930\n",
      "Epoch 21/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.4992 - accuracy: 0.8215 - val_loss: 0.5708 - val_accuracy: 0.7910\n",
      "Epoch 22/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.4933 - accuracy: 0.8236 - val_loss: 0.5700 - val_accuracy: 0.7930\n",
      "Epoch 23/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.4877 - accuracy: 0.8256 - val_loss: 0.5647 - val_accuracy: 0.8020\n",
      "Epoch 24/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.4824 - accuracy: 0.8283 - val_loss: 0.5622 - val_accuracy: 0.8020\n",
      "Epoch 25/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.4776 - accuracy: 0.8289 - val_loss: 0.5624 - val_accuracy: 0.8010\n",
      "Epoch 26/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.4730 - accuracy: 0.8314 - val_loss: 0.5649 - val_accuracy: 0.8000\n",
      "Epoch 27/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.4687 - accuracy: 0.8323 - val_loss: 0.5564 - val_accuracy: 0.8010\n",
      "Epoch 28/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.4647 - accuracy: 0.8348 - val_loss: 0.5569 - val_accuracy: 0.8090\n",
      "Epoch 29/150\n",
      "57500/57500 [==============================] - 3s 51us/step - loss: 0.4607 - accuracy: 0.8354 - val_loss: 0.5567 - val_accuracy: 0.8080\n",
      "Epoch 30/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.4569 - accuracy: 0.8366 - val_loss: 0.5624 - val_accuracy: 0.8050\n",
      "Epoch 31/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.4532 - accuracy: 0.8386 - val_loss: 0.5576 - val_accuracy: 0.8100\n",
      "Epoch 32/150\n",
      "57500/57500 [==============================] - 3s 50us/step - loss: 0.4497 - accuracy: 0.8395 - val_loss: 0.5574 - val_accuracy: 0.8060\n",
      "Epoch 33/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.4464 - accuracy: 0.8410 - val_loss: 0.5664 - val_accuracy: 0.8010\n",
      "Epoch 34/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.4435 - accuracy: 0.8420 - val_loss: 0.5561 - val_accuracy: 0.8110\n",
      "Epoch 35/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.4402 - accuracy: 0.8431 - val_loss: 0.5561 - val_accuracy: 0.8020\n",
      "Epoch 36/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.4373 - accuracy: 0.8440 - val_loss: 0.5569 - val_accuracy: 0.8070\n",
      "Epoch 37/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.4346 - accuracy: 0.8456 - val_loss: 0.5545 - val_accuracy: 0.8050\n",
      "Epoch 38/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.4318 - accuracy: 0.8466 - val_loss: 0.5566 - val_accuracy: 0.8070\n",
      "Epoch 39/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.4292 - accuracy: 0.8472 - val_loss: 0.5569 - val_accuracy: 0.8070\n",
      "Epoch 40/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.4266 - accuracy: 0.8485 - val_loss: 0.5541 - val_accuracy: 0.8120\n",
      "Epoch 41/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.4242 - accuracy: 0.8491 - val_loss: 0.5555 - val_accuracy: 0.8060\n",
      "Epoch 42/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.4217 - accuracy: 0.8508 - val_loss: 0.5541 - val_accuracy: 0.8090\n",
      "Epoch 43/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.4194 - accuracy: 0.8511 - val_loss: 0.5520 - val_accuracy: 0.8090\n",
      "Epoch 44/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.4172 - accuracy: 0.8524 - val_loss: 0.5583 - val_accuracy: 0.8070\n",
      "Epoch 45/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.4154 - accuracy: 0.8529 - val_loss: 0.5533 - val_accuracy: 0.8020\n",
      "Epoch 46/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.4129 - accuracy: 0.8536 - val_loss: 0.5583 - val_accuracy: 0.8020\n",
      "Epoch 47/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.4107 - accuracy: 0.8547 - val_loss: 0.5592 - val_accuracy: 0.8070\n",
      "Epoch 48/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.4091 - accuracy: 0.8552 - val_loss: 0.5532 - val_accuracy: 0.8100\n",
      "Epoch 49/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.4069 - accuracy: 0.8557 - val_loss: 0.5564 - val_accuracy: 0.8090\n",
      "Epoch 50/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.4050 - accuracy: 0.8563 - val_loss: 0.5573 - val_accuracy: 0.8060\n",
      "Epoch 51/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.4033 - accuracy: 0.8568 - val_loss: 0.5572 - val_accuracy: 0.8020\n",
      "Epoch 52/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.4014 - accuracy: 0.8582 - val_loss: 0.5538 - val_accuracy: 0.8080\n",
      "Epoch 53/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3995 - accuracy: 0.8588 - val_loss: 0.5548 - val_accuracy: 0.8150\n",
      "Epoch 54/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3982 - accuracy: 0.8586 - val_loss: 0.5581 - val_accuracy: 0.8100\n",
      "Epoch 55/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3965 - accuracy: 0.8593 - val_loss: 0.5559 - val_accuracy: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150\n",
      "57500/57500 [==============================] - 3s 50us/step - loss: 0.3948 - accuracy: 0.8602 - val_loss: 0.5617 - val_accuracy: 0.8110\n",
      "Epoch 57/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.3931 - accuracy: 0.8608 - val_loss: 0.5543 - val_accuracy: 0.8100\n",
      "Epoch 58/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3917 - accuracy: 0.8617 - val_loss: 0.5681 - val_accuracy: 0.7980\n",
      "Epoch 59/150\n",
      "57500/57500 [==============================] - 3s 54us/step - loss: 0.3899 - accuracy: 0.8617 - val_loss: 0.5600 - val_accuracy: 0.8080\n",
      "Epoch 60/150\n",
      "57500/57500 [==============================] - 3s 55us/step - loss: 0.3883 - accuracy: 0.8626 - val_loss: 0.5673 - val_accuracy: 0.8070\n",
      "Epoch 61/150\n",
      "57500/57500 [==============================] - 3s 51us/step - loss: 0.3870 - accuracy: 0.8635 - val_loss: 0.5594 - val_accuracy: 0.8070\n",
      "Epoch 62/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3853 - accuracy: 0.8633 - val_loss: 0.5630 - val_accuracy: 0.8070\n",
      "Epoch 63/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.3844 - accuracy: 0.8641 - val_loss: 0.5593 - val_accuracy: 0.8130\n",
      "Epoch 64/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.3825 - accuracy: 0.8646 - val_loss: 0.5613 - val_accuracy: 0.8080\n",
      "Epoch 65/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.3813 - accuracy: 0.8642 - val_loss: 0.5635 - val_accuracy: 0.8090\n",
      "Epoch 66/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.3800 - accuracy: 0.8663 - val_loss: 0.5675 - val_accuracy: 0.8100\n",
      "Epoch 67/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3787 - accuracy: 0.8662 - val_loss: 0.5658 - val_accuracy: 0.8060\n",
      "Epoch 68/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3778 - accuracy: 0.8658 - val_loss: 0.5666 - val_accuracy: 0.8040\n",
      "Epoch 69/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.3763 - accuracy: 0.8663 - val_loss: 0.5652 - val_accuracy: 0.8050\n",
      "Epoch 70/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3750 - accuracy: 0.8681 - val_loss: 0.5680 - val_accuracy: 0.8130\n",
      "Epoch 71/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3737 - accuracy: 0.8673 - val_loss: 0.5649 - val_accuracy: 0.8060\n",
      "Epoch 72/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3725 - accuracy: 0.8676 - val_loss: 0.5684 - val_accuracy: 0.8100\n",
      "Epoch 73/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.3713 - accuracy: 0.8687 - val_loss: 0.5670 - val_accuracy: 0.8070\n",
      "Epoch 74/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.3703 - accuracy: 0.8693 - val_loss: 0.5676 - val_accuracy: 0.8060\n",
      "Epoch 75/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.3689 - accuracy: 0.8692 - val_loss: 0.5737 - val_accuracy: 0.8070\n",
      "Epoch 76/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3680 - accuracy: 0.8699 - val_loss: 0.5735 - val_accuracy: 0.8020\n",
      "Epoch 77/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3668 - accuracy: 0.8702 - val_loss: 0.5687 - val_accuracy: 0.8050\n",
      "Epoch 78/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3658 - accuracy: 0.8700 - val_loss: 0.5812 - val_accuracy: 0.8020\n",
      "Epoch 79/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3644 - accuracy: 0.8706 - val_loss: 0.5717 - val_accuracy: 0.8070\n",
      "Epoch 80/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3636 - accuracy: 0.8714 - val_loss: 0.5717 - val_accuracy: 0.8020\n",
      "Epoch 81/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3624 - accuracy: 0.8715 - val_loss: 0.5709 - val_accuracy: 0.8020\n",
      "Epoch 82/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3616 - accuracy: 0.8715 - val_loss: 0.5750 - val_accuracy: 0.8050\n",
      "Epoch 83/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3604 - accuracy: 0.8723 - val_loss: 0.5729 - val_accuracy: 0.8070\n",
      "Epoch 84/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3596 - accuracy: 0.8736 - val_loss: 0.5841 - val_accuracy: 0.8040\n",
      "Epoch 85/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.3588 - accuracy: 0.8724 - val_loss: 0.5774 - val_accuracy: 0.8020\n",
      "Epoch 86/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.3575 - accuracy: 0.8740 - val_loss: 0.5769 - val_accuracy: 0.8050\n",
      "Epoch 87/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3566 - accuracy: 0.8735 - val_loss: 0.5741 - val_accuracy: 0.8040\n",
      "Epoch 88/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.3554 - accuracy: 0.8731 - val_loss: 0.5840 - val_accuracy: 0.8040\n",
      "Epoch 89/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3548 - accuracy: 0.8744 - val_loss: 0.5787 - val_accuracy: 0.8010\n",
      "Epoch 90/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3538 - accuracy: 0.8742 - val_loss: 0.5803 - val_accuracy: 0.8000\n",
      "Epoch 91/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.3527 - accuracy: 0.8753 - val_loss: 0.5774 - val_accuracy: 0.8030\n",
      "Epoch 92/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3515 - accuracy: 0.8754 - val_loss: 0.5780 - val_accuracy: 0.8000\n",
      "Epoch 93/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3508 - accuracy: 0.8764 - val_loss: 0.5811 - val_accuracy: 0.8010\n",
      "Epoch 94/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3499 - accuracy: 0.8763 - val_loss: 0.5907 - val_accuracy: 0.8070\n",
      "Epoch 95/150\n",
      "57500/57500 [==============================] - ETA: 0s - loss: 0.3490 - accuracy: 0.87 - 2s 33us/step - loss: 0.3493 - accuracy: 0.8762 - val_loss: 0.5839 - val_accuracy: 0.8000\n",
      "Epoch 96/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3480 - accuracy: 0.8766 - val_loss: 0.5812 - val_accuracy: 0.8030\n",
      "Epoch 97/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3472 - accuracy: 0.8775 - val_loss: 0.5852 - val_accuracy: 0.8000\n",
      "Epoch 98/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3463 - accuracy: 0.8777 - val_loss: 0.5906 - val_accuracy: 0.8010\n",
      "Epoch 99/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3457 - accuracy: 0.8777 - val_loss: 0.5843 - val_accuracy: 0.8000\n",
      "Epoch 100/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3446 - accuracy: 0.8780 - val_loss: 0.5874 - val_accuracy: 0.8000\n",
      "Epoch 101/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3438 - accuracy: 0.8786 - val_loss: 0.5966 - val_accuracy: 0.8040\n",
      "Epoch 102/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3432 - accuracy: 0.8779 - val_loss: 0.5952 - val_accuracy: 0.7990\n",
      "Epoch 103/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3419 - accuracy: 0.8784 - val_loss: 0.5870 - val_accuracy: 0.7980\n",
      "Epoch 104/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3410 - accuracy: 0.8795 - val_loss: 0.5917 - val_accuracy: 0.7990\n",
      "Epoch 105/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3402 - accuracy: 0.8796 - val_loss: 0.5937 - val_accuracy: 0.8000\n",
      "Epoch 106/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3398 - accuracy: 0.8804 - val_loss: 0.5997 - val_accuracy: 0.8050\n",
      "Epoch 107/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.3386 - accuracy: 0.8793 - val_loss: 0.5901 - val_accuracy: 0.8010\n",
      "Epoch 108/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3380 - accuracy: 0.8805 - val_loss: 0.5962 - val_accuracy: 0.7970\n",
      "Epoch 109/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3369 - accuracy: 0.8807 - val_loss: 0.5912 - val_accuracy: 0.7950\n",
      "Epoch 110/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.3362 - accuracy: 0.8813 - val_loss: 0.5955 - val_accuracy: 0.7980\n",
      "Epoch 111/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3354 - accuracy: 0.8812 - val_loss: 0.6035 - val_accuracy: 0.7990\n",
      "Epoch 112/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3344 - accuracy: 0.8819 - val_loss: 0.5942 - val_accuracy: 0.7950\n",
      "Epoch 113/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3335 - accuracy: 0.8819 - val_loss: 0.5974 - val_accuracy: 0.7970\n",
      "Epoch 114/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3330 - accuracy: 0.8823 - val_loss: 0.5965 - val_accuracy: 0.7930\n",
      "Epoch 115/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3318 - accuracy: 0.8833 - val_loss: 0.5965 - val_accuracy: 0.7940\n",
      "Epoch 116/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3314 - accuracy: 0.8830 - val_loss: 0.5971 - val_accuracy: 0.7960\n",
      "Epoch 117/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3299 - accuracy: 0.8831 - val_loss: 0.6038 - val_accuracy: 0.7990\n",
      "Epoch 118/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.3294 - accuracy: 0.8837 - val_loss: 0.5999 - val_accuracy: 0.7970\n",
      "Epoch 119/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3289 - accuracy: 0.8836 - val_loss: 0.5997 - val_accuracy: 0.7960\n",
      "Epoch 120/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3279 - accuracy: 0.8846 - val_loss: 0.6078 - val_accuracy: 0.7960\n",
      "Epoch 121/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.3271 - accuracy: 0.8849 - val_loss: 0.6072 - val_accuracy: 0.7990\n",
      "Epoch 122/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.3260 - accuracy: 0.8849 - val_loss: 0.6029 - val_accuracy: 0.7940\n",
      "Epoch 123/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3256 - accuracy: 0.8847 - val_loss: 0.6223 - val_accuracy: 0.8030\n",
      "Epoch 124/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3245 - accuracy: 0.8861 - val_loss: 0.6075 - val_accuracy: 0.7950\n",
      "Epoch 125/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3240 - accuracy: 0.8856 - val_loss: 0.6109 - val_accuracy: 0.7940\n",
      "Epoch 126/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3229 - accuracy: 0.8865 - val_loss: 0.6051 - val_accuracy: 0.7870\n",
      "Epoch 127/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3222 - accuracy: 0.8869 - val_loss: 0.6125 - val_accuracy: 0.7930\n",
      "Epoch 128/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3211 - accuracy: 0.8874 - val_loss: 0.6130 - val_accuracy: 0.7930\n",
      "Epoch 129/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.3205 - accuracy: 0.8872 - val_loss: 0.6115 - val_accuracy: 0.7880\n",
      "Epoch 130/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3195 - accuracy: 0.8878 - val_loss: 0.6113 - val_accuracy: 0.7930\n",
      "Epoch 131/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.3189 - accuracy: 0.8879 - val_loss: 0.6170 - val_accuracy: 0.7920\n",
      "Epoch 132/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.3179 - accuracy: 0.8885 - val_loss: 0.6280 - val_accuracy: 0.7940\n",
      "Epoch 133/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.3173 - accuracy: 0.8885 - val_loss: 0.6173 - val_accuracy: 0.7920\n",
      "Epoch 134/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.3164 - accuracy: 0.8887 - val_loss: 0.6154 - val_accuracy: 0.7960\n",
      "Epoch 135/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3154 - accuracy: 0.8901 - val_loss: 0.6196 - val_accuracy: 0.7910\n",
      "Epoch 136/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3146 - accuracy: 0.8894 - val_loss: 0.6182 - val_accuracy: 0.7880\n",
      "Epoch 137/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3139 - accuracy: 0.8898 - val_loss: 0.6190 - val_accuracy: 0.7870\n",
      "Epoch 138/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3129 - accuracy: 0.8902 - val_loss: 0.6186 - val_accuracy: 0.7920\n",
      "Epoch 139/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3122 - accuracy: 0.8903 - val_loss: 0.6219 - val_accuracy: 0.7930\n",
      "Epoch 140/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3112 - accuracy: 0.8912 - val_loss: 0.6253 - val_accuracy: 0.7920\n",
      "Epoch 141/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3105 - accuracy: 0.8906 - val_loss: 0.6212 - val_accuracy: 0.7860\n",
      "Epoch 142/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.3096 - accuracy: 0.8912 - val_loss: 0.6264 - val_accuracy: 0.7910\n",
      "Epoch 143/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3091 - accuracy: 0.8912 - val_loss: 0.6248 - val_accuracy: 0.7910\n",
      "Epoch 144/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3078 - accuracy: 0.8918 - val_loss: 0.6321 - val_accuracy: 0.7900\n",
      "Epoch 145/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3070 - accuracy: 0.8924 - val_loss: 0.6268 - val_accuracy: 0.7880\n",
      "Epoch 146/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.3064 - accuracy: 0.8924 - val_loss: 0.6317 - val_accuracy: 0.7910\n",
      "Epoch 147/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3053 - accuracy: 0.8925 - val_loss: 0.6282 - val_accuracy: 0.7880\n",
      "Epoch 148/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 0.3043 - accuracy: 0.8939 - val_loss: 0.6312 - val_accuracy: 0.7900\n",
      "Epoch 149/150\n",
      "57500/57500 [==============================] - 3s 51us/step - loss: 0.3034 - accuracy: 0.8940 - val_loss: 0.6428 - val_accuracy: 0.7860\n",
      "Epoch 150/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 0.3023 - accuracy: 0.8947 - val_loss: 0.6321 - val_accuracy: 0.7910\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "baseline_model_val = baseline_model.fit(X_train_tokens, \n",
    "                                        y_train_lb, \n",
    "                                        epochs=150, \n",
    "                                        batch_size=256, \n",
    "                                        validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "The attribute `.history` (stored as a dictionary) contains four entries now: one per metric that was being monitored during training and validation. Print the keys of this dictionary for confirmation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_dict = baseline_model_val.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the history attribute and store the dictionary\n",
    "baseline_model_val_dict = baseline_model_val.history\n",
    "baseline_model_val_dict.keys()\n",
    "\n",
    "# Print the keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the training data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 3s 44us/step\n",
      "----------\n",
      "Training Loss: 0.299 \n",
      "Training Accuracy: 0.895\n"
     ]
    }
   ],
   "source": [
    "results_train = baseline_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print('----------')\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 60us/step\n",
      "----------\n",
      "Test Loss: 0.595 \n",
      "Test Accuracy: 0.793\n"
     ]
    }
   ],
   "source": [
    "results_test = baseline_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print('----------')\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results \n",
    "\n",
    "Plot the loss versus the number of epochs. Be sure to include the training and the validation loss in the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and validation sets\n",
    "loss_values = baseline_model_val_dict['loss']\n",
    "val_loss = baseline_model_val_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'g', linestyle = \":\", label='Validation loss')\n",
    "\n",
    "plt.title('Training & Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a second plot comparing training and validation accuracy to the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy vs number of epochs with train and validation sets\n",
    "acc = baseline_model_val_dict['accuracy']\n",
    "val_acc = baseline_model_val_dict['val_accuracy']\n",
    "\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, acc, 'orange', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'orange', linestyle=\":\", label='Validation Accuracy')\n",
    "\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice an interesting pattern here? Although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss don't necessarily do the same. After a certain point, validation accuracy keeps swinging, which means that you're probably **overfitting** the model to the training data when you train for many epochs past a certain dropoff point. Let's tackle this now. You will now specify an early stopping point when training your model. \n",
    "\n",
    "\n",
    "## Early Stopping\n",
    "\n",
    "Overfitting neural networks is something you **_want_** to avoid at all costs. However, it's not possible to know in advance how many *epochs* you need to train your model on, and running the model multiple times with varying number of *epochs* maybe helpful, but is a time-consuming process. \n",
    "\n",
    "We've defined a model with the same architecture as above. This time specify an early stopping point when training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model_2.add(layers.Dense(25, activation='relu'))\n",
    "model_2.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer='SGD', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `EarlyStopping` and `ModelCheckpoint` from `keras.callbacks` \n",
    "- Define a list, `early_stopping`: \n",
    "  - Monitor `'val_loss'` and continue training for 10 epochs before stopping \n",
    "  - Save the best model while monitoring `'val_loss'` \n",
    " \n",
    "> If you need help, consult [documentation](https://keras.io/callbacks/).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import EarlyStopping and ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the callbacks\n",
    "early_stopping = [EarlyStopping(monitor='val_loss', patience=10), \n",
    "                  ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "#[EarlyStopping(patience=2),\n",
    "#                 ModelCheckpoint(filepath='model_2.{epoch:10d}-{val_loss:.2f}.h5')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train `model_2`. Make sure you set the `callbacks` argument to `early_stopping`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 3s 55us/step - loss: 1.8951 - accuracy: 0.2276 - val_loss: 1.8297 - val_accuracy: 0.2910\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 1.6732 - accuracy: 0.3909 - val_loss: 1.5412 - val_accuracy: 0.4470\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 1.3585 - accuracy: 0.5487 - val_loss: 1.2278 - val_accuracy: 0.5950\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 1.0804 - accuracy: 0.6606 - val_loss: 0.9811 - val_accuracy: 0.6740\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.8880 - accuracy: 0.7092 - val_loss: 0.8372 - val_accuracy: 0.6990\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.7783 - accuracy: 0.7329 - val_loss: 0.7618 - val_accuracy: 0.7220\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.7145 - accuracy: 0.7484 - val_loss: 0.7153 - val_accuracy: 0.7340\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.6735 - accuracy: 0.7594 - val_loss: 0.6883 - val_accuracy: 0.7400\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.6441 - accuracy: 0.7690 - val_loss: 0.6622 - val_accuracy: 0.7530\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.6218 - accuracy: 0.7755 - val_loss: 0.6476 - val_accuracy: 0.7520\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.6037 - accuracy: 0.7808 - val_loss: 0.6372 - val_accuracy: 0.7660\n",
      "Epoch 12/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.5882 - accuracy: 0.7862 - val_loss: 0.6227 - val_accuracy: 0.7670\n",
      "Epoch 13/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.5750 - accuracy: 0.7902 - val_loss: 0.6155 - val_accuracy: 0.7740\n",
      "Epoch 14/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.5636 - accuracy: 0.7937 - val_loss: 0.6080 - val_accuracy: 0.7710\n",
      "Epoch 15/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.5534 - accuracy: 0.7979 - val_loss: 0.6051 - val_accuracy: 0.7800\n",
      "Epoch 16/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.5443 - accuracy: 0.8019 - val_loss: 0.5933 - val_accuracy: 0.7860\n",
      "Epoch 17/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.5356 - accuracy: 0.8055 - val_loss: 0.5889 - val_accuracy: 0.7830\n",
      "Epoch 18/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5282 - accuracy: 0.8086 - val_loss: 0.5822 - val_accuracy: 0.7820\n",
      "Epoch 19/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.5209 - accuracy: 0.8113 - val_loss: 0.5831 - val_accuracy: 0.7780\n",
      "Epoch 20/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.5144 - accuracy: 0.8135 - val_loss: 0.5759 - val_accuracy: 0.7960\n",
      "Epoch 21/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.5081 - accuracy: 0.8163 - val_loss: 0.5743 - val_accuracy: 0.7910\n",
      "Epoch 22/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.5026 - accuracy: 0.8181 - val_loss: 0.5748 - val_accuracy: 0.7900\n",
      "Epoch 23/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.4972 - accuracy: 0.8201 - val_loss: 0.5694 - val_accuracy: 0.8020\n",
      "Epoch 24/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.4920 - accuracy: 0.8223 - val_loss: 0.5711 - val_accuracy: 0.7960\n",
      "Epoch 25/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.4871 - accuracy: 0.8242 - val_loss: 0.5638 - val_accuracy: 0.7970\n",
      "Epoch 26/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.4829 - accuracy: 0.8255 - val_loss: 0.5610 - val_accuracy: 0.8010\n",
      "Epoch 27/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.4781 - accuracy: 0.8277 - val_loss: 0.5607 - val_accuracy: 0.7980\n",
      "Epoch 28/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.4746 - accuracy: 0.8293 - val_loss: 0.5573 - val_accuracy: 0.8050\n",
      "Epoch 29/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.4702 - accuracy: 0.8309 - val_loss: 0.5633 - val_accuracy: 0.7940\n",
      "Epoch 30/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.4668 - accuracy: 0.8316 - val_loss: 0.5573 - val_accuracy: 0.8020\n",
      "Epoch 31/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.4630 - accuracy: 0.8340 - val_loss: 0.5556 - val_accuracy: 0.8040\n",
      "Epoch 32/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.4598 - accuracy: 0.8339 - val_loss: 0.5548 - val_accuracy: 0.8040\n",
      "Epoch 33/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.4563 - accuracy: 0.8365 - val_loss: 0.5564 - val_accuracy: 0.8010\n",
      "Epoch 34/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.4532 - accuracy: 0.8384 - val_loss: 0.5516 - val_accuracy: 0.8040\n",
      "Epoch 35/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.4500 - accuracy: 0.8393 - val_loss: 0.5529 - val_accuracy: 0.8060\n",
      "Epoch 36/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.4470 - accuracy: 0.8403 - val_loss: 0.5504 - val_accuracy: 0.8070\n",
      "Epoch 37/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.4444 - accuracy: 0.8416 - val_loss: 0.5529 - val_accuracy: 0.8050\n",
      "Epoch 38/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.4415 - accuracy: 0.8430 - val_loss: 0.5531 - val_accuracy: 0.8010\n",
      "Epoch 39/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.4388 - accuracy: 0.8441 - val_loss: 0.5513 - val_accuracy: 0.8080\n",
      "Epoch 40/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.4364 - accuracy: 0.8449 - val_loss: 0.5510 - val_accuracy: 0.8070\n",
      "Epoch 41/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.4337 - accuracy: 0.8460 - val_loss: 0.5593 - val_accuracy: 0.8030\n",
      "Epoch 42/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.4313 - accuracy: 0.8471 - val_loss: 0.5496 - val_accuracy: 0.8010\n",
      "Epoch 43/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.4289 - accuracy: 0.8470 - val_loss: 0.5560 - val_accuracy: 0.8070\n",
      "Epoch 44/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.4267 - accuracy: 0.8483 - val_loss: 0.5492 - val_accuracy: 0.8080\n",
      "Epoch 45/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.4245 - accuracy: 0.8491 - val_loss: 0.5568 - val_accuracy: 0.8080\n",
      "Epoch 46/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.4225 - accuracy: 0.8498 - val_loss: 0.5533 - val_accuracy: 0.8100\n",
      "Epoch 47/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.4203 - accuracy: 0.8510 - val_loss: 0.5511 - val_accuracy: 0.8100\n",
      "Epoch 48/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.4181 - accuracy: 0.8518 - val_loss: 0.5494 - val_accuracy: 0.8090\n",
      "Epoch 49/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.4158 - accuracy: 0.8526 - val_loss: 0.5565 - val_accuracy: 0.8050\n",
      "Epoch 50/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.4142 - accuracy: 0.8532 - val_loss: 0.5556 - val_accuracy: 0.8110\n",
      "Epoch 51/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.4119 - accuracy: 0.8539 - val_loss: 0.5579 - val_accuracy: 0.8100\n",
      "Epoch 52/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.4105 - accuracy: 0.8549 - val_loss: 0.5535 - val_accuracy: 0.8060\n",
      "Epoch 53/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.4087 - accuracy: 0.8543 - val_loss: 0.5519 - val_accuracy: 0.8100\n",
      "Epoch 54/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.4065 - accuracy: 0.8566 - val_loss: 0.5602 - val_accuracy: 0.8080\n"
     ]
    }
   ],
   "source": [
    "model_2_val = model_2.fit(X_train_tokens, y_train_lb,\n",
    "                          epochs=150,\n",
    "                          callbacks=early_stopping,\n",
    "                          batch_size=256,\n",
    "                         validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best (saved) model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best (saved) model\n",
    "from keras.models import load_model\n",
    "saved_model = load_model('best_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use this model to to calculate the training and test accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 2s 39us/step\n",
      "Training Loss: 0.422 \n",
      "Training Accuracy: 0.851\n",
      "----------\n",
      "1500/1500 [==============================] - 0s 88us/step\n",
      "Test Loss: 0.552 \n",
      "Test Accuracy: 0.782\n"
     ]
    }
   ],
   "source": [
    "results_train = saved_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = saved_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely done! Did you notice that the model didn't train for all 150 epochs? You reduced your training time. \n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance. \n",
    "\n",
    "## L2 Regularization \n",
    "\n",
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform. \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L2 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 3s 55us/step - loss: 2.3639 - accuracy: 0.2411 - val_loss: 2.2710 - val_accuracy: 0.3530\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 2.0790 - accuracy: 0.4774 - val_loss: 1.9024 - val_accuracy: 0.5520\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 1.6934 - accuracy: 0.6167 - val_loss: 1.5535 - val_accuracy: 0.6580\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 1.4215 - accuracy: 0.6866 - val_loss: 1.3500 - val_accuracy: 0.7060\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 1.2614 - accuracy: 0.7212 - val_loss: 1.2230 - val_accuracy: 0.7310\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 1.1618 - accuracy: 0.7427 - val_loss: 1.1457 - val_accuracy: 0.7410\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 1.0936 - accuracy: 0.7558 - val_loss: 1.0929 - val_accuracy: 0.7450\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 3s 60us/step - loss: 1.0422 - accuracy: 0.7670 - val_loss: 1.0512 - val_accuracy: 0.7570\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 3s 51us/step - loss: 1.0008 - accuracy: 0.7757 - val_loss: 1.0160 - val_accuracy: 0.7650\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.9659 - accuracy: 0.7834 - val_loss: 0.9893 - val_accuracy: 0.7670\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.9348 - accuracy: 0.7906 - val_loss: 0.9610 - val_accuracy: 0.7720\n",
      "Epoch 12/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.9074 - accuracy: 0.7949 - val_loss: 0.9388 - val_accuracy: 0.7840\n",
      "Epoch 13/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.8826 - accuracy: 0.8003 - val_loss: 0.9176 - val_accuracy: 0.7890\n",
      "Epoch 14/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.8596 - accuracy: 0.8042 - val_loss: 0.9001 - val_accuracy: 0.7830\n",
      "Epoch 15/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.8384 - accuracy: 0.8088 - val_loss: 0.8788 - val_accuracy: 0.7920\n",
      "Epoch 16/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.8186 - accuracy: 0.8122 - val_loss: 0.8670 - val_accuracy: 0.7840\n",
      "Epoch 17/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.8001 - accuracy: 0.8153 - val_loss: 0.8506 - val_accuracy: 0.7920\n",
      "Epoch 18/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.7827 - accuracy: 0.8189 - val_loss: 0.8390 - val_accuracy: 0.7840\n",
      "Epoch 19/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.7661 - accuracy: 0.8213 - val_loss: 0.8229 - val_accuracy: 0.7940\n",
      "Epoch 20/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.7506 - accuracy: 0.8241 - val_loss: 0.8145 - val_accuracy: 0.7880\n",
      "Epoch 21/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.7357 - accuracy: 0.8261 - val_loss: 0.7961 - val_accuracy: 0.8020\n",
      "Epoch 22/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.7220 - accuracy: 0.8283 - val_loss: 0.7901 - val_accuracy: 0.8040\n",
      "Epoch 23/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.7089 - accuracy: 0.8307 - val_loss: 0.7772 - val_accuracy: 0.8070\n",
      "Epoch 24/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6963 - accuracy: 0.8326 - val_loss: 0.7700 - val_accuracy: 0.8030\n",
      "Epoch 25/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.6845 - accuracy: 0.8347 - val_loss: 0.7586 - val_accuracy: 0.8040\n",
      "Epoch 26/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.6732 - accuracy: 0.8358 - val_loss: 0.7486 - val_accuracy: 0.8010\n",
      "Epoch 27/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.6623 - accuracy: 0.8375 - val_loss: 0.7480 - val_accuracy: 0.7990\n",
      "Epoch 28/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.6521 - accuracy: 0.8394 - val_loss: 0.7342 - val_accuracy: 0.8120\n",
      "Epoch 29/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.6422 - accuracy: 0.8405 - val_loss: 0.7305 - val_accuracy: 0.8090\n",
      "Epoch 30/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.6330 - accuracy: 0.8413 - val_loss: 0.7222 - val_accuracy: 0.8140\n",
      "Epoch 31/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.6242 - accuracy: 0.8432 - val_loss: 0.7130 - val_accuracy: 0.8100\n",
      "Epoch 32/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.6157 - accuracy: 0.8453 - val_loss: 0.7116 - val_accuracy: 0.8030\n",
      "Epoch 33/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.6073 - accuracy: 0.8455 - val_loss: 0.7017 - val_accuracy: 0.8130\n",
      "Epoch 34/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5997 - accuracy: 0.8475 - val_loss: 0.6992 - val_accuracy: 0.8010\n",
      "Epoch 35/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5924 - accuracy: 0.8478 - val_loss: 0.6914 - val_accuracy: 0.8060\n",
      "Epoch 36/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.5852 - accuracy: 0.8485 - val_loss: 0.6905 - val_accuracy: 0.8060\n",
      "Epoch 37/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.5785 - accuracy: 0.8502 - val_loss: 0.6804 - val_accuracy: 0.8140\n",
      "Epoch 38/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.5719 - accuracy: 0.8510 - val_loss: 0.6804 - val_accuracy: 0.8110\n",
      "Epoch 39/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.5653 - accuracy: 0.8520 - val_loss: 0.6755 - val_accuracy: 0.8090\n",
      "Epoch 40/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.5598 - accuracy: 0.8525 - val_loss: 0.6712 - val_accuracy: 0.8010\n",
      "Epoch 41/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.5539 - accuracy: 0.8532 - val_loss: 0.6712 - val_accuracy: 0.8020\n",
      "Epoch 42/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.5485 - accuracy: 0.8541 - val_loss: 0.6623 - val_accuracy: 0.8090\n",
      "Epoch 43/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.5434 - accuracy: 0.8548 - val_loss: 0.6566 - val_accuracy: 0.8060\n",
      "Epoch 44/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.5383 - accuracy: 0.8548 - val_loss: 0.6546 - val_accuracy: 0.8110\n",
      "Epoch 45/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.5335 - accuracy: 0.8558 - val_loss: 0.6539 - val_accuracy: 0.8040\n",
      "Epoch 46/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.5290 - accuracy: 0.8569 - val_loss: 0.6513 - val_accuracy: 0.8050\n",
      "Epoch 47/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.5243 - accuracy: 0.8566 - val_loss: 0.6523 - val_accuracy: 0.8050\n",
      "Epoch 48/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.5199 - accuracy: 0.8589 - val_loss: 0.6464 - val_accuracy: 0.8060\n",
      "Epoch 49/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.5160 - accuracy: 0.8587 - val_loss: 0.6437 - val_accuracy: 0.8060\n",
      "Epoch 50/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.5119 - accuracy: 0.8589 - val_loss: 0.6446 - val_accuracy: 0.8060\n",
      "Epoch 51/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.5085 - accuracy: 0.8594 - val_loss: 0.6396 - val_accuracy: 0.8020\n",
      "Epoch 52/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.5050 - accuracy: 0.8586 - val_loss: 0.6369 - val_accuracy: 0.7990\n",
      "Epoch 53/150\n",
      "57500/57500 [==============================] - 3s 60us/step - loss: 0.5012 - accuracy: 0.8599 - val_loss: 0.6339 - val_accuracy: 0.8040\n",
      "Epoch 54/150\n",
      "57500/57500 [==============================] - 3s 58us/step - loss: 0.4975 - accuracy: 0.8609 - val_loss: 0.6342 - val_accuracy: 0.8020\n",
      "Epoch 55/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.4944 - accuracy: 0.8611 - val_loss: 0.6331 - val_accuracy: 0.8060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.4911 - accuracy: 0.8610 - val_loss: 0.6273 - val_accuracy: 0.7980\n",
      "Epoch 57/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.4880 - accuracy: 0.8618 - val_loss: 0.6263 - val_accuracy: 0.8010\n",
      "Epoch 58/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.4852 - accuracy: 0.8620 - val_loss: 0.6305 - val_accuracy: 0.8030\n",
      "Epoch 59/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.4821 - accuracy: 0.8624 - val_loss: 0.6294 - val_accuracy: 0.8090\n",
      "Epoch 60/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.4798 - accuracy: 0.8628 - val_loss: 0.6226 - val_accuracy: 0.8080\n",
      "Epoch 61/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.4770 - accuracy: 0.8627 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
      "Epoch 62/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.4747 - accuracy: 0.8634 - val_loss: 0.6236 - val_accuracy: 0.8020\n",
      "Epoch 63/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.4718 - accuracy: 0.8639 - val_loss: 0.6256 - val_accuracy: 0.8020\n",
      "Epoch 64/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.4702 - accuracy: 0.8639 - val_loss: 0.6184 - val_accuracy: 0.8010\n",
      "Epoch 65/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.4672 - accuracy: 0.8645 - val_loss: 0.6274 - val_accuracy: 0.8040\n",
      "Epoch 66/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.4655 - accuracy: 0.8642 - val_loss: 0.6173 - val_accuracy: 0.8010\n",
      "Epoch 67/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 0.4634 - accuracy: 0.8651 - val_loss: 0.6180 - val_accuracy: 0.8010\n",
      "Epoch 68/150\n",
      "57500/57500 [==============================] - 3s 55us/step - loss: 0.4611 - accuracy: 0.8659 - val_loss: 0.6216 - val_accuracy: 0.8040\n",
      "Epoch 69/150\n",
      "57500/57500 [==============================] - 3s 56us/step - loss: 0.4592 - accuracy: 0.8651 - val_loss: 0.6126 - val_accuracy: 0.8010\n",
      "Epoch 70/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 0.4572 - accuracy: 0.8658 - val_loss: 0.6106 - val_accuracy: 0.8020\n",
      "Epoch 71/150\n",
      "57500/57500 [==============================] - 3s 55us/step - loss: 0.4555 - accuracy: 0.8656 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
      "Epoch 72/150\n",
      "57500/57500 [==============================] - 3s 60us/step - loss: 0.4536 - accuracy: 0.8663 - val_loss: 0.6251 - val_accuracy: 0.8020\n",
      "Epoch 73/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 0.4520 - accuracy: 0.8652 - val_loss: 0.6131 - val_accuracy: 0.8020\n",
      "Epoch 74/150\n",
      "57500/57500 [==============================] - 3s 51us/step - loss: 0.4504 - accuracy: 0.8671 - val_loss: 0.6194 - val_accuracy: 0.8060\n",
      "Epoch 75/150\n",
      "57500/57500 [==============================] - 4s 70us/step - loss: 0.4484 - accuracy: 0.8673 - val_loss: 0.6072 - val_accuracy: 0.8020\n",
      "Epoch 76/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 0.4469 - accuracy: 0.8678 - val_loss: 0.6095 - val_accuracy: 0.8000\n",
      "Epoch 77/150\n",
      "57500/57500 [==============================] - 3s 51us/step - loss: 0.4453 - accuracy: 0.8676 - val_loss: 0.6097 - val_accuracy: 0.8070\n",
      "Epoch 78/150\n",
      "57500/57500 [==============================] - 4s 64us/step - loss: 0.4435 - accuracy: 0.8677 - val_loss: 0.6114 - val_accuracy: 0.8010\n",
      "Epoch 79/150\n",
      "57500/57500 [==============================] - 4s 71us/step - loss: 0.4422 - accuracy: 0.8689 - val_loss: 0.6205 - val_accuracy: 0.8000\n",
      "Epoch 80/150\n",
      "57500/57500 [==============================] - 3s 56us/step - loss: 0.4408 - accuracy: 0.8676 - val_loss: 0.6189 - val_accuracy: 0.7980\n",
      "Epoch 81/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.4392 - accuracy: 0.8672 - val_loss: 0.6087 - val_accuracy: 0.8010\n",
      "Epoch 82/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.4376 - accuracy: 0.8687 - val_loss: 0.6177 - val_accuracy: 0.8050\n",
      "Epoch 83/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.4370 - accuracy: 0.8687 - val_loss: 0.6052 - val_accuracy: 0.8020\n",
      "Epoch 84/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 0.4361 - accuracy: 0.8688 - val_loss: 0.6070 - val_accuracy: 0.7990\n",
      "Epoch 85/150\n",
      "57500/57500 [==============================] - 3s 60us/step - loss: 0.4341 - accuracy: 0.8693 - val_loss: 0.6072 - val_accuracy: 0.8090\n",
      "Epoch 86/150\n",
      "57500/57500 [==============================] - 4s 73us/step - loss: 0.4329 - accuracy: 0.8695 - val_loss: 0.6151 - val_accuracy: 0.8070\n",
      "Epoch 87/150\n",
      "57500/57500 [==============================] - 4s 62us/step - loss: 0.4317 - accuracy: 0.8690 - val_loss: 0.6094 - val_accuracy: 0.7980\n",
      "Epoch 88/150\n",
      "57500/57500 [==============================] - 3s 60us/step - loss: 0.4305 - accuracy: 0.8692 - val_loss: 0.6077 - val_accuracy: 0.8010\n",
      "Epoch 89/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.4293 - accuracy: 0.8701 - val_loss: 0.6113 - val_accuracy: 0.8060\n",
      "Epoch 90/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.4289 - accuracy: 0.8696 - val_loss: 0.6156 - val_accuracy: 0.8040\n",
      "Epoch 91/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.4274 - accuracy: 0.8705 - val_loss: 0.6095 - val_accuracy: 0.7990\n",
      "Epoch 92/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.4263 - accuracy: 0.8713 - val_loss: 0.6067 - val_accuracy: 0.8000\n",
      "Epoch 93/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.4251 - accuracy: 0.8702 - val_loss: 0.6112 - val_accuracy: 0.8030\n",
      "Epoch 94/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.4245 - accuracy: 0.8707 - val_loss: 0.6065 - val_accuracy: 0.7960\n",
      "Epoch 95/150\n",
      "57500/57500 [==============================] - 3s 56us/step - loss: 0.4227 - accuracy: 0.8719 - val_loss: 0.6115 - val_accuracy: 0.7960\n",
      "Epoch 96/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.4215 - accuracy: 0.8718 - val_loss: 0.6116 - val_accuracy: 0.8030\n",
      "Epoch 97/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.4211 - accuracy: 0.8720 - val_loss: 0.6063 - val_accuracy: 0.8050\n",
      "Epoch 98/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.4203 - accuracy: 0.8723 - val_loss: 0.6093 - val_accuracy: 0.8110\n",
      "Epoch 99/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.4189 - accuracy: 0.8720 - val_loss: 0.6262 - val_accuracy: 0.7940\n",
      "Epoch 100/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.4178 - accuracy: 0.8733 - val_loss: 0.6155 - val_accuracy: 0.8030\n",
      "Epoch 101/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.4166 - accuracy: 0.8729 - val_loss: 0.6184 - val_accuracy: 0.8070\n",
      "Epoch 102/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.4158 - accuracy: 0.8723 - val_loss: 0.6111 - val_accuracy: 0.7930\n",
      "Epoch 103/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.4152 - accuracy: 0.8728 - val_loss: 0.6222 - val_accuracy: 0.8030\n",
      "Epoch 104/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.4134 - accuracy: 0.8738 - val_loss: 0.6105 - val_accuracy: 0.8020\n",
      "Epoch 105/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.4130 - accuracy: 0.8740 - val_loss: 0.6115 - val_accuracy: 0.8060\n",
      "Epoch 106/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.4126 - accuracy: 0.8741 - val_loss: 0.6123 - val_accuracy: 0.8010\n",
      "Epoch 107/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.4115 - accuracy: 0.8739 - val_loss: 0.6126 - val_accuracy: 0.8050\n",
      "Epoch 108/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.4106 - accuracy: 0.8755 - val_loss: 0.6073 - val_accuracy: 0.8000\n",
      "Epoch 109/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.4096 - accuracy: 0.8746 - val_loss: 0.6041 - val_accuracy: 0.8070\n",
      "Epoch 110/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.4084 - accuracy: 0.8747 - val_loss: 0.6111 - val_accuracy: 0.7970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.4076 - accuracy: 0.8756 - val_loss: 0.6185 - val_accuracy: 0.8050\n",
      "Epoch 112/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.4073 - accuracy: 0.8757 - val_loss: 0.6081 - val_accuracy: 0.8030\n",
      "Epoch 113/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.4062 - accuracy: 0.8750 - val_loss: 0.6291 - val_accuracy: 0.8110\n",
      "Epoch 114/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.4057 - accuracy: 0.8755 - val_loss: 0.6313 - val_accuracy: 0.8000\n",
      "Epoch 115/150\n",
      "57500/57500 [==============================] - 3s 50us/step - loss: 0.4043 - accuracy: 0.8767 - val_loss: 0.6096 - val_accuracy: 0.7950\n",
      "Epoch 116/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.4027 - accuracy: 0.8756 - val_loss: 0.6218 - val_accuracy: 0.8000\n",
      "Epoch 117/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.4018 - accuracy: 0.8774 - val_loss: 0.6248 - val_accuracy: 0.8030\n",
      "Epoch 118/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.4005 - accuracy: 0.8779 - val_loss: 0.6089 - val_accuracy: 0.8010\n",
      "Epoch 119/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.4005 - accuracy: 0.8779 - val_loss: 0.6139 - val_accuracy: 0.8000\n",
      "Epoch 120/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.4000 - accuracy: 0.8785 - val_loss: 0.6244 - val_accuracy: 0.8020\n",
      "Epoch 121/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.3989 - accuracy: 0.8775 - val_loss: 0.6094 - val_accuracy: 0.8070\n",
      "Epoch 122/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.3977 - accuracy: 0.8781 - val_loss: 0.6087 - val_accuracy: 0.8010\n",
      "Epoch 123/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.3958 - accuracy: 0.8792 - val_loss: 0.6162 - val_accuracy: 0.7900\n",
      "Epoch 124/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.3958 - accuracy: 0.8791 - val_loss: 0.6092 - val_accuracy: 0.8020\n",
      "Epoch 125/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.3935 - accuracy: 0.8808 - val_loss: 0.6084 - val_accuracy: 0.8070\n",
      "Epoch 126/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.3936 - accuracy: 0.8800 - val_loss: 0.6395 - val_accuracy: 0.8030\n",
      "Epoch 127/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.3939 - accuracy: 0.8790 - val_loss: 0.6021 - val_accuracy: 0.8040\n",
      "Epoch 128/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.3924 - accuracy: 0.8795 - val_loss: 0.6117 - val_accuracy: 0.8060\n",
      "Epoch 129/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.3922 - accuracy: 0.8799 - val_loss: 0.6213 - val_accuracy: 0.8000\n",
      "Epoch 130/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.3908 - accuracy: 0.8809 - val_loss: 0.6165 - val_accuracy: 0.7990\n",
      "Epoch 131/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.3886 - accuracy: 0.8831 - val_loss: 0.6345 - val_accuracy: 0.8100\n",
      "Epoch 132/150\n",
      "57500/57500 [==============================] - ETA: 0s - loss: 0.3881 - accuracy: 0.88 - 2s 43us/step - loss: 0.3886 - accuracy: 0.8818 - val_loss: 0.6223 - val_accuracy: 0.8050\n",
      "Epoch 133/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.3874 - accuracy: 0.8825 - val_loss: 0.6277 - val_accuracy: 0.8050\n",
      "Epoch 134/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 0.3870 - accuracy: 0.8832 - val_loss: 0.6311 - val_accuracy: 0.8040\n",
      "Epoch 135/150\n",
      "57500/57500 [==============================] - 4s 69us/step - loss: 0.3854 - accuracy: 0.8842 - val_loss: 0.6222 - val_accuracy: 0.8010\n",
      "Epoch 136/150\n",
      "57500/57500 [==============================] - 4s 64us/step - loss: 0.3845 - accuracy: 0.8842 - val_loss: 0.6323 - val_accuracy: 0.8040\n",
      "Epoch 137/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.3835 - accuracy: 0.8839 - val_loss: 0.6594 - val_accuracy: 0.7960\n",
      "Epoch 138/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.3823 - accuracy: 0.8853 - val_loss: 0.6140 - val_accuracy: 0.8040\n",
      "Epoch 139/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.3828 - accuracy: 0.8840 - val_loss: 0.6234 - val_accuracy: 0.7980\n",
      "Epoch 140/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.3818 - accuracy: 0.8850 - val_loss: 0.6185 - val_accuracy: 0.8030\n",
      "Epoch 141/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.3796 - accuracy: 0.8865 - val_loss: 0.6217 - val_accuracy: 0.7970\n",
      "Epoch 142/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.3796 - accuracy: 0.8870 - val_loss: 0.6282 - val_accuracy: 0.8040\n",
      "Epoch 143/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.3780 - accuracy: 0.8866 - val_loss: 0.6137 - val_accuracy: 0.8050\n",
      "Epoch 144/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.3773 - accuracy: 0.8870 - val_loss: 0.6385 - val_accuracy: 0.7990\n",
      "Epoch 145/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.3759 - accuracy: 0.8888 - val_loss: 0.6839 - val_accuracy: 0.7850\n",
      "Epoch 146/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.3756 - accuracy: 0.8885 - val_loss: 0.6219 - val_accuracy: 0.8000\n",
      "Epoch 147/150\n",
      "57500/57500 [==============================] - 3s 55us/step - loss: 0.3738 - accuracy: 0.8895 - val_loss: 0.6372 - val_accuracy: 0.8070\n",
      "Epoch 148/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.3731 - accuracy: 0.8893 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
      "Epoch 149/150\n",
      "57500/57500 [==============================] - 3s 51us/step - loss: 0.3742 - accuracy: 0.8881 - val_loss: 0.6550 - val_accuracy: 0.7930\n",
      "Epoch 150/150\n",
      "57500/57500 [==============================] - 3s 50us/step - loss: 0.3716 - accuracy: 0.8902 - val_loss: 0.6212 - val_accuracy: 0.8060\n"
     ]
    }
   ],
   "source": [
    "# Import regularizers\n",
    "from keras import regularizers\n",
    "random.seed(123)\n",
    "L2_model = models.Sequential()\n",
    "lambda_coef = .005\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L2_model.add(layers.Dense(50, activation='relu', \n",
    "                          kernel_regularizer=regularizers.l2(lambda_coef), \n",
    "                          input_shape=(2000,)))\n",
    "\n",
    "# Add another hidden layer\n",
    "L2_model.add(layers.Dense(25, activation='relu'))\n",
    "\n",
    "# Add an output layer\n",
    "L2_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L2_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L2_model_val = L2_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training as well as the validation accuracy for both the L2 and the baseline models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHwCAYAAACPE1g3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3gc1bn48e/Z3rQr7apLtiR3G9NNCWBaEkKSC4FACilAQgIJkJsESEi7BEiB3F9CbgokXBISOg6pwA09GAjdFIfYxl3N6lppe505vz9mLUuyLMsGWwbez/PMs6uZ2TNnZoveOfOeM0prjRBCCCGEEGJqbNNdASGEEEIIId5KJIAWQgghhBBiF0gALYQQQgghxC6QAFoIIYQQQohdIAG0EEIIIYQQu0ACaCGEEEIIIXaBBNBCiEkppR5QSp3zZq+7L1NKnauU+ueov5NKqVlTWXc3tvW2OGZi71NK/V4p9f3procQ70QSQAvxNlQK+LZOplIqM+rvT+5KWVrr92utb3mz191VSqmwUuo+pVRMKdWllPr6ntjORLTWAa31pjdajlLqSqXU7ePK3mPH7J1gomNamu9WSv1WKdWmlEoopV5RSr1/OuoohHj7cUx3BYQQbz6tdWDrc6VUK/A5rfWj49dTSjm01sW9Wbc34GuAB6gD3MCi6a2OmMw+8NlyAB3AcUA78AHgD0qp/bXWrXujAvvAMZiQUkoBSmttTnddhHirkhZoId5BlFLHK6U6lVKXK6V6gN8ppSqUUvcrpfqVUkOl542jXrNcKfW50vNzlVL/VEr9uLTu5tGteru4botS6slS6+CjSqnrJ2pJHKUI9Gmt01rrIa310zvZ118rpX48bt7flFKXlJ5/Qym1sbT91Uqp0ycpSyul5pSeR5RS9yql4kqpF4DZ49b9mVKqo7T8JaXU0tL8k4FvAR8rXQlYOcExsymlvlNqNe1TSt2qlAqVljWX6nGOUqpdKTWglPr2JHX+YKnVNV6qz5Xjlh+jlHpGKTVcWn5uab5XKfWTUh1ipffQu/WzM66MVqXUe0rPr1RK/VEpdbtSKg6cq5Q6XCn1bGkb3UqpXyqlXKNev59S6hGlVFQp1auU+pZSqlYplVZKRUatd2jp8+nc0f6Op7VOaa2v1Fq3aq1NrfX9wGbg0AmOlbtUx8Wj5lUp68pNtVKqsvS9GC7V9Sml1IT/P0vv0UVKqfXA+tK8/1BKvVp6/TNKqQNGrX9I6X1KKKXuUUotU6W0DDVBetDoz+K4+VP5Hv9AKfU0kAYmTEkSQkyNBNBCvPPUAmGgCTgf63fgd6W/ZwIZ4JeTvP4IYC1QCfw38FullNqNde8EXgAiwJXAp3dS7xeAs5RSn93JelvdiRWsKrACDOAk4O7S8o3AUiAEXAXcrpSqm0K51wNZrJbwz5am0V4EDsI6xncC9yilPFrrB4EfAstKKSEHTlD2uaXpBKwAJ8D278UxwHzg3cAVSqmFO6hnCjgbKAc+CHxRKXUagFJqJvAA8AugqlTfV0uv+zFWkHlUaR++Dky1pfJDwB9L27wDMICvYr3/7yrV+cJSHcqAR4EHgXpgDvCY1roHWA58dFS5nwLu1loXpliP7SilaoB5wKrxy7TWOeDPwFmjZn8UeEJr3QdcCnRiHasarBMhPcnmTsP67C9SSh0C3AxcgPVZvxG4txS0u4C/AL/HOtZ3ATs8kduJqXyPP431nS8D2nZzO0IIJIAW4p3IBL6rtc5prTNa60Gt9Z9KLbsJ4AdYl713pE1rfZPW2gBuwQoka3Zl3VIAdxhwhdY6r7X+J3DvjjZYanH7X+B44BtKqc+U5ruVUvmtrbTjPIUV5Cwt/X0m8KzWugtAa32P1rqr1Dq5DKu18PBJ9hullB04o1TvlNb636X9GqG1vr10TIta659gpZvMn6zcUT4JXKe13qS1TgLfBD6ulBqdbndV6X1bCawEJgrE0Vov11q/Vtq/f2EFZ1vf108Cj2qt79JaF0r1fbXUqvpZ4Mta6y1aa0Nr/UwpwJyKZ7XWfy1tM6O1fklr/VzpWLRiBY9b6/AfQI/W+ida66zWOqG1fr607BasoHnrMT8LuG2KddhOqeX6DuAWrfXrO1jtTsYG0J8ozQMoYH12m0rH6ymt9WQB9DVa66jWOgN8HrhRa/186XjeAuSAI0uTA/h5qdw/Y50o7rIpfo9/r7VeVXo/dvtkRAghAbQQ70T9Wuvs1j+UUj6l1I2lS/Zx4EmgvBS4TKRn6xOtdbr0NLCL69YD0VHzwMpX3ZHzgEe01k8C7wO+VwqijwRe0VrHxr+gFODczbag6BNYQRQASqmzR11WHwYWY7WUTqaKbbm1W41pyVNKXaqUWlNKfxjGauHeWblb1Y8rr620vdEnKD2jnqfZwbFXSh2hlHq8dEk/BnxhVD1mYLXAj1eJlWc+0bKpGPMeKqXmlVIJekqfrR9OoQ4Af8NqvZ0FvBeIaa13K7AsnRTcBuSBiydZ9R+At3TcmrBa5f9SWvb/gA3Aw0qpTUqpb+xks6OPQxNw6dbPWekzMQPrva4HtowLxif7HuzQFL/Hu1W2EGJ7EkAL8c4zvuXsUqwW0iO01kHg2NL8HaVlvBm6gbBSyjdq3oxJ1ndg5UCjtd4MnIyVEvIb4OpJXncXcGYpIDoC+BNA6e+bsAKqiNa6HPg3O9/n/lI9Rtd15tYnysp3vhzr8n9FqdzYqHIna7UE6MIKuEaXXQR6d/K6idyJ1ao/Q2sdAn49qh4djMvdLhnASk+ZaFkKGHm/SoFZ1bh1xu/fr4DXgbmlz9a3plAHSid4f8BqKf80u9n6XErf+S3WCcgZk7W6ljrU/QHrhOsTwP2lllxKreOXaq1nAacAlyil3j3JpscHxD/QWpePmnxa67uwvgcN41KgRn+2xh/z2km2OZXv8c4+f0KIKZIAWghRhpUvOayUCgPf3dMb1Fq3ASuAK5VSLqXUu7ACkx35M1Y+82mlwC2Olb4wm0mCAq31K1hB72+Ah7TWw6VF/tLr+gFKrdmLJyxkbHlGqS5Xllr8FgGjx3Auwwp4+wGHUuoKIDhqeS/QvKMOaFgB/1eV1cEywLac6d0ZyaEMq5U/q5Q6HCso3OoO4D1KqY8qpRzK6hh5UCmIvBm4TilVr5SyK6XepZRyA+sAj7I6JzqB72Clp+ysDnEgqZRaAHxx1LL7gVql1FdKqThlSqkjRi2/FSsf/FRgss6lADallGfUtLVevwIWAqeU0il25k7gY1iB+9b0ja2dAOeUAt04Vm63MYXywDpR+0KpZVsppfylY1gGPFsq5+LS+/AhxqYRrQT2U0odpJTyYPUV2JG9/j0W4p1MAmghxP8AXqzWx+ewOnXtDZ/E6lg2CHwfWIaVG7odrfWzWAHgd4Eh4CHg71j5yHcppQ6eZDt3Ae9hVECktV4N/AQrgOkF9gcmHdVjlIux0iZ6sDp//W7UsoewOuetw0q/yDL2svk9pcdBpdTLE5R9M1Zr65NYI0ZkgS9NsV7jXQhcrZRKAFdgta4CoLXeOqzbpUAUqwPh1lzqy4DXsDpDRoEfAbZSmsyFWCcjW7BaR8eMyjGBy7DetwRWILlsVB0SWOkZp2Ady/VYnSe3Ln8aK1//Zb3zYefOwgoet04bS1cZLsBKxehRUxgHvZSDncJKrXhg1KK5WB0ek1ifmRu01st3UqetZa7AyoP+JdZndwPWiQFa6zzwYawUpWGsvO/7KX0PtNbrsK6wPIp1fCa7Yc90fY+FeEdSk/eDEEKIvUMptQx4XWstLWcCAKXUP4A7tda/me667C1KqeeBX2utf7fTlYUQ00ZaoIUQ00IpdZhSarayxj4+GWsItL9Od73EvkEpdRhwCKNard+OlFLHKWvsa4eybul+ANJ6LMQ+T+5EKISYLrVY+cQRrFSAL5ZylsU7nFLqFqyxlL+8tSPf29h8rPSaANaoJGdqrbunt0pCiJ2RFA4hhBBCCCF2gaRwCCGEEEIIsQskgBZCCCGEEGIXvOVyoCsrK3Vzc/N0V0MIIYQQQrzNvfTSSwNa6/E3jXrrBdDNzc2sWLFiuqshhBBCCCHe5pRSbRPNlxQOIYQQQgghdoEE0EIIIYQQQuwCCaCFEEIIIYTYBRJACyGEEEIIsQskgBZCCCGEEGIXSAAthBBCCCHELpAAWgghhBBCiF0gAbQQQgghhBC7QAJoIYQQQgghdoEE0EIIIYQQQuwCCaCFEEIIIYTYBXs0gFZKnayUWquU2qCU+sYEy5uUUo8ppf6llFqulGrck/URQgghhBDijdpjAbRSyg5cD7wfWAScpZRaNG61HwO3aq0PAK4GrtlT9RFCCCGEEOLNsCdboA8HNmitN2mt88DdwIfGrbMIeKz0/PEJlgshhBBCCLFP2ZMBdAPQMervztK80VYCZ5Senw6UKaUi4wtSSp2vlFqhlFrR39+/RyorhBBCCCHEVOzJAFpNME+P+/sy4Dil1CvAccAWoLjdi7T+X631Eq31kqqqqje/pkIIIYQQQkyRYw+W3QnMGPV3I9A1egWtdRfwYQClVAA4Q2sd24N1EkIIIYQQbxGGaTCcGybi3S5BYVrtyQD6RWCuUqoFq2X548AnRq+glKoEolprE/gmcPMerI8QQgghhNgHJPIJVg+u5rWB1+hL92GYBoa2plQhRV+6j950L/3pfuzKzopPrUCpiZIbpsceC6C11kWl1MXAQ4AduFlrvUopdTWwQmt9L3A8cI1SSgNPAhftqfoIIYQQQog3rmAUGMoNEc1GiWaiDGYHreelKWfkMLWJqU201hjaQGuNiYmhDbYkttAabx0pL+gK4rA5sCs7NmXD6/BS46vh8NrDqfHVUOOroaiLOJVz+nZ6HKX1+LTkfduSJUv0ihUrprsaQgghhBB7TcEosG54HQWjQJWviipvFS67a+w6ZoFMMUO6kCZTzIyZts6L5+NsSW5hS2ILnclOotkoIXeIsCdM2BMm6AoSy8WIZq3AeCg7xOhY0cQkVUhNWEenzUnYE8br8KKUwoYNpdRIYLx1XqWvksWRxexfuT/7Ve5HyB3a4X53RNO8tiXGB/ave3MO5C5SSr2ktV4yfv6eTOEQQgghhBCjFMwCg5lBBjIDDGYGKZpFUIwEm3kjT87IkTWyZItZWmOtrBpcxbqhdRTMwpiyQu4Qbrt7JEgumtuNwzAhr8NLQ6CBxkAjB1YdSDwfJ5qNsmF4A4l8gpArRNgbZmF4IeXuchy2seHi1oA74okQ9lqBd4W7gt5heHZTlGzBIOB2EvA4CLjtRFMFNvUn2difZFN/irZckVVOO391Grgd/ybidzGvtoz5NWXMry2jYJg8urqXh1f38npPAodNsXRuJWWefacFWgJoIYQQQohxtga6sVyMeD5OLBezpnyMeC5OLB8jVUjhsXvwOrx4HB4cNgfRbJSB9AD9mX6i2SiGaWBipTMUzSKJfAK93aBkO1bmLGNRZBGfWvQpFkUW4Xf4GcgM0Jfuoz/TT97I43V4x0w+p2+7eV6HF5/DR5mrjJA7tMN84kS2wGAyTzSdZzidJ5Yp4HHYS8GwA7/bQbZgkMwWiSeKrO3Ns6JtiH+u30BPPLvD/XDYFE0RH7OqAoS8TnJFk2zBIFsw6BzK8MS6formtuNiU7CkOcx3PriQ9y6q2aeCZ5AAWgghhBBvUVprckaOdDFNupBGo3EoBzZlw26zY1f2kUebstGd6mb14GrWDK5hTXQNyXySoDtI0BUk5A5hmAZbklvoTHTSk+7B1OaE23XYHIRcIXxOHzkjR6aYIVvMUjSLVHgqqPRWUuWtYnb5bJw250jqgk3Zxiyv9FbitDvRWqPRaK1x2p147B7cdjceh4cyVxk2teujDmcLBmt7EgwnC8yqLaO6zL1d0BzLFFjfm+DVjmFe7RhmZecwHdHMLm8r5HVyzJxKjplbyTFzKqnwu0hmiyRzBRLZIkGvk5lhH077jvcjXzRpHUyxtieBYWqOnVdF2O/a4frTTQJoIYQQQuxRqUKKwcwgPqcPv9OPx+4ZCea2djLLGbmRTmhD2SGGc8MoFHabHYeywpXOZCebY5tpjbfSEe8gno9jaGOX6+O2u5lfMZ8qXxXxXJwN6Q3EcjFsykZjoJGDaw6mMdBIrb+WkDtEyBWyHt0hgq7gSI7veFrrSUeK2Nny8esmckXWdCdoHUjTOpiidSBFIrstTUMpsNsUHqcdr9OOx2kjlinw2pY463sTY1p0KwMuFtWHqA26aRtMs2kgRX8iN7K8PuThoJnlnHX4TGqDHir8Lip8LoIeB7miSSpXJJErksoV8TjslHkcBDwOytxOGiq82G1j9yvgdgCeKe0rgMthY15NGfNqyqb8mukkAbQQQgghdkprTaKQGElPyBTHtlTmjTypQopUIUWykGQgM0BrrJXNsc30ZfrGrGtTNtx2N4ZpUDALu5TSUOWtojnUzIkzTyTsCeNz+vA5fPicPmzKhmEaFHUR0zQp6qKVQqGt5xFPhEWRRcwqn4XT9uanBEwUHA8mczy6ppcH/93D0xsHqS5zs7g+xH71QRbWBSkYJj3xLD3xLL2xLL3xHL2lv9P5sScH1WVuKnxWq+zWY1Yw9EgqRLZg4nXZ2a8+yAnzZ7F/Q4gKv4vXu+Os6rKm1V0xZoZ9HD+vitnVAeZUBTigMUR1cOrBrpAAWgghhHhbyBQzdCe72ZLcwlBuiHp/PbPLZ1PhqQCsAHgwO8ja6Fo2Dm8kVUiRM3Ij03Bu2Bp5IWMNSWZow0qFUFYKRLKQJGfkdlKLbcpcZbQEWziy/khaQi1UeavIFDMjQXbOyOGwOXDanDhtTlx2FxWeipHOaUF3EIWyxgYuBcG1/loCrsCbetyyBYOX2oZ4ZuMA0VSexgofM8M+ZoStxwqfc6etxlprUnmDaDJP62CKzQPWtLo7zorWKKaGxgovHz9sBtFUnlVdcR5c1TOmDJfdRnXQTW3Qw8L6IMfPr6Ym6GZG2EdzxE9TxIffvXth25Gz9q2bkLwdSAAthBBC7GVFszgSsA5lh9Boqr3VVPuq8Tv9KKXQWpMpZojlYvSme9kwvGFk6kp2jYyza2qTvJFnKDc04bYq3BU0BBroSnURzUbHLHPanLjtblx2FyF3iIgnwryKeVR4KnDZXSMd3wxt4Hf4R4ZPq/JV4XP6xpTlUA7KXGX4nX78Tv92Ize8WdL5IgOJPIOpHBG/m/pyD44Jcmu11vTGc6ztTbC2J87aniTJXAGn3YbLbsNpt9EWTfFy2zB5w8RuU5R7nQym8mPK8bvsI8F0JOAini0SzxSIZwrESlM8W8Qw9Xavm1UV4MLj53Dy4lr2qw+OCcQT2QLrepN4nXZqQ54pBepi3yEBtBBCCDEFWmuyRpZ4Lk53qpuORAedyU62JLaMtKjmjTx5M4/WGpuyjUx5I0+ykBxJb0jmkztMW9g6YkI8F6eoi9stmx2azeLIYpx2JwqFTdlw2BzU+mupD9TTEGig3F3OluQWNg1vYlNsE53JTo6rOI754fnMq5jHnPI5hNyh3eqctjsyeYN4tjBhR7a+eJZ/bhjg5fYhoqk8w+kCQ2krQAUrz1cp0BqGUnlS49IaHDbFjFKLsWlqhtJby8iPSYHYmv5QMEzyhknBMKkMuDnnqCaOml3JYS1hAm4H6XyRjmiGjmia9tLUOWTlIL/cPkzQ4yDodVLuczEz4ifkdRDyOgmV5jWFfbRU+akKbL+vo5V5nBzaVPEmHmWxN8mNVIQQQrwtJfIJNg5vpCfdA3pbzmi6kKYt0UZbrI3WeCu96V6AkXSF8Y9KKSvwzSe3C2gViipfFUFXEJfdZbXm2lwopca0ELvsLgLOAD6nj4AzQNAdHLlxRdgTBrCGJUv305vuJWfkRkaG2NoyPLt8NvWB+jcU9BqmZn1fgtc6Y5R5nKVUBe+EQ4RlCwbt0TRtg2naBlOlVlaToqkxDI3XZac66KGmzE110IPbYRtpkY1lCnQPZ3m9J87angSbB1NobXUsm10dYG51gIDbwXObBnm9JwFA0OOgOuih3Ouk3Ock6LFaZK3RKUAB5T4XVWVuqsrchP1OBhJ52qIpWgfTdETT2G2KCp+Lcp+TCp+LmWEf82rKWFBbRsU+PKKD2HfJjVSEEEJMq/50P5tjm6nx1zCjbMaYQDBTzPBa/2u82v8qWuuRwHHr6AdBtxVMBpwBhrJDrImuGRmObCg3hMfuGQlgk4UkG4Y30JPq2WFdnDYnM8tm0hxs5qj6owAwtXWb4a1B79bnWmt8Tmv83IAzQJmrjDp/HY1ljdQH6nHb3bt0HPJFq/XT57Lv0iX7gmHSPpihdTBFTyxLrmiSL1qtqSPPiyZ5w6BoaFwOG26HDbfDjkbz2pY4r7QNkchtf7ONcp8Tt8OGqcE0NYbWDKcL263nsCnspSlbMDAnaYNTCprCPhbUBjnlwHoiAReb+lOs70vwxLp+YukCS5oruPzkBSydW8miuiA2m6QwiLcGCaCFEEK8aQpmgZ5kD53JTrqSXbQn2lkbXcvr0dcZzA6OrOd1eJlbPpfmUDNt8TZWDa6a0l3UbMo2ZmzemWUzraHI8vGRznAeu4dDaw5lTvkc5pbPpS5QZ7Uko0BZQ5jV+mqx2+yTbktrTV8ix8b+JFpbw4U5bAqbTVHIm7T3mqzvHCJbuiFErmiSKz06bAqvyxpazOuy0xPLsro7zuquOBv7kxQMjVLgdznwu+2Ue7e1rFaXuXE7bAym8tYNLVJ5ehNZOocy2+XZjuay23A5rMlhUxRKgXW2YKCBedVlnHJQPYfOrODAGeVk8lYLc8eQ1XpbNDQ2m8KmwKYUVWVumiI+miJ+msI+ysfl6BqmZjCZGxk1Ilc0Kfc5R9IZKgNuvK4dH2PT1BIwi7csSeEQQoh3iLyRJ5FPjASaeSOPqU0cNsfIVDALDGWHGMoOEc1G6c/0syWxxbq5RLLT6oQ2Kh0Cxj4ff+MJh83B7NBsFoQXsDCykJZQC72pXtYNrWPd0Do2xTbRGGjkkJpDOLTmUA6qPgiv3Tvmbm8jd4DLxRjODRNyh1gUWcTc8nlkc25yRYNyr4syjwObzep8N5QulNIPUmwZztATy9ITy9Ibz5ItmDRX+phTHWB2VYD6ci+JbJFoKkc0VaA3nmVdb4I13XGGJmiF3V3VZW4W1gVZVB+k3OsklSuSzBmkckWG0nn6kzn64jn6kzkKhkmFz0XYb03VZe6RkRiaK/3Ul3vxOLYFzC67bdLWbAlWhdg9O0rhkABaCCHeYrbeLW1r/u5AZmDb0GOmgdPutAJi5SCWj9Gb6qU33bvdCAxTo4i4q2gKzaCxrIFKbyV2tX2rokIxlMkznDIIOKqocNVQ4awl4IygtB2N1aJrak0sUyCaKjCczjOUzpMpmOSLBgVDj6Q2VPhcVPhdhH0ubDZFrmiMpCj0JXK0D6Zpi6bIFrYF7EpB0OPEMDXJcWkKQY+D2pCHmqAHt8POpoEkbYPpCVt0fS47c6sDLKwLsqC2jDnVZTjtCsPUVv6vuS09wuO0b3t0WukSbocNw9RkCgaZvEGmYBD2u6gMTC3VwzpObHdjCiHE3ic50EIIsY8pmkVWD67mue7neK77OdYNrSPsCVPnr6POX0elt5KCWSBTzJAupEkVUrTGW2mLt1Ewx7aMhlzleO1BtLZRNIulG0gUcSofLsK4zQOoMULYTD8uu6s0ebChKOoiRbOAoYskMpruqJ1czoc2/OiinwQOOm2KuTVlzKkOEBy5A5mDgqFZ2TnMK+3DxDKj66SB7tK0Pafd6uxV4XPhcdlx2214nDbKPA7SOYP1fUmGUlaAbWrrLmXuUopC2O+iKeJn6dxKmir9+Jx2YpkCw5kCsXQepaxRGZrCPmZGfDRWePG5tv93ly+atEdTdMeyhLzOkdbeidbdHbs7Zq9SCrvEzkLs06QFWggh3oDORCdPdD7B4x2P05noxGFzlEZwsKO0E5v2gumhWHRjGDZsjjTanqKgk0RzPaSLKQAqXS2EbLPI6yQZc5CUMUDGHMaGAxtuMF1o043fVk2dr4m54dksqpxD/5CHFzcVeGlzgrxhblc/pbCCw9LIBA6bjVyxlK9bNDG1xmFTOO22kREM5tdaoxYsqA3ic9tZM+ouZq0DqZFb+uaLJkrB3OoAB8+o4JCmcvarD+Fx2q2hx7Byaa3n1qPNpgh5nfin2IHONHVpGDOJKIUQe5+0QAshREneyNOb6sXEHAl480XF5mgvm4Y6aY9305XsIVkYImPEyZhxMkYcU4MyPWjTQ7HgJqe6ydu3AOBXDfiYyXC+QDqfJ28WUaqAsifAlsVmz6KUgVH0ow2fNRX3x0jNwkjPImEEcDtsaM2oQNikzOOissxNdZmHcp+TjqE0/96UZEXBBJJAknk1Ac45qonj5lXTWOHdlhfrsOF3Od5wKsDsqgD/cUD99sexFIB7nJN3xnsjJG9XCLEvkgBaCPGWk8gWGEjmyRUNCkVNrmgwnI0Tz+aIZ4rEswVi2Sy96W4Gsl0M5XtImX0U1AAF2wAFhkBNfvVNazWSwqANP9oIAeB05nA4YtjsOZwqRCh/JvbsYvLZMMqmmF/ho7HOS0OFl8YKK32gsdxLZcCNzabI5A22DGfYMpxhOJ2nqsy6dW910EOgdMlfayvPdmvqwnimqekcyrB5MMWc6gAN5d43/yBPwUR1E0KIdwIJoIUQe51panriWVoHU7QNWnf4iibzI3cHyxdNDFOXWk41hhomYfTTl7Jue5wzkyhHHOWKYnNGsbmiKNskoyXYwKHKcelKfMZ87GYEuxnB53Lhd4PfrfC6oNofZkawntkVDcwO1+FzudFalzrAWTeBmGxYrqnwuuzMqQ4wpzqww3WUUjgmSYK12RQzI1Z+rxBCiL1PAmghxKR6YtZtdgE8ThsehzXagGHq0g0hNHnDIJYuEE0XRjp+lXkc1Ie81Jd7qQt52BKL8XJnB6t6u9kU7SVbzKO1A7QNh81J0KexO5MoexwccQzbMAXdR9HWDxTBBpRZkxtwKjcRdx0RzyyqvcdQ6anB73LhcVpj7/qcTurL6mkMWDe78Dg803gUhRBCvJ1IAC3EO9xQKp+hB1YAACAASURBVE9PPIvHacfvsuNzO0jnizz07x7uW9nNi21RptrXWCkIem2EfHmSuoOk2ojd24HN04nNYXWWww2qDsYnHWRHPQ84A9T7apgZXMDMspOYGZxJfaCeCk8FFe4Kyt3leB1e6VgmhBBiWkgALcQ7QNEw6RjKsLEvyaaBJBv7UtZjf4poKr/D182pdnP+CREOaXGRN5MMZoeIZoYYzsVIF+OkizFSRpxUIU6yECNeiJHIJxgqvd6DYkaghRm+Y5kZbGJuZQ1VvkoqPBW4bC4KZoGCWaBoFnHanFR5q6j0VeJ1TE9OrxBCCDEVEkAL8RaULRh0DqVLd1pL0126w1pfPEdfIksiW8TUYJZuXJHKFSkY25qRKwMuZlUFOGlRFbXhAk73MF3pVrrSbfRmWhkudlPQCXqNDHd2w50TDOXrdXipcFcQcocIe8uZVTGTcnc55e5yQu4Qs8tnsziymIBrx7m+QgghxFuRBNBC7EPS+SKtA2l6E1kGEjkGU/ltj8kc/aOej06rcDtsVAetoc7m1ZQR8jpRSpPWPSTNdvK2AbyeHE5nBq0yJApD9KR7eDDVj5E0RsrxOry0hFrYP7iEiDcyEhCPDowrPFYKhcvumoYjJIQQQkw/CaCF2Iu01vTGc3QMpekqDWXWNZxh80CKTf3WHdHG8zrtVJa5iPjdNFZ4OWhGObUhDzPDXry+OH2FfxMr9JIuWneqSxfSdKR6WD+8nkwxM1KOJ+Mh6A4SdAWp8FRwWM1h1PprqfXXUuevY1b5LOr8ddiUDE0mhBBCTEYCaCH2oFzRoCOa4cXWKC9sjvL8pkG6xgXJIa+T5oiPI2dFmFXpZ1ZVgLpyD5V+N5VlLkyy9KZ7iWajDGYHiWairB5czd83vUB3ysqtsCkbfocfn9OHz+mj0lvJGXPPYH54PvMr5tMcapa8YiGEEOJNIgG0ELspWzB4fnOUf3UMk8wXSecM0nmDRLZATzxL13CWgWRuZP3KgIsjWiKc31xBS1WAhnIPdSEvfreDollkKDvEQGaA/sx6Xhlaz5rNa1g9uJqORMd22w65QxxeezifWfwZDq89nFmhWTIihRBCCLGXSAAtxCSSuSKb+1Pkigb5oknOMOmMplm+tp9nNg6SKVj5w26HDZ/Ljs/lIOB2UBPysKguSF3IuiPdwTPLmVXppyfVw78G/sXrsVYe7munI9FBR6KDwcwg1u06tmkINLAosojT5pzGjLIZhD1hwp4wFZ4Kwp6wpFoIIYQQ00QCaCHGGUrleXRNLw+t6uHJ9QPki+Z268wIe/nokkaOX1DNkS2R7e5OZ2qTvnQfrfFWNg5v5MbVK3m572V6070j69T4apgZnMmxjcdS46sh4olQ6a0k4o3QEmoh5A7t8X0VQgghxK6TAFq84xmm5t9bYjy1vp+n1g+wom0Iw9TUhzx88oiZHNESweey43LYcDtshP0uZoZ9KKWI5WKsj62iNd5Ka6yVtngbbfE22hPtYzrwVfuqOaT6EA6uPpiDqg9iVmiW3BlPCCGEeIuSAFq8YxQMk86hDK2DKdoGUrQOpmkdTPFK+zCxTAGARXVBzj92FifvV8sBjaGRvOKCUWDt0FpW9q9kTfuakUB5KDc0Ur5d2WkINNAUbOLwusNpDjbTFGyiOdhMta9acpSFEEKItwkJoMXbUq5o8OLmIZ5c38/rPQnaBlN0DmUwzG15xn6XneZKP+9dVMPSuZUcPaeScp+d9ng7bfFXuHV1O+3xdtYNrWP14GrypnXHvojHSrE4ceaJtIRaaAo20RRsojHQiNPunK5dFkIIIcReIgG0eFvQWrOxP8VzmwZ5Yl0/T28YIJ03cNltzKsNsH9DiFMOqKcp4qOl0k9TxE9lwIVSioHMAE9veZprX3qKZ7Y8Q6KQGCk35A4xKzSLsxacxQFVB3BA1QHU+muncU+FEEIIMd0kgBZvOVpr+pM5NvQlWdeT4MW2IZ7fFB0ZMq6h3MuHD2ng+HnVHDUngs/lwNQmsVyMgcwA7fF1/GnTejYOb2TD8AY2DG8AoMpbxXub38uSmiUjrcrSkU8IIYQQ40kALd4SNvQleWhVD8vX9rG2J0E8WxxZVhfycMycCEfMinBES5iWSj+JQoKHWx/mS48/QGu8lWgmSlEXx5TZEGhgbvlcTm4+maWNS1kQXiBDwwkhhBBipySAFvukgmGysmOYx9f28dCqXjb0JQE4oDHEKQfWM6c6MDLVBj3kzTydiU7WDz/N9aseZnnHcvJmnuZgM0fXH03EWxoizhOhsayRWaFZ+Jy+ad5LIYQQQrwVSQAt9hl9iSwPrerlqXX9PLtxkESuiE3BES0RPn1kEyftV0NdyLoddSKf4JG2R7jjxYfZOLyR3lTvyI1IKtwVnDnvTE6dfSqLIotk9AshhBBCvKkkgBbTKpM3eHh1D395ZQtPrR/AMDUN5V7+48B6jp1byVGzK/F7FMO5YQYz7axq6+DB1gdZ3rGcnJGjKdjEYTWHMSM4g5llM5lZNpMFkQU4bTIahhBCCCH2DAmgxV6XyBZ4Yl0/j6zu5bE1fSRzRepDHr5w3CxOO6iBOdUBNsU2sWzt7/jv+x/Z7jbXFe4KPjz3w5wy6xQWVy6WFmYhhBBC7FUSQIu9oi+R5dHVfTy8uodnNgySN0zCfhcf2L+W0w9u5IiWMHkzx/LO5Vzz8B94sedFnDbnyFjLEU+EsCdMla+KxZWLpYVZCCGEENNGAmixx3QOpblvZTcPr+7h1Y5htIaZYR9nv6uJk/ar5dCmCqLZAZ7ofJwvP/4Ez3U/R9bI0hBo4CuHfIXT555O2BOe7t0QQgghhBhDAmjxpjJNzRPr+7n92Tb+sbYPrWH/hhCXvGceJ+1Xy9xqP2uH1rK8cxnX/f0JVg2uAqDeX8/pc0/nhBkncETdETKcnBBCCCH2WRJAizdFRzTNvSu7WPZiB+3RNJUBNxefMIePHTaDxgofPakelq29mYv/eT89qR4Uiv2r9uc/D/5PjptxHHPL50ousxBCCCHeEiSAFrstmspz38ou/vbqFl5uHwbg8JYwX3vffN63Xy0uh42V/Sv5+RN38EjbI5iYHNtwLBceeCFLG5dS6a2c5j0QQgghhNh1EkCLXZbIFrjpqc385qlNpPMGC2rLuPzkBZxyYB2NFT4GMgMsW3cH9268l9ejr1PmLOOTCz/JWQvPoiHQMN3VF0IIIYR4QySAFlOWKxrc+Xw7v/jHBqKpPB88oI4vnTiHBbVBTG3yRMcTXPPyH3l6y9MY2mC/yH58+4hvc+rsU+Wuf0IIIYR425AAWuxUMlfk7hfaufmfm+mKZXnXrAjfeP8CDpxRTsEscN/G+7j53zezYXgD1b5qzt3vXE6ZfQqzy2dPd9V3LjVgPfr3YjrJ4EYonwn2d+ZQfLpQoOfq76GcDqovuwybb/uTKyOZwkylcNZUT0MNhRBCiMlJAC12qCeW5XfPbObO59tJZIsc3hLmmjMO4Ni5leSMHHeuuZNbVt1CV6qLuRVzuXbptbyv+X04bG+Rj9Xqe+Hei8EownFfhyMvBIdr8tf0/Bs2P2GtuzudHl++Fe79EgQb4YgL4JCzwVs+6Uu01m+bDpbaMOi6/BvE//53UIrU8y/QcN11eObPG1k+/Kc/0X/dTzFiMQLHH0/43HPxHX7YXj0GulBg8Lc341m4gMBxx+2VbeY7tzD8x3uInHce9rKyvbJNIYQQu0dprXe+1j5kyZIlesWKFdNdjbe17liGGx7fyLIXOyiaJu/fv47PL53FQTPKiefjLHt9GbevuZ1oNspBVQfxuf0/x7GNx+57QV4hCzedAA4PvOsiWPQhq9W3kIWHvwMv3gT1B0OgFtY9AJE58P4fwZz3TFxeLgG/OgqG2+Fjt8PCUzCSSTKvvIr/mKN3vv+bn4LbToPGw8Fmh9anwBWAgz8FB3wM6g4C29jh+9IvvUTX1y/Hs//+1F97DTaPZ9ePQ3SzVedZeycQ3BFtmnR/+zvE/vIXqi+7FM9++7Hla1/HTCSo+fa38MybR8/3vk921Sq8Sw7Fd8ihDN9zD8bQEO5FCyk/80w88+bham7GHonssc+bmUrR+dWvknryKQDC55xN9aWXolw7Obl6A4x4nNazPkF+40a8Bx/MzN/chM3v32PbE3vY5iehetHevbI13QY3Qj4JdQdOd02EeFMppV7SWi/Zbr4E0GKrnliWG5Zv4O4XOjC15iNLZvDF42YzM2J1DLxt9W38Ye0fSBaSHN1wNJ9b/DkOrTl03wuct3ruVxh/+yamtxGH0YEKNcCSz8Dqv0HPa/Cui+Hd37Vandc/gnn/1+lfPkDR3ULV/7sVV1Pz2PLu+wq89HsI1oPdhb7weTq/fAnJf/yD2u9dTcVHPrLjugxuhJtOhLJaOO9h8ISgeyU8ewP8+49gFsFfDfNOgnkno+ecxOBvf0//L36BIxKh2N+P96CDaLzhehwVFWOKLna1UujsBG9oZJ4jEsFZXw8rl8H9X4VCCk75GRx67i4dQiOZIvbnPxN/6CEc4Qpczc3W1NKC94ADUI6pXW3QWtNz9dUM33U3lRdfTNXFF1l1Hxig6+uXk3rmGave1dVUf/3rBD/4AZRSmNkssXvvJXrLreQ3bhwpzxYI4DvsMBp+et3EJxVaQ3QT+MLgrdh++Q4UBwfpuOALZFevpubb3yLf2sbQbbfhWbyYhut+gmvmTKv4QoF8Zyf51lbyrW3WY1sbjuoqqr/8ZZwNU+8sqwsFOi74AqkXXyTy2c8yeNNN+A47jBk3/nrMviUef5yhO+/Cd+ihlH/so9t9Dt6yYp3gDYPrbdBPQmt47Gr453XWCftHb53uGu0d0c3wm3dbjRMXvwChxumu0b4pNQh/uwgO+AgsPmO6ayOmSAJosUOmqbnl2VZ+9ODrFA3NR5Y0cuHxc5gR9tGZ6OT3q37PX9b/haIu8t6m93Le4vNYGFk43dWeXD5F9rsH0vZ/Lsy8RrmcuEIKlzuGf4ad0Feuw3bgh0ZWz23ezJZLLiG35nWUXYOyEzn/AiLnn28FMRseg9s/DEd9CWYdD7efwXDgbLp/8yj2qkrMeILmPyzDM3/+9nVJR+E374HsMHzuMQi3jF2eGoQNj8K6B2HDYxRjCbr+NYfUpiTBD3yA2quvIvX0M3R97Ws4GxqYcdNNuBobyK1fz+D/3kD87w+ije03667xEwj3EDh4Dt6mCtTmx+H0G+HAj+308BW6uojefgfD99yDmUjgXrgQnc+Tb2+HQgEAZ309FWd/mvIzz8QeCOywLG2a9F57LUO33kbk85+j6pJLxpx0adMkeuutmPE44c+ehz2wfcur1prC1oB1cyu59esYvuePVF1yCZXnf37sykaR4rKLGFz2dxweE1elF9fMGTjnLcb2nu9AWc2E9cy3tdH++fMp9vXRcN11lJ14AgCJRx+l61vfBsPAu+RQCq1t5Ds7wdh20G2hEK6mJnLr14NpEjn/80TOO2+nVwy01vRcdRXDdy+j7gc/oPyMDxO77z66vn45/mOOofH6X1Ls6qLnmmtIPfEk9kgEY3AQ5fEQOv00wmefjbulZdJt7NM6X4KbTwKbA1qOs04g574PymdMd812XTEP9/0nrLzLStFK9sAlayDwNs/jzwzDb0+CZC8UczD3PdYVOrG9v10Er5SOzSHnwMnXvj1OHN/mJIAWE2ofTPO1P67k+c1RTphfxdUfWsyMsI++dB8/e/ln/N+m/8OmbJw6+1Q+s/gzNAWb3vxKaA3tz8Fz10PHi3DkF0r5yO7dLrJ4//fYfMWt4Kui8qIvkW/vIN/aSm7tGgpdPdhDIco/9jEqPvlJ0i88T893r0Q5ndRdew2exD/p++VviLf7cNbXU/O1r1C25nIr3eKCJ8HpoXDDqWz61Trc+x1I4y9+yeYPn4HN76f5zt9hb38cjBxaa6IPvMjgX57AXZYlcNrZlJ1+Dq7mZgq9fSSffILk8idIPfssOp0eU39l19R85BDKv3vHSLCZXrGCjgsvQrldeObNJ/X00ygHhGYVCBy1BNqeBiMHNfuT7x4kuS5OesADpsZZX0f9u234ii/BmTfDfqdP/FYYBgM33sjA9TcAEDxxKeEPHIm31g5mEW2YFAbjZDd1M/TIK6Rf78DmcVF+4kGEv3Q5zpZFY8vL5+n69neI33eflQrxjW9M7YrFwHrIxqBxu9+sER0XXUz6ueeY/dCDOCpLl8rzKfQfzqXzdy+S3OLd+XbGsVdUMOPXv8J74NjL0IUtW+i+8iqKvb24Wlq2tcQ3N+Fqbh5pDS50d9P73/9N4oEHcTY2UvXlLxM44fgdnmBEb72N3h/+kMjnzqP6sstG5g//8Y90f+e/cC9cSH7DBpTLReXFFxP+1CfJbdpM9NZbiN97H7pQwFFba9WlqQlXoIhhusl3R8m3Wlcm/EcfTd1VV2IvH5drn0/Bsk+BUYCP3AL+yJjFxvAw3Vd8l+za16m/9lp8Bx885eOYb2sjuXw5ieXLya5aTdkJxxM+5xw8i0Z9PgpZuHGpVY+Fp1gnkEOt1rLjvwXHXz61jfWvhVgHNB0Nzl1/z8cbuvtuBq6/gboffJ/AscdO7UW5BCz7NGx6HE74Niw6Da4/DN5zFRzzlclf2/kSPPRN8EXg43fuXt+KdBTan4V5J1vpYbuqfy3c9XE4/ALr93eqjCLccaaVjvbpv0LH8/CP78En7rFOhvamTcut/iVzT4KTfwT2XeyLk+iFv10IQ23wvh/AvPdNvr7W0LcGEt0w+8Sdv29tz8LvToYjL7L+t/3zOqhaCB/5PVQv2LW6vpXlEnD3J8Dutq7QTOUEom+NddV48Rm79/l+g6YlgFZKnQz8DLADv9FaXztu+UzgFqC8tM43tNZ/n6xMCaDfHKapueOFdq75+xrsSvFfpyziI4c2UtRF7lxzJze8egNFs8jHF3ycsxedTY1/4la7N6SQhdfvh2evh66XrUvt1ftB2z+tfOSTf2S1ZmyVT0GiBypatssVHrNvQz20nXIsuZiD5mV/HPNPW2tN5uWXif7+FhKPPmqVU2pZbPjxj3HW1lorLr+W1LKf0LummVxPkvI5aWp+cTe2lnehtabjnE+QfullZl3+HlxnX0/qhRdoP/dcgrMV9Yd0YuRtdD9fTrLLg686j+FqINfZD4Cjqopif+l5fR2BpcduCwABbIqg9zXc7Xdtl3aR27CB9vPPR+dyhOcmKZ85iOPzf4EZh1n/RF/6Pbzwv6BNOP1GjOolpJ56ir6f/g+Fri6qjikjUr8O9cH/Z/2ADW6wpvgWCokiXQ/ESHfkCc53Ub3fAE5XctK3MBN1El3rJ97uxeaAytOPJvytX6A8Poxkks4vfYn0s89R9dWvEjn/89uC53zKCtzGd6DMxmD5tfD8jdY/pE//FVqWTrjt3ObNbDrlVMo//GHqrr4Kkv1w50eJPfM6Xc+VU/21yyj/6EdHUiwKr/4D/eofoGq+FeCM/4dntxE65RRcM6bY+pmNgbKBe/sOf6nnnqf3B98nt34DOJ34D1tCYOkxuGfNoDCQKKV+bCbx2D8InHgCjT//OWrcZzp6+x30/vCHhE45herLLsVRVTVmeXFggNjf/kZu3Try61eT27QRM6tBaVxVIZzzD8BRWUXs/vtxVFXS8OOf4DukFAQXMmSu+xBDy9eCslGxpBzvV/8CFc0ApF9+hS2XXUqxfwBHOExxYIDqr36F8Gc/u109tzLicYZ//h2GH3iS/GAOANfs2XgWLCD5+OOY6TS+ww8nfO45BJYuRT1+FTzzC/jUn2HOu9GGQfK+uxn+3S8h2Y3riP/AddCxVs57MDhmW87GRuw+n3XS/eiVVgqUw2tdHZr3PljwwV1u+dVa0/8/P2PwxhtRXi+YJjNu/DX+I4/c0Qug/3Ur8H/1TitN69SfW30aAH73ASu4uviliX+vkv3w2FXwym2Y2oMu5LCffz80HzP1SpsGvHIbPHoVZKLQdAyccROp1e0M/vZmKj7+MQInnoja8Bg8/2ur4/Lc944tY3CjVddkD9iccMETULPfuO2Y8ODlkBmyrhDMebf1e/1/l8KK38Kpv7A6RBfz8OujrZboC5/bO62rRhGeuBae/LH1nid7Yd77rYaCqW5/4z/gz+dDLgnBOiv9a+774ORrIFIaTUpr6ze262XrPV/3kHXiBnDgWXDKz3fcCd0owI3HWsHjRc+Dy29d1fzLBdY2q8dd0Q3UWNuNzLGmhkOs10wkGwe0lRY4EdOwfqt84akdi4kMrLcC2OhG6/OS6LZOBHb1JCmftk642p+z/kfNPgHOunvnjWV3fcI6Sfvyyje2H7tprwfQSik7sA54L9AJvAicpbVePWqd/wVe0Vr/Sim1CPi71rp5snIlgH7jXmqLcuW9q3ltS4ylcyu59owDaCj38mLPi/zw+R+yYXgDSxuW8s3Dv8mM4Jt8KTXRA+sftn58Nj5u5eZG5sCRX7R+hFx+WP8oPPB168vacuy2fNb4FquMyvnwrgutjnfjWpy0abLlU+8n8XIbjd/7GmUfOW+HVcm3tzO0bBmOcJjwOeeMzefVGh69Ev3k/9D3WpDo6wHc8+fT8NOfkn5pBT3/dQU1py0k7HvC+kex8XEGrvs+/Sv9hE87kfgz/8IYilH9nxdQ8cmzUL4w+c5OksufIPPyy7gXWKM7uOft4BbmRhHu/Kg14sen/jymA6A53IO648OooU3wqT9B89FjX2saVmA3qlwjkaD7iitIPPAg/mY39Qe14fCY1qXzihaSgxV03deNmTepfV8doUOqUOEWCM+y3p+K5kl/5PLrVtFz5bdJbUjgqrBRdcFnGPjr0+Q2bKDu+9+j/LTTtq289gH46xetH/UZR267bN/9KjxyhTW04KHnWD+yyV4r7SUy8ZCIPT/8IUO330HLf38Rz6bfUujpYdNDdbjnLaDp9ttQ9nGtFc/8Eh7+Niy9FN59xQ73Z1J9r8NzN8DKu63WkIM+AUd8ESrnjFlNGwaZV14h+cgDJB7+O/nu4W0LHXZcM5vwHnAAtVf814RD+QGY2ezkaSDpqJVz+9LvwV+JcdhXsHU9i1p3v3Wi+f4fkck1sOWSS6wTqC9/GXdLE9Eff5N0WxqbxwU2G2Y6i69WE77oMnLDViDprKuj4afX4Wpupvs7/0XioYfwL11K/Y+uxRHe9k8s39nJ0K+vY/hvD2IWNN4ag2BDksBsH653fw6WnIdhuhm+549Eb7+dYnc3Nr+XQCRK4KjD8V3wM5LLl1t57q2tOKqrsRsD5IcNtDFxq57N5yW02Ee4ejWuJe+Hgz8NGx+zApvhdnCVwak/Q8///+zdd3Rc1fX28e+Zqi65F7ljm96N6WCKARM6gQCht4SEkECoPxKSEELoJCTwEgiYGnozvZtusGk2prn3ot6mzz3vH0eyZVs2kq3RGM/zWcsLZnQ12hpJM8/dd99zj6Dh9ddJLFpE6RFHrrksorUw+23svE9Y8koVdRNeoOy44+j12wuYf8YZJBYuYtA9/6Vgp51WfEr8u+nU3/lHCvzfUVC40P2Z9d0ODvzTqicgT30cnj4HTp2w5gm8Xz4GL12CTTRRa8dR8cpMiNbS74hyiv/65prf8JKp8NVT7u+wJVTVLYSXLnZ/N4P3hM3HYd+8loqviqiaGsQEAthkksLhxfQZOZNwNz+kE7DHBe533x90z9X4Q90O7fEPwBOnu3M8znlr1WU2X/8TfPAPF9Jadhx7bw3LprnHO+ivK7ed8x7cfxjsfTEc8Me1/+6u/nOY96ELsgNHu9f99hxNqFsET50N8z90Oy7jbnAjNC9dAv13gpMeW+VEzvpXXsVfVrpypyidgonXwnu3uB3rn453z+3Hd8I717vna8RB7n2raqYbwwMIFsCw/dxrV90iePcGd/tnD7a5Q80H/3SvbSf8z+3ctWhYCm/+1b3OrXguPBdQq2a5I4rgnvedT3dHCEqbz6+omuXq/PxhFyrPfnPN8TQvDY+c6N5Hjr0HtjxszdoqvnfnBe12HoTbOFL28X/c+3GLknL3869fBIfd2v7zapIxd5Rj9kQ49r+QjLpVsDY/1P3urW1Z14Wfwn/3d0d29r207W0yLBsBenfgz9bag5tvXwFgrf17q23+A8y21l7fvP3N1to91vW4CtDrb0ldlOte/pbnvlhMn5IwV4zbkiO278ekpZP477T/MnnpZPoX9uey0Zex38D9Ov/kwE/udi/44GYERx4MWxwKw/YHn4/6V15lyR//iI3F3DY2DXgESwOE+pQSHtifUHlfQvWfEEp+h797N8wuZ8F2PyOd15fE3HnUPfkoNY8+Se+DBtLjttc2rF5r3eHIJVNp7H8ei//vD3iJBAbI23ZbBv3resy/d3YhKlaLHX4QC17Pp+njyQQHD6L8llvI33rrH/wyaxWrc7OFLXv7NXPdi3jFd5CKwUmPukOH7f52LLWPPc6yv/8dm0w0h0v3M7bJJOERIyi/9RbCw4ev+4HWoeGhm1l2239J1oMvZCi/8pcUHXe+68ClEq5bOOl2FzhGHOR2ppZOXfkAA3aBQ290q6O0nJiU3w3Oen3VzkPdIpj2OOkvX2Lmf+aT3y3BwCPyWPDl9kSmfsewZ58hNGRIW08CPP9b+Ox+OOpO9zs46y0XvGa95TpErRX2XtkJ6jbEvRHNfMOt7LL9Ce4NeNrjrsM08hD35thyiNFad0h76mOQipHosS8J24/Q8tcJ+qow/beFbX4KjctXHgmIVrswNPJg9/wU94X6JTDjVfj+NdeFScVW1uel3M9w11+6kYeWLtSst+Dly6Dye+izDemB+7Pk+fk0vPMJAIGCFN2PGkvZhdcDUHvf/6P6/vGkmg84FI/ZnX7XXoe/e+/mb8VS+9hjLLv279hUapUdE5tMgrGUDPPofuY55B99Ecx93x1ZmvGqO9KxJxTatAAAIABJREFU3fGw+6+x3YbT+NZrNPy/y2iclyYdXfmt5G2zDd3POJ2Sgw7C1M7B3jmGVNHWxEf9ES/WHCQssPhLGp+8h7pZFjAUH3AgJUccTnjYMIIDB+KrmUH6qd9R++7XVM/rQ6q2+fkKBik99FC6n34aeSOGYac+TuqN20nMmUXVN0U0Lc2j5/m/ouevz8cYQ6qignmnnEqqooJB4+/Fa2ykavy9NL33wYqawwN7uZp/ejK+UAgvEiExbx6JefPx5YcIvXYGwe3GYH5238pvdN6HcN9hRAPbs3RKMbFvZpC/8854FfOIz6+k+zEH0/vPN6xc9SXe2Lz6z7w1f5+L+8FB18A2x5JctoxFv/010S+/pnRohD7H70rdG5OomFqA5/npcerJ9By+BN+0+6F8FBx8reuARqrh9Ofd6hnfPO/GesZcAWMud1/j84fc7O6oM+HQm1d2YGe8Br22gKP+35qH1Z/+hQv8533ggunapJMw/Rn46N/upOoWgXy30zH8QOi7rfv7K+jhmgJNlTDjdfe7NeN1t/1ht7rfsRbfvABPneXC3ilPQ7chNH34IfPPOhsTDDLo/vvcSNITp7uv3xK+W3d565e4IwTzPnA7oy07Lr23gEF7QLDVju3nD8GEC6DPVvDzJ93fbYvaBXD7aDfjf9Kja38uVud5UL/Q7bB/8TB8M8EF162Ocq8B377oGiBbHeGaEr23gtNfWHXH45Ur3M5+2SC3w3XojbDL2Ss//sX/3FGEZMStAvXzJ1Y9cjNlPLzwO9jiMPc70X2Y6+rHG91zN/N12Pcy97F15YVUAh4/xf3eHHkH7Phzd39LJtjqKBfw2xq7eeAo9x7x2y/b3jnpAtkI0D8FDrHWnt18+xRgV2vt+a226Qe8BnQDCoEDrbWfrutxFaDXz3NfLOLyp6aRtpZf7DOMX+wzjE+Wv8ddU+9ietV0euf35rStT+O4zY8jP7Dhc4RriDfCP7Z1L7iH3ugOEbb6g4vPmcPcY39KcPBgivZaeQjTJhIkFrmTx5Lz5rs362a+kI9gQZxUzEc6tvIFvGyzCH3Hv4bpvY4X7vWQXLqUxRdfQmzGDIY+9RShAeUuJLx+FRz4Z9jt16Tq6qh/4UVKjz5qnSfWtVvNXLjnYHd4tbh/c5jbzHXfB69zX3OtYt9/79ZhTnsr7vOXldHt5yet3zJ5q/Ea66j7xyXkR98lL7jEHTHY5SzXGVr8ueuiHPTXlR3tukXuhThc4l5IWx/unvcRPHAEDNwVTnnGHUacdId70/NS0Hc7qhcOZtmTn1Jy+OHUP/88ff7v/+h+6ilrLzCddCeEzv0AsK7jU9DTHdpu/cZnvZWdp6qZboemsDeMPteFiZaZ4YZlMPm/7l+0etWv1RK0d/vVyiCRjLpQ/dEdUPmdCws9hkOPYa5zOnuie+MEKB0EdfNX/v/w/VddVcQXgK2PcW/cq0sl3I7C9Gdg/iSsl6ZxaQk2laD4zD9h9vzVKpvb6oU0XHs01M6nuDzmdqBLB7q/1RFjYeTBxJZG3O9OwzJY9BlUfIsvmKb0qGMIHnX1miM5Fd/Dx/8PvngEUlG3wxcuhq+fw54ygVikO5FPPiF/hx3I32mnVXfaWzq4e/8e9r3cfR+TbndBq/swkmNuoeaNL6h57DG8urrm58NHsH9/0tXVbmSkd5zuo7sTPvxCqp95jdq3P8PGUwRLLKmIxaaaf9f8PvrtXEXZoQe4mdTmblhy6VLmnXwKycWLwfPwFwboNrSasnMvp6mhnOr77iM+Ywb+7t0xwSCpZctYnfFZgkOG4i/r7n73lk7DWkNsucXfqyd9Lr2UksMOwzbWsPzUXan5JkDe1lvT79prCY8Yjnn5Eph8jwtHZYOhaibphdNJLK4kkb8NiYXLSMydS9N77+Elk/T7wxWUhj6AKffCNj8ltfOFLL/rf9Q98wyBPn3ofdIYSqruwSTq3XkdpzzrRsBaPHUOTH/adTQTjfDAUdjBe5Iaezv+nr3xtWc5x8YK+PfO0HMknPR424fdpz8Dr/wfNCyGniOxu55Huu+++GNzMDNeaz6a0GqnIVzq/j4rvwesG3MYMRb2vHDF0R+vqQmTn+/GjOZ/7I7idR9G8shHmHPMT/GXlWFTSbzGJobcdCGhV890AXC///vh7+mHzHgdHj8N8kpgswNW7nh//pDb8f31xy7Irq+aea4b/Flzt3bUmTD6HPectOz4bH2MG10xxv3OvHiRe+3Z/w/wxBlup2Pv38NeF8KLF8PUR2HI3u7o70sXQ2Evd8Sz53B3hO2ZX7rn+GcPrzmekk66cP35Q24H5LB/rL2L/Mx58OX/4Cc3rxrgwY1xvfYH2O6E5p2xVq//c9+H+37idhL3+M36P3cbKBsB+jjg4NUC9Ghr7W9abXNRcw03N3eg7wG2sdZ6qz3WucC5AIMGDdp53rw29sSlTam0x/WvfMvd781h9JDu3Hz89vQsMVwz6RomzJrAwOKBnLXNWRy+2eGE/Jlb53bFH8lZr7tDdK14sRhzTziR1NKlDH3maYL9+rX5EDadJrlkCYk5c1csG5acMwO/v5FQoIJQchbhoiihvY/DHHNnRr4Nay02Gl31kHsiktlZv1TcvVi1dXhtY5ZKrOwuLZ3quqNH3u5OGOuILx91nbKSAS5YhordvOWu50K3IdhEglmHH05y3nwKRo9m0H3j1zqnu0K0Bl661HWVRx7sDveu63OsdZ8TKlr7nGMq7o4WtJbf3b2htsXzIFLlOmutv7a1sPxrFyAWfeZOpBxxsJuTXN+jQpFq15We8bp7vNHntL1dOgnLpjfvNMxy/134ycqT+/ps636O8953h7F3PNl1v9cyYrNCUxV8eq/rODUuc58z7vofrnvCBW4noKiP+7yeI92a7q3Gt7xYjPiMGassKWjy8+h+0knkhZa4352miuZvL0Dt4v5EqgsJbrEToe32Ijx0COERIwjMesrN+W5zLBxz94quamLhIipuvonCvO8pCbyP77Ab3e8e7vWg6cMPqXvqKUwovPLE0kGD8JqaiE/7iMSEG0nkb4sX7uN2AGM10H8n8kftQY9zz1l1R/udG6h/8GaWfDEQr7HJrR6UHyE0ZDC+4buRnDef+Ly5pCsqV36OMQT79SO8xRb0vuTilauyxOpWmYuNfvHFinXWC3bclj57B8k77DcwaLUZ72gNqZt3o252HtHFERKNIRKNIWwsRqBvX/pcegnF48b98BHKr552z31hL9ddHLy7uz8ZdZ3RT8dD/53w9ryE+m+iVD/wAPHvvyfYvz9FY8ZQNGZfCkb2xdcwf+VObN1C6L+D+5vtuz34fO68ls+/oPq++2h44w3yt92W/jff7Boc057EPnEW86eNJjq3iqFPPA4+P3NPOIFgsInBR4D/oimrdpM3xKLP3FG2iu9c06PFgX92obUzJGOuE73669D7t7qvve/l7mf60LFuVv3E5lGzdMoF6s/udzsjiQa387DPJe7jCz+F/x3nXn92/aWbKx+yt9sBWtvzYy1M/Lsbd9nnUtj/yjW3Wf4t3LEr7PlbGHt124/zzo3w9jVuZZLD/+le56yF8ePckcjfftEpJwivr411hGM6rku9oPn2bGA3a+3ytT2uOtDtV9OU4DePfM77Mys5dffB/PGwrVjStJALJ17IjJoZ/HL7X3Lududm/sqByRj8czvXgTvt+TU+vORPf6b2sccY+J87N+yqb4kmWDgZynfO2qEeaYO1bk6zuP9al5D7Qe/c6Lq2o85w866rhdLGDz6g4uZbKL/tn4QGaA3aTmWtO4mo5cSphiWw0ylu9rEDa2wDbidj/kfuEPgPXfUTXNh6+DjXad/9166z90M7R6trqnRHProNcR3cdX3dlhCy7XFuJKfFdy+79drHXu2CQEfcc5DbUdrhJDev/pNb3BGZtkRr4NZtSfbZl8bwWBITbiBR7yPBQNKNjW6lleaVX0JDhhAeMoTgoEH4wu1bscim09Q++RQVt95KuqGBwl1HU7TvvhSNGeOWYZw1i+r7H6Du2WewiSTBYo/wtrsSGrEVwfL+1D77LPGvv6Fg9Gj6/OFKwpttRmzaNBomTqTxnXfxhcP0vuRiCnbe2X3BxZ+7zmftfNfl3eIwePJMWD6dxMizqKsaSs2jj5GuqiK8+eaUjDuE6NRpbmWiaBQTDrda9WYwoYGDMHkrv1evsYnap54iNnUqvtJSSg45hPoXXwSfj35/u4aSAw+k4uy9qPygmn5/upyyE08DoOnBvzL/2ocp3GEkAx98ut3r2XdIvMHthDYud0F2PVePiE77ikCvnitPcF8ba92ozRcPu53bbkPgzFdXfa201p1sOe0J1w1e/QTtqlkueNfMcX+jJz+59pMXW3v8VHdO0++mrXkU6rnzYdqTcOH0NVb6WcWbV8N7N7sjlOOudydZPnwsHHrT2nf4u0g2AnQAdxLhAcAi3EmEJ1lrp7fa5mXgMWvtfcaYLYE3gXK7jqIUoNtnytxqLnz8C5bVxbnmqG04fpeBvDn/Tf7w/h/w+/xct/d17FXegbO92yOddH+gq79Btcw5nfa8OzmklboXXmTxxRfT45yz6f3733duPSIiHTXxOtdVW11HltZr7Yv/uZNmYdVD7Gvzxl9ckB9+gDtqcOZrq45YdIJ0bS1V4++j4c03SMx0FygK9OtHaskSTDhM6ZFH0n23PoR32gf6brPi82w6Te0TT1Bx6z9INzbiLykhXVMDfj8FO+5IYtEiUkuWUHL44fS++GJ30masHl74Hd4XTxOtDtG4vJTG2nISC924S+G++9Dj9NMp2G23FV1tLx4n8sknNH3wIYk5c9zRhdXWXm8RGjyYbqedStlRR+ErKCCxYAGLLvo9sWnTKD7oIBpef53SoVH6n3UgHHu3Gyf8187UzO/O0tdqKRg1ivwdd1ixFGR4iy3bXIs+U1I1NfhLStY44Tm5dCnLb7iB+pdexldcTL9rrqHk4B9Y9SKVcONpld+7o73d1mPZ2cYKN9qx02lrP3q2uiVfulVG9v+D62iveKzlcOvWrulx2C3rfgxr4dUr3ZjWHhe4q3lGq90qNu3Z2c6gbC1jdyjwD9wSdfdaa/9mjLkamGKtndC88sbdQBHu9JBLrbXrPPNLAXrd6qJJbnjlWx7+eD7lZfn8+6Qd2XZAMbd9fhvjvxrP1j225pYxt9C/qH/nfmEvDfcf7ua0Tn4Sem9J5LPPiE2bSuGsGwkN7Ic5+/UVbxzpxkaa3n3XrXW7xRYMvv8+THAt81MiIl2pdoHrfrcIFaz/1fUSEbhlCzdnf+7EHw4lTZVw6zZuZnzP38HYv6zf121veQsWuPXoP55E3pZb0u3EE1dZZaUtqZoaqu68k1RNjetg77UX/tJSvEiEyrvuovqeezHBIMVjx5Jc5ma0U0ubRxoCAQpHj6ZozL4U7bdfu5eNtMkkySVLsKnUyjuNITR48BojWzaRYPktt1J9332Ehm/G0F/vgu/jW9yKKHPfd6tmnPU6Va9OpfaZZ1e5QFSgd28GP/gAocFrhs/47DnUPfece79r5i8ro9tJJ+HLX3PEIF1bS+2TT+IrLllx1CDQswfRqVNpnPgOjRMnEv/uO/xlZRTuszfFY8ZQMHo0tU89TeWdd4Ln0f3002n66CNiU6dSduIJ9Ln88nUfcfDS7iTDVp3jFeOPzSNO6dpaQgMHrKjJX7qWJfA64uHj3RHgC79a+bXf+hu8eyP85tMfHvMCF6JblkaEVU84zCJdSGUTZ63lpWlL+fPz06lqjHPGnkO5aOxIol4tl757KZOXTuZnm/+MS3e5tO1Z58blbrmbnU51S4itLhFxh2n6bO3muVbvoLQs0xMqxuKjMvUzKh950f1BAMG+PSgaeyjBvn1pfP89IlM+hWSSQL9+DPnfw2udexYR+dGrnOHGXVotqbZO79/qus8/f3KDLiiVLYn581l2/Q1EP/+c0MCBLqgNdbPmBbvu1mUd3ui0aQT79SNQWgh37AYYd2Lw5uPguPErtrOpFMklS4h9+y1L/3gVpiCfIQ8+SLC8fMU2kcmTWfDr8/EaG1cZ+bCJBKHhmzHg1lsJjxixcvvPPmPR7y8mtWS18yL8ftdJ9/sp2GknCvfYncTcuTS+8y7p2pVLXRaPPZDel11OaEC52yG49R9Ujx9PeIst6H/99eRtPvIHv38vHmf5DTdS+8QT2ERirdsF+/en/003rVwnvhXreTR99BFeU9PKO40h2LcfoSGD8Rc3j0su+ATuGQsH/Q32ON9lhlu3hkG7E9vxKnxFRe0br2tZc7ziWzj5GfAHSNXUEPn4Y0oOOeSHPz8DFKA3cTe++i23vz2LrfuXcN0x27HtgFI+W/YZF79zMQ2JBq7a/SoOH3Rg24P4Xtod9pk9EYwffv74quuZeh48cZpbRgfcBU5aX61q+bfu8M2IsSR3vIjF551KZLFH6b470qP/10SWBWhMj6Jp0iRsPE5o+GYUjxlD0Zgx5O+wQ2bmz0RERFrMeMPN1PrDcP7ktY43xL7+mnmnn4G/tJTBDz1IsE8f6l95hcWXXEpw4EAG3nWXO0GxWdOHH7Lo0svwGhvp+4crKT3mGKru/i8Vt91GsLyc8ptuJNCjB/G57uT31JIlhLfcckXXvoVNp4l+OZXIx5PI3357CvdYc5WlhokTWXL5FaRra93oy2mnUbD77m2e0BmfPYdFF11E/NtvKT3mGPJ33IFwq45zYuGi5hNv51Lz2KOkli6j/OabKD5w5Xt/qqqKxZddTtP776/1afX37EloyGAKdh5FUeQF8oMLMBd+if30ARru+iPVNaOIfjMbjKHogP3pcfrp5O+8M8YYvFiMyCef0DjxHXwF+fQ4++w1rpgamTKFRRdfQrq2luFvvL7qRce6iAL0Juyud2dx7UvfcuLoQfz1yK0J+H08+u2jXPfJdQwoHsAte9/AyM8fgw9vc0vY7Hflqh3kd26At/8Gh1znFmWvnefmp1ouL9o83N/Q40y8Jd9SyMcETn/ULSKfTsE9B5JaPI+GYVdSccc9ePE4/fYroLRkmvv84x+ArY7Ei0ZJ1zeseTEDERGRTJt4nbtQzE6nrnOz6JdfMv/Mswj06kXpkUdQcdu/yN9xRwbecfsaAQ8gVVHB4ssuo+nDjwiWl5NctIiSQ8fR9+qrO2c509Zfq6aGmkceoebh/7mTL0eOpPSIwwkN28x1+geUU//yyyz5y9X4QiH6X3/dD56cn6quZsF55xGb9hV9//gHup14Ik2TJrHokkvw6hvofeklFIxamR9tKkVqyRISc+e6HYMZM4l+9RWk0/jDaQp32Iro19+TbLAEBw2k+8mnkKquovaRR0nX1ZG3zTYEevVyJ4vGYpj8fGw8jr+khF4XXkjZT48FoOquu6j4178JDhyw4ddV2AAK0Juoxycv4NKnpnLYdv345wk7Yklz/SfX8+h3j7LvgH35+3a/pvi5C9xSVH23dcso7XAyHN68ZuOcd+GBI91Z50f/x11d6O793fq15zQve/XsL6kPHMKih5oveGEgv2eKoqNPwy79hsb3JxGrdmMh4a22pPymmwkP7AsTfuMOl506oeNnzouIiGRJZMoU5p9zLjYapXjsgfS/8cZ1rpNvPY+qu+6m+sEH6fXbCyg77rjOvxhZK148Tv0LL1J9//3Ev/9+5QeaR0QKRo2i/003/vDqHS2PF42y6KLf0/j22xTutRdNH3xAaOhQym+9tV3jIum6Ohrfe5/Ge6+iaXYjoeIkPc44k6LTrlhxgqQXjVL33HNUP/QQNhanaJ99KNrPzX0n5s5l2V+vITJlCnlbb42vuJjIpEmU/OQn9P3Lnzt9R6QjFKA3Qa98tYRfPfwZe4/oxd2njiLmNXLxxIv5aMlHnL716fyuYAT+Cee7EYwj/unOAJ94nVvfcfiB7oIm9x7iLmBx7sSV6wwv/BTuO9QtAl/xHdHgjsx7rJK8Lbek96WX0PTGyzQ++wCxKgNY8gcWU3TMmRSNGUN4iy0y+qIhIiLSFSKffU506pd0P+WUNVbJ2Jika2vdFTCbO8KB7j3oduIJHR6PtKkUS6/+K7WPP07p0UfT949/WPWaB+3x/avuAjalg+CCz9u+uuDavr611L/4EstvuIF0fb0biTn22KxnCgXoTcyHMys5ffxkth1QyoNnjaY6vpTz3jiPhY0LuWq3qzg6HYJHT3KX5/zpvaueAfvp/fDChW4xdp/fdZr7rHZo5Kun4ckzSIaGMeelQnzhPIY8/hiBHs3rOC76jNQdP4FwEYGLP277SlMiIiLyo2GtJbVkCcH+67lSl7Xu6PPwA2Hro9brIbxoFK+pKSvzzm1RgN6EfLOknuPv/Ih+ZXk88Ys9qEst4cxXzySaivKP/f7BLj23g9t3dWMYv3in7bO4v3/NLbo+9i9ugf82eF+/ztzLbyO5aAlDHn1klTOMATcOEshfcRlVERERkU3J2gK0lj/4kVlcG+X08Z9QGA5w3xmjqU4u5OxXzybpJbn34HvZvPvm8OG/3ZWETn6qzfCcqqqicXqEaONJFDcNpq3JolRlJYtveZz4zNkM/M+da4ZncDPVIiIiIjlGAfpHpC6a5PTxnxCJp3nivN2JspizXz0bz3rcc/A9jOg2Apqq3Koaww9cZSk6Lxaj+oEHaXzzTaJTp4K1mGCQ2sceX3W9yWSSmkceoeK2f+HF4/T9058o2nvvdVQlIiIiklsUoH8k4qk05z4whTmVTdx/xmiCeRWc+eqZ+IyP8QePZ1jZMLfhO9dDogEOumbF56Zra1nw6/OJfvopedtuS8/zf+1O+Bs+nOrx91H5n//Q+O5P6HbSSTS9/x7xGTMp3HNP+lx5JeFhQ7P0HYuIiIhsnBSgfwSstfzf01/x8Zxq/nnCDgztm+Tkl8/Fb/zce/C9DCkd4rZb/h1m8n9h59Oh95YAJBctYv65vyA5fz7lt95Cybhxqzx2z1/+gtIjj2DZDTdQPX48wfJyBvz7XxQdcEDWz3wVERER2RgpQP8IPPzxfJ76bCEXHDCCMVsWcerLpxJNRrlv3H0rwnPDW2+x6Dfnk9+7B8X9hlM0bx5eNMqCc87Fi8UYeM9/KRw9us3HD/brx4BbbyV58cX4e/RY51qXIiIiIrlOAXoj98WCWq5+/mv2HdmLX+w7gF+8cS4LGxZy59g7GdmteXFza6m58yZ8/hRp04tlt/ybZbf8G/x+Ar16Mfjhh8gb+cMLoQfLy39wGxEREZFcpwC9EatuSvCrhz6ld0mYm4/fhsvfu4ypFVO5eczN7NJ3F7dRvJHUY7+hadpseuzWg953vUViWSWNE98hMXcuPc4+q91XIhIRERGRH6YAvZFKe5YLHvmcyqYET5+3B//9+jYmLpzIlbteydjBY91GS6bCk2dQP2kp2BJKLh8PwTxCAwbQ/eSfZ/cbEBEREdlEKUBvpP711gzen1nJ9cduy6LkJB7+5mFO3vJkThh6GHzzAsx4Fb58DAq6U9e0PeHNQ+RtvkW2yxYRERHZ5ClAb4RmVzRyx9uzOGL7/uy+ORz/wp/YrmQzLvp2Erx6E6QTEC6BbY4hseUvid19Ir0v/n22yxYRERHJCQrQGxlrLX9+/mvCAR+XjhvGhe+cTQDDTTM+J+jPh9HnwsiDYdDu4A9Sd/vtYAwlP/lJtksXERERyQkK0BuZV6cv493vK7jqsK2495t/8m31t9ze5KMfATjzFeg2ZMW21lrqn3+BglGjCPbrl72iRURERHKIL9sFyEqRRIq/vvA1W/Qtpne/r3ni+yc4y5awT9ViOOF/q4RngNhX00nMnUvJ4Ydlp2ARERGRHKQO9Ebk9rdnsqg2ygNnb89VU05mO38x58/8Co65Gwbtusb29S88jwkGKTn44CxUKyIiIpKbFKA3ErMrGrnr3dkcs2M5XzVOoCpWxW2LlxLY51LY7vg1trfpNHUvvUThvvvgLy3NQsUiIiIiuUkjHBuJa178hryAn7P368F9X43n4Eic7QaNgTFXtLl90/vvk66opPSww7u2UBEREZEcpwC9Efh0XjVvfbuc8/bbjMdn3kMyHee3NbVwyHXgW/NH1PTxJyy6+BIC/fpRNGbfLFQsIiIikrsUoDcCN7/2PT2LQuyzdZpnZjzNCXX1DNzpLOix2Rrb1r/0EgvOPptA794MefghfHl5WahYREREJHcpQGfZhzMr+XBWFb8aM5w7vvwnhRh+EQP2vXSNbavG38eii35P3vbbMeThhwj279/1BYuIiIjkOAXoLLLWctNr39GvNI/hg5fw3qL3OLeqirJ9Lof8bqtst/yWW1l+/fUUH3wwg+65B39ZWRYrFxEREcldCtBZNPG7Cj6bX8tv9h/B3dPuoL8HJwZ7wy5nrbJd5R13UHXXXZQdfzzlt9yMLxzOUsUiIiIiogCdJS3d50HdC9h6SC1fVHzJqTXVhMdeA/7giu2q7rmHyn/9m9Kjj6bvn/+E8fuzWLWIiIiIKEBnyavTlzJ9cT1X7hrg8Vd+SYHncWSv0bD5uBXbVD/4EMtvvImSQ8fR75q/YtpYkUNEREREupYSWZbc+9Y0rit5kp3fO5aXbT1HdN+OopMeB2MAqJswgWV/+xtFBx5A/+uvV+dZREREZCOhKxFmwYLlNfy58mK28s3jri32IRmfy4lj/rZidMNramLZddeTv9NOlN9yCyYY/IFHFBEREZGuog50FlS/+Be28s1j8bi7eMwXYY/+ezCsdNjKjz/4IOnqavpcdim+UCiLlYqIiIjI6hSgu9qCyWw7735eDh3E1D6lLI8u56QtTlrx4XRdHVX33EvR/vuTv/32WSxURERERNqiEY6ulIiQfvoXLLXdmbXD5Uz+5jYGFg9k7wF7r9ik6t7xeI2N9PrtBVksVERERETWRh3orvTWNfhrZnFJ8lwGD/X4bPlnnLD+TtkjAAAgAElEQVT5CfiM+zGkKiupfvBBSsaNI2/zzbNcrIiIiIi0RR3orjLvQ5h0B28VH8G85C58UjWB/EA+R404asUmlXfdhY3H6fmb87NYqIiIiIisizrQXeWFC/HKBnNRzTHsv2U3Xpv3GuOGjqMkVAJAcskSah95lNKjjiQ8dGiWixURERGRtVGA7grVs6HiW74dcgq1qRAD+i8kkoowdvDYFZtU/uc/WKDXr36VvTpFRERE5AcpQHeFWW8B8Gz95pQVBFkQ/4SiYBG79t0VcOs+1014ntLDDydYXp7NSkVERETkByhAd4VZb2NLB/Do7CD7bd6TdxZOZJ8B+xBsvnBK/euvYyMRyo49JsuFioiIiMgPUYDOtHQK5rzHsp57UB9LM2JQBbXxWg4cfOCKTeqeeZbgoEHk77RTFgsVERERkfZQgM60xZ9DvI530tuQF/RRxaeE/WH27L8nAImFi4h8/DFlRx+FMSbLxYqIiIjID1GAzrTZbwOG+5YMZq/hPXln4Vvs0X8PCoIFANQ99ywYQ+mRR2a3ThERERFpFwXoTJv1Nsk+2/FNXZAh/atZFlm2YnzDeh51zzxLwW67EuzfP8uFioiIiEh7KEBnUrwBFn7Ckh67AVDn+wy/8bPvgH0BiH76KcmFCyk7+uhsVikiIiIiHaAAnUlz3wcvxefBHQDL9LoP2KXvLpSGSwGofeZZfIWFFB944LofR0REREQ2GgrQmTTrbQjk81bjMMp71bOgYR4HDDoAcGs/17/yCsXjDsFXUJDlQkVERESkvRSgM2n22zB4D75YGqVb7+8A2H/Q/kCrtZ81viEiIiLyo6IAnSl1i6Dye6KD9mVeVYRI4Eu277U9vQJl1D77LJX/+jfBwVr7WUREROTHJpDtAjZZs98G4PvCUeBbRqx2Fid+O4qZfz+QVEUFoeGb0fcPf9TazyIiIiI/MgrQmTLrbSjqw+RIX4KhKVzzQIp+NZMI77kn/a69lsK99lR4FhEREfkRUoDOBGth9kQYfgBfLa5n3/ov6VcDJdf+ifJjTsh2dSIiIiKyATI6A22MOcQY850xZqYx5vI2Pn6rMeaL5n/fG2NqM1lPl2mqhEgl9N+JrxbXM/b7b6kr8tH/8GOzXZmIiIiIbKCMdaCNMX7gdmAssBCYbIyZYK39umUba+2Frbb/DbBjpurpUtWzAYiVDKZ2/kK2mVXD1IM3Y7dgMMuFiYiIiMiGymQHejQw01o721qbAB4FjlzH9icCj2Swnq7THKBnpnpx0Pz38Vmwhx+Q5aJEREREpDNkMkCXAwta3V7YfN8ajDGDgaHAW2v5+LnGmCnGmCkVFRWdXminq54NxsfntUUcPHcyXw4xjNh6r2xXJSIiIiKdIJMBuq0lJuxatj0BeNJam27rg9bau6y1o6y1o3r16tVpBWZM9WwoHUj1e5PoHWnizR19bNVjq2xXJSIiIiKdIJMBeiEwsNXtAcDitWx7ApvK+Aa4AN19GP3ee4X6ggDVO29GYbAw21WJiIiISCfIZICeDIwwxgw1xoRwIXnC6hsZYzYHugEfZbCWrlU9m7ivH1vNm8a72wfYou822a5IRERERDpJxgK0tTYFnA+8CnwDPG6tnW6MudoYc0SrTU8EHrXWrm2848clUg2xWhZ/1oDfery2XZJteipAi4iIiGwqMnohFWvtS8BLq9131Wq3/5zJGrpc9RyshaZJM/mqb1+Wdq9k257bZrsqEREREekkGb2QSk6qno2XMPir6/hyaDEBX4CR3UZmuyoRERER6SQK0J2tejaJJnfBlNq+MTbvtjkhfyjLRYmIiIhIZ1GA7mzVs0l4bqm9xT2qNP8sIiIisolRgO5s1bOJJ7sBsLgkrgAtIiIisolRgO5s1bOJNoapC4eJhQ3b9FCAFhEREdmUKEB3plgdRCqJ1lmWlYYI+/MZWjo021WJiIiISCdSgO5M1XMASNXEWF7mMaJ0C/w+f5aLEhEREZHOpADdmapnYz3w1dSzvEeMbXttne2KRERERKSTKUB3purZJCN+jOexrJtls7Ih2a5IRERERDqZAnRnqp5DMu2WsFteBn0L+2a5IBERERHpbArQnanVGtDLyowCtIiIiMgmSAG6M1XPJhkvIuUzVBWrAy0iIiKyKVKA7iyJJmhcSrLRR0VxHj5fHiWhkmxXJSIiIiKdLJDtAjYZ1bMBiNUkWFoSoCTYA2NMlosSERERkc6mDnRnaQ7QyeV1LC+zdA/3znJBIiIiIpIJCtCdpXo26YTBNjSyvFuaPgWafxYRERHZFClAd5bq2STTPQFY3iPOgOJ+WS5IRERERDJBAbqzVM8hYV3XeXmZYWi3AVkuSEREREQyQQG6s1TPJpl0q24sK4PNysqzXJCIiIiIZIICdGdIxqB+EYmmENG8MJE8Q78ijXCIiIiIbIoUoDtDpBKAZG2CitICAPoU9slmRSIiIiKSIQrQnSFWB0CysoGlpQECFJEfyM9yUSIiIiKSCQrQnSFai/UgubyWxSVQ4OuZ7YpEREREJEMUoDtDrI5U1IdNpVhamqQs1CvbFYmIiIhIhihAd4ZYHYkmd1X05T1i9MzT/LOIiIjIpkoBujPEakk2+gGo6J6kv1bgEBEREdlkKUB3hlgdicYA1hgqS2Bwaf9sVyQiIiIiGaIA3RlidSSjeUS6l5H2GzbTVQhFRERENlkK0J0hVkeyKUh1WSEAI3sOzHJBIiIiIpIpCtCdIVpLotGwtCQI1lBerJMIRURERDZVCtCdwGuoIR2xLC6x+G0pAV8g2yWJiIiISIYoQHeCVHUtAMsKEuSZHlmuRkREREQySQG6E6Tr6gGoyY9QFNBVCEVEREQ2ZQrQnSBd3wRAXUGE7uHeWa5GRERERDJJAXpDeWnSjTEAGgrT9CnQRVRERERENmUK0BsqVkcq4Z7GhgIYUKwALSIiIrIpU4DeULE60jEf1meIhGGIrkIoIiIisklTgN5QsTrScR/xgiAYw+Y9B2W7IhERERHJIC1YvKFitaQTPhoLAljPY3gPXURFREREZFOmAL2hYnWk4j7qC3yQKqEoL5jtikREREQkgzTCsaGaRzhq8i0hume7GhERERHJMAXoDdUSoPNSFPh0FUIRERGRTZ0C9AayTTWkEz7qCpKUhnQRFREREZFNnQL0BvJqK8Ea6guge55GOEREREQ2dQrQGyhVXQ1AQz50zy/JcjUiIiIikmkK0BsoXdMcoAugW15xlqsRERERkUxTgN5A6doGAOoLDCXhoixXIyIiIiKZpgC9gdL1jQDU50OZArSIiIjIJk8BegOlGiKAG+Eoy9cIh4iIiMimTgF6A6UbE6QDhkTQ0KNAJxGKiIiIbOoUoDdEKk465hEvcFdE764OtIiIiMgmL6MB2hhziDHmO2PMTGPM5WvZ5nhjzNfGmOnGmP9lsp5O13wVwlhLgC7QDLSIiIjIpi6QqQc2xviB24GxwEJgsjFmgrX261bbjACuAPa01tYYY35cl/JrDtBNpQFs2kdxXijbFYmIiIhIhmWyAz0amGmtnW2tTQCPAkeuts05wO3W2hoAa+3yDNbT+WJ1pOI+GvL9WC9MQdCf7YpEREREJMMyGaDLgQWtbi9svq+1kcBIY8wHxphJxphDMlhP54vVko77qCvwY2yYgF8j5SIiIiKbuoyNcACmjftsG19/BDAGGAC8Z4zZxlpbu8oDGXMucC7AoEGDOr/S9WQbqvCSPmrzDT6bl+1yRERERKQLZLJluhAY2Or2AGBxG9s8Z61NWmvnAN/hAvUqrLV3WWtHWWtH9erVK2MFd1S6chkAtfkGPwrQIiIiIrkgkwF6MjDCGDPUGBMCTgAmrLbNs8B+AMaYnriRjtkZrKlTparcyHZ1viVg8rNcjYiIiIh0hYwFaGttCjgfeBX4BnjcWjvdGHO1MeaI5s1eBaqMMV8DbwOXWGurMlVTZ0tXVwJQm58m6FOAFhEREckFmZyBxlr7EvDSavdd1er/LXBR878fnXRNDQC1+UnCvoIsVyMiIiIiXUHLRmyAdG09AHUFSfL86kCLiIiI5AIF6A2QrmsEoKEgRZ6/MMvViIiIiEhXUIDeAKmGCCbsI+03FAQ1wiEiIiKSCxSgN0C6MQ6FQQAKg+pAi4iIiOQCBegNkI4ksc0BujhUlOVqRERERKQrKECvL2tJR9IkC8MAFIXUgRYRERHJBe0K0MaYQmOMr/n/RxpjjjDGBDNb2kYuGSEVN8SbA3RpqDjLBYmIiIhIV2hvB/pdIM8YUw68CZwB3Jepon4UYnWk4z6iRS5Al+VphENEREQkF7Q3QBtrbQQ4BviXtfZoYKvMlbXx82qWYdM+GgpCAJTmK0CLiIiI5IJ2B2hjzO7Az4EXm+/L6FUMN3bp5YsBqC90AbpHfkk2yxERERGRLtLeAP074ArgGWvtdGPMMODtzJW18UtXLgGgtrkD3V0daBEREZGc0K4usrX2HeAdgOaTCSuttRdksrCNXapiGQBVBUGsF6Q0Py/LFYmIiIhIV2jvKhz/M8aUGGMKga+B74wxl2S2tI1buroSgKo8g/XCFIRyeqJFREREJGe0d4RjK2ttPXAU8BIwCDglY1X9CKRragCoyDfghSkM+7NckYiIiIh0hfYG6GDzus9HAc9Za5OAzVxZG790TS0YS3UwhfXC5AcVoEVERERyQXsD9H+AuUAh8K4xZjBQn6mifgxS9Y34w4aojeKzeRhjsl2SiIiIiHSBdgVoa+1t1tpya+2h1pkH7Jfh2jZq6fom/Pk+El4Uv9EJhCIiIiK5or0nEZYaY24xxkxp/nczrhuds9KNMfyFQZJelCD52S5HRERERLpIe0c47gUagOOb/9UD4zNV1I9BOpLEXxgmaaMEfQrQIiIiIrmivWuvbWatPbbV7b8YY77IREE/FulImvyhBaSpI6QALSIiIpIz2tuBjhpj9mq5YYzZE4hmpqSNn7WWVMxiSgqxJkmevyDbJYmIiIhIF2lvB/qXwAPGmNLm2zXAaZkpaePn1deDZ0iXuMt35wdyehxcREREJKe091LeXwLbG2NKmm/XG2N+B0zNZHEbq/SyBQCkSl2ALgioAy0iIiKSK9o7wgG44Nx8RUKAizJQz4+CV7McgHiRC86F6kCLiIiI5IwOBejV5OyVQ7wGdxnvaF4YgOKQArSIiIhIrtiQAJ2zl/L2mhoAaGq+fHdRuCib5YiIiIhIF1rnDLQxpoG2g7KB3L16iG1qBKA2AKSgVAFaREREJGesM0Bba4u7qpAfEy/iAnRDwLgAnacALSIiIpIrNmSEI2d5kSYAatwEB93ySrJYjYiIiIh0JQXo9WCbA3Rtc4Dunq9GvYiIiEiuUIBeD17UXYSxxpfCWj+l+Tk7Di4iIiKScxSg14MXjYKx1JGEdJiicHsv6CgiIiIiP3YK0OvBRmP4ApbGdALrhSkI+bNdkoiIiIh0EQXo9eDFohi/pSkdw3phCkPqQIuIiIjkCgXo9eDFEvgClkg6Bl6YQo1wiIiIiOQMBej14MXi+IKGeDoCNkwooKdRREREJFco+a0HG0/iCxjiXpRA7l6QUURERCQnKUCvBy+RxAR9JL0oAZOX7XJEREREpAspQK8HL57CF/KRIkrQqAMtIiIikksUoNeDjacwIT9pGyfsL8h2OSIiIiLShRSg14OXTGNDfjBWAVpEREQkxyhArwcv4ZFqXrouXwFaREREJKcoQK8Hm/JINl88pTBYmOVqRERERKQrKUB3kE2lsGlINl++uyCgDrSIiIhILlGA7iAvGgUgkec60MWhomyWIyIiIiJdTAG6g1oCdCykAC0iIiKSixSgO8g2B+hIyD11JXkK0CIiIiK5RAG6g1o60JGge+rKFKBFREREcooCdAd5ERegG5oDdLe8kmyWIyIiIiJdTAG6g2xTAwANQYO1hrI8rcIhIiIikksUoDvIa6oHoCEAeGEKw8HsFiQiIiIiXUoBuoO8Rheg64IW64Upar4ioYiIiIjkhowGaGPMIcaY74wxM40xl7fx8dONMRXGmC+a/52dyXo6Q0sHuj7gAnRB2J/likRERESkK2WsfWqM8QO3A2OBhcBkY8wEa+3Xq236mLX2/EzV0dlspAmAWr8H6kCLiIiI5JxMdqBHAzOttbOttQngUeDIDH69LuE1NQJQF/Sw6TAFIXWgRURERHJJJgN0ObCg1e2Fzfet7lhjzFRjzJPGmIFtPZAx5lxjzBRjzJSKiopM1NpuXqQJjKXBl3AjHCF1oEVERERySSYDtGnjPrva7eeBIdba7YA3gPvbeiBr7V3W2lHW2lG9evXq5DI7xkYi+PyWGCn85OH3tfVtioiIiMimKpMBeiHQuqM8AFjcegNrbZW1Nt58825g5wzW0ym8aAQTsMRJEDD52S5HRERERLpYJgP0ZGCEMWaoMSYEnABMaL2BMaZfq5tHAN9ksJ5O4UWj+PyWhI0T8ilAi4iIiOSajA3wWmtTxpjzgVcBP3CvtXa6MeZqYIq1dgJwgTHmCCAFVAOnZ6qezmKjMQhYrLEK0CIiIiI5KKNnwFlrXwJeWu2+q1r9/xXAFZmsobN58Tg24Ea58/y6jLeIiIhIrtGVCDvIi8Wxzbsd+YHC7BYjIiIiIl1OAbqDvFicdHMHOj+Ql+VqRERERKSrKUB3kI0nV3SgC4IK0CIiIiK5RgG6g7x4knTIrf1cEAxnuRoRERER6WoK0B1kEynSQfe0qQMtIiIiknsUoDvIS6RJhfwAFIbUgRYRERHJNQrQHWDTaWzKI9kcoItD6kCLiIiI5BoF6A7wojEAkiH3tBWHdSEVERERkVyjAN0BNhoBIBFsHuEIqwMtIiIikmsUoDvAi0YBiIVdgC7QOtAiIiIiOUcBugNaRjhWdKA1Ay0iIiKScxSgO6BlhCMaalnGTqtwiIiIiOQaBegO8GKuAx1rXoVD60CLiIiI5B4F6A7wIm4GOhryYb0Aec2jHCIiIiKSOxSgO8BrHuFoCvrB+gkH9PSJiIiI5BolwA6wzSMckZAPa4OEFKBFREREco4SYAe0jHA0BU1zB1ojHCIiIiK5RgG6A1aOcBjw1IEWERERyUVKgB1gmxoAS1PAYG1AAVpEREQkBykBdoDX1IgJWOIGsAFCfj19IiIiIrlGCbADvEgjPr8lgQUbIOg32S5JRERERLqYAnQH2EgTvoAL0IYgxihAi4iIiOQaBegO8KJRjN+SwMNHINvliIiIiEgWKEB3gBeJ4AtYktbDRzDb5YiIiIhIFihAd4AXjboATRq/UYAWERERyUUK0B1gYzGM35IirQ60iIiISI5SgO4ALxrHF3ABOmBC2S5HRERERLJAAboDvHgcn9+SJo3fpw60iIiISC5SgO4AG0vgC1g8UgQ0Ay0iIiKSkxSgO8CLJyBgscYj6NMIh4iIiEguUoBuJ+t52GQaL2AB1IEWERERyVEK0O1ko1H33+YAHfSrAy0iIiKSixSg28lrDtDpoLt8d8gXzmY5IiIiIpIlCtDt5MViAKRD7hLeIXWgRURERHKSAnQ7eZEIAKk8BWgRERGRXKYA3U62uQOdCruTB8N+jXCIiIiI5CIF6HbyIm4GOrkiQKsDLSIiIpKLFKDbyYu6EY5EngvQeepAi4iIiOQkBeh2ahnhSISaA3RQAVpEREQkFylAt1PLCEdMHWgRERGRnKYA3U5ezAXoePMydnkBBWgRERGRXKQA3U4tVyKMNp9EWKARDhEREZGcpADdTi0jHJHmDnS+ArSIiIhITlKAbicvFsP4IebzA5AfzMtyRSIiIiKSDQrQ7eRFI/gClrhxAbpQAVpEREQkJylAt5ONxjABS9S42wUhBWgRERGRXKQA3U5eNILP7xHDh7U+8gPBbJckIiIiIlmgAN1OXsQF6DiA9RMK6KkTERERyUVKge1kI034ApYogBckrAAtIiIikpOUAtvJi0YwAUscsDagAC0iIiKSo5QC28mLRvH5LXEs2IBGOERERERyVEZToDHmEGPMd8aYmcaYy9ex3U+NMdYYMyqT9WwIG426Zeysbe5A+7NdkoiIiIhkQcYCtDHGD9wOjAO2Ak40xmzVxnbFwAXAx5mqpTN4zcvYuQ60TiIUERERyVWZTIGjgZnW2tnW2gTwKHBkG9v9FbgBiGWwlg3mxeL4/JaE9cALKkCLiIiI5KhMpsByYEGr2wub71vBGLMjMNBa+0IG69hg1vOw8YQb4SCtkwhFREREclgmU6Bp4z674oPG+IBbgd//4AMZc64xZooxZkpFRUUnltg+Nuaa4yZgSVoPbICAr61vT0REREQ2dZkM0AuBga1uDwAWt7pdDGwDTDTGzAV2Aya0dSKhtfYua+0oa+2oXr16ZbDktnnNAdrn90iSxkcQYxSgRURERHJRJgP0ZGCEMWaoMSYEnABMaPmgtbbOWtvTWjvEWjsEmAQcYa2dksGa1osXiQLgC1iS1gVoEREREclNGQvQ1toUcD7wKvAN8Li1drox5mpjzBGZ+rqZYGMrA3TKpvGZQJYrEhEREZFsyWgStNa+BLy02n1XrWXbMZmsZUN4URegjd+SIoWfUJYrEhEREZFs0VIS7dB6hCNNioDRCIeIiIhIrlKAbof8HXdg+DXHkN8jgUcSv08BWkRERCRXaZi3HXyhEL7SADYcxiNJwGiEQ0RERCRXqQPdXqkYqWAeAAF1oEVERERylgJ0eyWjxJsDdNCnDrSIiIhIrlKAbq9UnHggDEBQIxwiIiIiOUsBur1SUZItHWi/ArSIiIhIrlKAbq9kbEUHOqQRDhH5/+3df3SUVZ7n8fdNJSSECAh2EIk9hFkgSCepFNXIBKKhiS4qG42QAznsSsiMjaBNCysYHVscHWamkQMOZxrPEUGYyE706JBFD+gQVsRtttHwyxaBAFo9AwqtZAyhQ5JKcvePqpSBhFAFSSqxPq9zcqh6ftz61s0D+XBzn1siIhKxFKCD1XiRBv/Icx9HbJiLEREREZFwUYAOVmM9DdG+AB3r0CocIiIiIpFKATpY3ovU+4NzbLRGoEVEREQilQJ0sBrraHD4PncmVlM4RERERCKWAnSwGuuo9wfoOI1Ai4iIiEQsBehgeeuoi/IF6L4K0CIiIiIRSwE6WI111BkHoBFoERERkUimAB2sxjrq/N3VN0YBWkRERCRSKUAHo7kJmhq4GGUATeEQERERiWQK0MForAOgzvoDtEagRURERCKWAnQwGusBqDO+AB0fExfOakREREQkjBSgg+G9CHw/At1PAVpEREQkYilAB6NlCgcW2+wgNsYR5oJEREREJFwUoIPhD9AXrQUbTR+Huk1EREQkUikJBsPrC9D1gLUxxMao20REREQilZJgMBpb5kA3g3VoBFpEREQkgikJBiNpPCw+woXoBGiOITZa3SYiIiISqZQEgxHdB/rfQr1twtpoYqN1E6GIiIhIpFKADkFDU4PvJkKNQIuIiIhELCXBEHib67EK0CIiIiIRTUkwBI3NXrDRmgMtIiIiEsGUBEPgbW6AZo1Ai4iIiEQyJcEQNFrfHOjoKBPuUkREREQkTBSgQ9DY7CXKRGOMArSIiIhIpFKADkGT9RJFn3CXISIiIiJhpAAdgia8RBET7jJEREREJIwUoEPQZL1EGwVoERERkUimAB2CZrw4ohSgRURERCKZAnSQmpqbsDQRbTQHWkRERCSSKUAHqaG5AYAYjUCLiIiIRDQF6CA1NPkCtEagRURERCKbAnSQWgJ0jEMBWkRERCSSKUAHqb6pHoA+UQrQIiIiIpFMATpIgRFoBWgRERGRiKYAHaSWmwj7aAqHiIiISESLDncBvUXLFI5YR2yYKxEREZHu5vV6OXXqFHV1deEuRbpAXFwcSUlJxMQEt9qaAnSQWqZwxGoEWkREJOKcOnWKG264geHDh2OMCXc50omstZw7d45Tp06RnJwc1DmawhGklgCtKRwiIiKRp66ujsGDBys8/wAZYxg8eHBIv11QgA5SyxSOuGhN4RAREYlECs8/XKF+bxWgg9QyAt03Oi7MlYiIiEikOXfuHE6nE6fTyc0338ywYcMCzxsaGjo8t6KigoULF171NTIzMzur3E6XkJDQZtuqVau47bbbSEtLY8qUKfzhD3/otno0BzpItd6WEWhN4RAREZHuNXjwYA4ePAjAc889R0JCAk888URgf2NjI9HR7cc6t9uN2+2+6mvs2bOnc4rtJhkZGVRUVBAfH8/LL7/M0qVLeeONN7rltTUCHaQ/eS8CGoEWERGRnqGwsJDFixczefJknnzyST7++GMyMzPJyMggMzOTY8eOAbBr1y6mTZsG+MJ3UVER2dnZjBgxgjVr1gTaaxnl3bVrF9nZ2cyYMYOUlBRmz56NtRaAbdu2kZKSwqRJk1i4cGGg3dY8Hg9ZWVm4XC5cLtclwXzFihWkpqaSnp5OcXExACdOnCAnJ4f09HRcLhcnT54M6v1PnjyZ+Ph4ACZMmMCpU6dC7cJrphHoINX5R6Dj+2gOtIiISCT7m3cO8/lX5zu1zdtu6c+y/zY25PMqKyspLy/H4XBw/vx5du/eTXR0NOXl5Tz99NO8/fbbbc45evQoH3zwATU1NYwePZr58+e3Wb7twIEDHD58mFtuuYWJEyfy29/+Frfbzbx589i9ezfJyckUFBS0W1NiYiI7duwgLi6O48ePU1BQQEVFBdu3b6esrIy9e/cSHx9PVVUVALNnz6a4uJi8vDzq6upobm4OuR/Wr1/PPffcE/J510oBOki1jb4A3Vc3EYqIiEgPkZ+fj8PhAKC6upo5c+Zw/PhxjDF4vd52z7nvvvuIjY0lNjaWxMREzp49S1JS0iXHjB8/PrDN6XTi8XhISEhgxIgRgaXeCgoKeOWVV9q07/V6eeyxxzh48CAOh4PKykoAysvLmTt3bmDUeNCgQdTU1HD69JY5xRgAABrlSURBVGny8vIA33rMoXr99depqKjgww8/DPnca9WlAdoYMxX4R8ABvGqt/YfL9j8CPAo0AReAn1trP+/Kmq7VRf8IdN8YTeEQERGJZNcyUtxV+vXrF3j8q1/9ismTJ7NlyxY8Hg/Z2dntnhMb+/1goMPhoLGxMahjWqZxXM3q1asZMmQIhw4dorm5ORCKrbVtVrsIts0rKS8vZ/ny5Xz44YeX1NzVumwOtDHGAfwGuAe4DSgwxtx22WH/y1qbaq11AiuAVV1Vz/Wqa6zHWkN8jG4iFBERkZ6nurqaYcOGAbBx48ZObz8lJYUvvvgCj8cDcMUb9qqrqxk6dChRUVGUlJTQ1NQEwN13382GDRuora0FoKqqiv79+5OUlERZWRkA9fX1gf1Xc+DAAebNm8fWrVtJTEy8zncXmq68iXA8cMJa+4W1tgEoBe5vfYC1tvUEon7A9f03pAvVNdaDjaZPtO67FBERkZ5n6dKlPPXUU0ycODEQWjtT3759Wbt2LVOnTmXSpEkMGTKEAQMGtDluwYIFbNq0iQkTJlBZWRkYJZ86dSq5ubm43W6cTicrV64EoKSkhDVr1pCWlkZmZiZnzpxp02ZtbS1JSUmBr1WrVrFkyRIuXLhAfn4+TqeT3NzcTn/PV2Kud+j8ig0bMwOYaq39K//z/wHcbq197LLjHgUWA32An1lrj7fT1s+BnwP8+Mc/Hted6/y1eLz8Wcr/8D6/yXqXO0f9qNtfX0RERMLnyJEjjBkzJtxlhN2FCxdISEjAWsujjz7KyJEjWbRoUbjL6hTtfY+NMfustW3WAOzK4dT2PtKlTVq31v7GWvvnwJPAM+01ZK19xVrrtta6f/Sj8ITX+sYGrHUQqxFoERERiVDr1q3D6XQyduxYqqurmTdvXrhLCouuvInwFHBrq+dJwFcdHF8KvNyF9VyX+qZ6sDGawiEiIiIRa9GiRT+YEefr0ZVp8BNgpDEm2RjTB5gFbG19gDFmZKun9wFtpm/0FPVNDVgbTR+HArSIiIhIJOuyEWhrbaMx5jHgfXzL2G2w1h42xjwPVFhrtwKPGWNyAC/wn8CcrqrnejU0NYB1EBejAC0iIiISybp0HWhr7TZg22Xbnm31+Jdd+fqdqaGpHppj6ONfrFxEREREIpOGU4Pkbfb6pnBoDrSIiIhIRFMaDJK3uQFstFbhEBERkW6XnZ3N+++/f8m2l156iQULFnR4TkVFBQD33nsv3333XZtjnnvuucB6zFdSVlbG559//0HRzz77LOXl5aGU320SEhLabFu1ahW33XYbaWlpTJkyhc5YDllpMEhe26ARaBEREQmLgoICSktLL9lWWlpKQUFBUOdv27aNgQMHXtNrXx6gn3/+eXJycq6prXDIyMigoqKCTz/9lBkzZrB06dLrblNpMEhNzV5oVoAWERGR7jdjxgzeffdd6uvrAfB4PHz11VdMmjSJ+fPn43a7GTt2LMuWLWv3/OHDh/Ptt98CsHz5ckaPHk1OTg7Hjh0LHLNu3Tp++tOfkp6ezvTp06mtrWXPnj1s3bqVJUuW4HQ6OXnyJIWFhbz11lsA7Ny5k4yMDFJTUykqKgrUN3z4cJYtW4bL5SI1NZWjR4+2qcnj8ZCVlYXL5cLlcrFnz57AvhUrVpCamkp6ejrFxcUAnDhxgpycHNLT03G5XJw8eTKovps8eTLx8fEATJgwgVOnTgV1Xke69CbCHxKvbQCiiY5q7/NhREREJGJsL4Yzv+/cNm9OhXv+4Yq7Bw8ezPjx43nvvfe4//77KS0tZebMmRhjWL58OYMGDaKpqYkpU6bw6aefkpaW1m47+/bto7S0lAMHDtDY2IjL5WLcuHEAPPjggzz88MMAPPPMM6xfv55f/OIX5ObmMm3aNGbMmHFJW3V1dRQWFrJz505GjRrFQw89xMsvv8zjjz8OwE033cT+/ftZu3YtK1eu5NVXX73k/MTERHbs2EFcXBzHjx+noKCAiooKtm/fTllZGXv37iU+Pp6qqioAZs+eTXFxMXl5edTV1dHc3BxyN69fv5577rkn5PMup+HUIDVZL1HEYIwCtIiIiHS/1tM4Wk/fePPNN3G5XGRkZHD48OFLpltc7qOPPiIvL4/4+Hj69+9Pbm5uYN9nn31GVlYWqampbN68mcOHD3dYz7Fjx0hOTmbUqFEAzJkzh927dwf2P/jggwCMGzcOj8fT5nyv18vDDz9Mamoq+fn5gbrLy8uZO3duYNR40KBB1NTUcPr0afLy8gCIi4sL7A/W66+/TkVFBUuWLAnpvPZoBDpITdaLg5hwlyEiIiLh1sFIcVd64IEHWLx4Mfv37+fixYu4XC6+/PJLVq5cySeffMKNN95IYWEhdXV1HbZzpcHAwsJCysrKSE9PZ+PGjezatavDdqy1He6PjY0FwOFw0NjY2Gb/6tWrGTJkCIcOHaK5uZm4uLhAu5fXeLXXupry8nKWL1/Ohx9+GKjremgEOkhNtgFHlAK0iIiIhEdCQgLZ2dkUFRUFRp/Pnz9Pv379GDBgAGfPnmX79u0dtnHHHXewZcsWLl68SE1NDe+8805gX01NDUOHDsXr9bJ58+bA9htuuIGampo2baWkpODxeDhx4gQAJSUl3HnnnUG/n+rqaoYOHUpUVBQlJSU0NTUBcPfdd7NhwwZqa2sBqKqqon///iQlJVFWVgZAfX19YP/VHDhwgHnz5rF161YSExODrq8jCtBBsNbSTCMO+oS7FBEREYlgBQUFHDp0iFmzZgGQnp5ORkYGY8eOpaioiIkTJ3Z4vsvlYubMmTidTqZPn05WVlZg3wsvvMDtt9/OXXfdRUpKSmD7rFmzePHFF8nIyLjkxr24uDhee+018vPzSU1NJSoqikceeSTo97JgwQI2bdrEhAkTqKyspF+/fgBMnTqV3Nxc3G43TqczsMxeSUkJa9asIS0tjczMTM6cOdOmzdraWpKSkgJfq1atYsmSJVy4cIH8/HycTucl01aulbneIfHu5na7bcuaht3F2+TF9bqL+D9NY++Cv+/W1xYREZHwO3LkCGPGjAl3GdKF2vseG2P2WWvdlx+rEegg1Df5lmSJNprCISIiIhLpFKCD0NDcAEBMlKZwiIiIiEQ6BeggNDQpQIuIiIiIjwJ0EFqmcChAi4iIiIgCdBBaRqD7OK5/3UARERER6d0UoIMQCNBaB1pEREQk4ilAB6FlCodGoEVERCQczp07h9PpxOl0cvPNNzNs2LDA84aGhg7PraioYOHChVd9jczMzM4q9wdPH+UdhEFxg4j5UyY3DL4p3KWIiIhIBBo8eDAHDx4E4LnnniMhIYEnnngisL+xsZHo6PZjndvtxu1us5RxG3v27OmcYiOARqCDMHzAcKKqZjCoT1K4SxEREREBoLCwkMWLFzN58mSefPJJPv74YzIzM8nIyCAzM5Njx44BsGvXLqZNmwb4wndRURHZ2dmMGDGCNWvWBNpLSEgIHJ+dnc2MGTNISUlh9uzZtHzw3rZt20hJSWHSpEksXLgw0G5rHo+HrKwsXC4XLpfrkmC+YsUKUlNTSU9Pp7i4GIATJ06Qk5NDeno6Lpfrkk877Kk0Ah2k+sZm+kTr/xsiIiKR7tcf/5qjVUc7tc2UQSk8Of7JkM+rrKykvLwch8PB+fPn2b17N9HR0ZSXl/P000/z9ttvtznn6NGjfPDBB9TU1DB69Gjmz59PTMyl93kdOHCAw4cPc8sttzBx4kR++9vf4na7mTdvHrt37yY5OZmCgoJ2a0pMTGTHjh3ExcVx/PhxCgoKqKioYPv27ZSVlbF3717i4+OpqqoCYPbs2RQXF5OXl0ddXR3Nzc0h90N3U4AOUn1jM7HRjnCXISIiIhKQn5+Pw+HLJ9XV1cyZM4fjx49jjMHr9bZ7zn333UdsbCyxsbEkJiZy9uxZkpIu/S37+PHjA9ucTicej4eEhARGjBhBcnIyAAUFBbzyyitt2vd6vTz22GMcPHgQh8NBZWUlAOXl5cydO5f4+HgABg0aRE1NDadPnyYvLw+AuLi4TuiVrqcAHQRrLQ0agRYRERG4ppHirtKvX7/A41/96ldMnjyZLVu24PF4yM7Obvec2NjvF0VwOBw0NjYGdUzLNI6rWb16NUOGDOHQoUM0NzcHQrG1FmPMJccG22ZPo0QYBG+T75sbqwAtIiIiPVR1dTXDhg0DYOPGjZ3efkpKCl988QUejweAN95444p1DB06lKioKEpKSmhqagLg7rvvZsOGDdTW1gJQVVVF//79SUpKoqysDID6+vrA/p5MiTAI9Y2+b7wCtIiIiPRUS5cu5amnnmLixImB0NqZ+vbty9q1a5k6dSqTJk1iyJAhDBgwoM1xCxYsYNOmTUyYMIHKysrAKPnUqVPJzc3F7XbjdDpZuXIlACUlJaxZs4a0tDQyMzM5c+ZMp9fe2UxvGzp3u922oqKiW1/z3IV6xv1tOc/fP5aH/mJ4t762iIiIhN+RI0cYM2ZMuMsIuwsXLpCQkIC1lkcffZSRI0eyaNGicJfVKdr7Hhtj9llr26wBqCHVIDQ0+e4G7eNQd4mIiEjkWrduHU6nk7Fjx1JdXc28efPCXVJY6CbCINR7fQE6NkYBWkRERCLXokWLfjAjztdDiTAI349Aaxk7ERERkUinAB2EhkZ/gNZNhCIiIiIRT4kwCFqFQ0RERERaKBEGITbagfPWgdwY3yfcpYiIiIhImClAB+EnwwZQ9uhEUpParnUoIiIi0tWys7N5//33L9n20ksvsWDBgg7PaVn699577+W7775rc8xzzz0XWI/5SsrKyvj8888Dz5999lnKy8tDKf8HRwFaREREpIcrKCigtLT0km2lpaUUFBQEdf62bdsYOHDgNb325QH6+eefJycn55ra+qFQgBYRERHp4WbMmMG7775LfX09AB6Ph6+++opJkyYxf/583G43Y8eOZdmyZe2eP3z4cL799lsAli9fzujRo8nJyeHYsWOBY9atW8dPf/pT0tPTmT59OrW1tezZs4etW7eyZMkSnE4nJ0+epLCwkLfeeguAnTt3kpGRQWpqKkVFRYH6hg8fzrJly3C5XKSmpnL06NE2NXk8HrKysnC5XLhcLvbs2RPYt2LFClJTU0lPT6e4uBiAEydOkJOTQ3p6Oi6Xi5MnT3ZCz14brQMtIiIiEoIzf/d31B9pGwivR+yYFG5++ukr7h88eDDjx4/nvffe4/7776e0tJSZM2dijGH58uUMGjSIpqYmpkyZwqeffkpaWlq77ezbt4/S0lIOHDhAY2MjLpeLcePGAfDggw/y8MMPA/DMM8+wfv16fvGLX5Cbm8u0adOYMWPGJW3V1dVRWFjIzp07GTVqFA899BAvv/wyjz/+OAA33XQT+/fvZ+3ataxcuZJXX331kvMTExPZsWMHcXFxHD9+nIKCAioqKti+fTtlZWXs3buX+Ph4qqqqAJg9ezbFxcXk5eVRV1dHc3PztXV2J9AItIiIiEgv0HoaR+vpG2+++SYul4uMjAwOHz58yXSLy3300Ufk5eURHx9P//79yc3NDez77LPPyMrKIjU1lc2bN3P48OEO6zl27BjJycmMGjUKgDlz5rB79+7A/gcffBCAcePG4fF42pzv9Xp5+OGHSU1NJT8/P1B3eXk5c+fOJT4+HoBBgwZRU1PD6dOnycvLAyAuLi6wPxw0Ai0iIiISgo5GirvSAw88wOLFi9m/fz8XL17E5XLx5ZdfsnLlSj755BNuvPFGCgsLqaur67AdY0y72wsLCykrKyM9PZ2NGzeya9euDtux1na4PzY2FgCHw0FjY2Ob/atXr2bIkCEcOnSI5uZm4uLiAu1eXuPVXqu7aQRaREREpBdISEggOzuboqKiwOjz+fPn6devHwMGDODs2bNs3769wzbuuOMOtmzZwsWLF6mpqeGdd94J7KupqWHo0KF4vV42b94c2H7DDTdQU1PTpq2UlBQ8Hg8nTpwAoKSkhDvvvDPo91NdXc3QoUOJioqipKSEpibf527cfffdbNiwgdraWgCqqqro378/SUlJlJWVAVBfXx/YHw4K0CIiIiK9REFBAYcOHWLWrFkApKenk5GRwdixYykqKmLixIkdnu9yuZg5cyZOp5Pp06eTlZUV2PfCCy9w++23c9ddd5GSkhLYPmvWLF588UUyMjIuuXEvLi6O1157jfz8fFJTU4mKiuKRRx4J+r0sWLCATZs2MWHCBCorK+nXrx8AU6dOJTc3F7fbjdPpDCyzV1JSwpo1a0hLSyMzM5MzZ84E/VqdzfS0IfGrcbvdtmVNQxEREZHucOTIEcaMGRPuMqQLtfc9Nsbss9a6Lz9WI9AiIiIiIiFQgBYRERERCYECtIiIiIhICBSgRURERILQ2+4bk+CF+r1VgBYRERG5iri4OM6dO6cQ/QNkreXcuXOBdaiDoQ9SEREREbmKpKQkTp06xTfffBPuUqQLxMXFkZSUFPTxCtAiIiIiVxETE0NycnK4y5AeQlM4RERERERCoAAtIiIiIhICBWgRERERkRD0uo/yNsZ8A/yhG17qJuDbbnidHzr1Y+dQP3YO9eP1Ux92DvVj51A/Xj/1Ycf+zFr7o8s39roA3V2MMRXtffa5hEb92DnUj51D/Xj91IedQ/3YOdSP1099eG00hUNEREREJAQK0CIiIiIiIVCAvrJXwl3AD4T6sXOoHzuH+vH6qQ87h/qxc6gfr5/68BpoDrSIiIiISAg0Ai0iIiIiEgIF6HYYY6YaY44ZY04YY4rDXU9vYYy51RjzgTHmiDHmsDHml/7tg4wxO4wxx/1/3hjuWns6Y4zDGHPAGPOu/3myMWavvw/fMMb0CXeNPZ0xZqAx5i1jzFH/NfkXuhZDZ4xZ5P/7/Jkx5l+MMXG6Hq/OGLPBGPNHY8xnrba1e/0ZnzX+nzmfGmNc4au857hCH77o/zv9qTFmizFmYKt9T/n78Jgx5r+Gp+qep71+bLXvCWOMNcbc5H+uazFICtCXMcY4gN8A9wC3AQXGmNvCW1Wv0Qj8T2vtGGAC8Ki/74qBndbakcBO/3Pp2C+BI62e/xpY7e/D/wT+MixV9S7/CLxnrU0B0vH1p67FEBhjhgELAbe19ieAA5iFrsdgbASmXrbtStffPcBI/9fPgZe7qcaebiNt+3AH8BNrbRpQCTwF4P9ZMwsY6z9nrf/nubTfjxhjbgXuAv691WZdi0FSgG5rPHDCWvuFtbYBKAXuD3NNvYK19mtr7X7/4xp8gWUYvv7b5D9sE/BAeCrsHYwxScB9wKv+5wb4GfCW/xD14VUYY/oDdwDrAay1Ddba79C1eC2igb7GmGggHvgaXY9XZa3dDVRdtvlK19/9wD9bn98BA40xQ7un0p6rvT601v6btbbR//R3QJL/8f1AqbW23lr7JXAC38/ziHeFaxFgNbAUaH0znK7FIClAtzUM+I9Wz0/5t0kIjDHDgQxgLzDEWvs1+EI2kBi+ynqFl/D9o9bsfz4Y+K7VDw1dk1c3AvgGeM0/FeZVY0w/dC2GxFp7GliJb4Tqa6Aa2Ieux2t1petPP3euTRGw3f9YfRgCY0wucNpae+iyXerHIClAt2Xa2aalSkJgjEkA3gYet9aeD3c9vYkxZhrwR2vtvtab2zlU12THogEX8LK1NgP4E5quETL/HN37gWTgFqAfvl/xXk7X4/XR3/EQGWP+Gt+0wc0tm9o5TH3YDmNMPPDXwLPt7W5nm/qxHQrQbZ0Cbm31PAn4Kky19DrGmBh84XmztfZf/ZvPtvwKyP/nH8NVXy8wEcg1xnjwTR/6Gb4R6YH+X6GDrslgnAJOWWv3+p+/hS9Q61oMTQ7wpbX2G2utF/hXIBNdj9fqSteffu6EwBgzB5gGzLbfr8WrPgzen+P7T/Eh/8+aJGC/MeZm1I9BU4Bu6xNgpP8u8z74bkrYGuaaegX/XN31wBFr7apWu7YCc/yP5wD/u7tr6y2stU9Za5OstcPxXXv/x1o7G/gAmOE/TH14FdbaM8B/GGNG+zdNAT5H12Ko/h2YYIyJ9//9bulHXY/X5krX31bgIf8KCBOA6papHnIpY8xU4Ekg11pb22rXVmCWMSbWGJOM7ya4j8NRY09nrf29tTbRWjvc/7PmFODy/7upazFI+iCVdhhj7sU36ucANlhrl4e5pF7BGDMJ+Aj4Pd/P330a3zzoN4Ef4/uBnG+tbe+GBmnFGJMNPGGtnWaMGYFvRHoQcAD479ba+nDW19MZY5z4bsTsA3wBzMU3aKBrMQTGmL8BZuL7dfkB4K/wzYnU9dgBY8y/ANnATcBZYBlQRjvXn/8/J/+Eb6WEWmCutbYiHHX3JFfow6eAWOCc/7DfWWsf8R//1/jmRTfim0K4/fI2I1F7/WitXd9qvwffSjvf6loMngK0iIiIiEgINIVDRERERCQECtAiIiIiIiFQgBYRERERCYECtIiIiIhICBSgRURERERCoAAtItLDGWOajDEHW3112qcqGmOGG2M+66z2REQiQfTVDxERkTC7aK11hrsIERHx0Qi0iEgvZYzxGGN+bYz52P/1X/zb/8wYs9MY86n/zx/7tw8xxmwxxhzyf2X6m3IYY9YZYw4bY/7NGNPXf/xCY8zn/nZKw/Q2RUR6HAVoEZGer+9lUzhmttp33lo7Ht+nh73k3/ZPwD9ba9OAzcAa//Y1wIfW2nTABRz2bx8J/MZaOxb4Dpju314MZPjbeaSr3pyISG+jTyIUEenhjDEXrLUJ7Wz3AD+z1n5hjIkBzlhrBxtjvgWGWmu9/u1fW2tvMsZ8AyS1/thtY8xwYIe1dqT/+ZNAjLX2b40x7wEX8H0EdZm19kIXv1URkV5BI9AiIr2bvcLjKx3TnvpWj5v4/v6Y+4DfAOOAfcYY3TcjIoICtIhIbzez1Z//z/94DzDL/3g28H/9j3cC8wGMMQ5jTP8rNWqMiQJutdZ+ACwFBgJtRsFFRCKRRhNERHq+vsaYg62ev2etbVnKLtYYsxffgEiBf9tCYIMxZgnwDTDXv/2XwCvGmL/EN9I8H/j6Cq/pAF43xgwADLDaWvtdp70jEZFeTHOgRUR6Kf8caLe19ttw1yIiEkk0hUNEREREJAQagRYRERERCYFGoEVEREREQqAALSIiIiISAgVoEREREZEQKECLiIiIiIRAAVpEREREJAQK0CIiIiIiIfj/c9ggB2A9rB8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# L2 model details\n",
    "L2_model_dict = L2_model_val.history\n",
    "L2_acc_values = L2_model_dict['accuracy'] \n",
    "L2_val_acc_values = L2_model_dict['val_accuracy']\n",
    "\n",
    "# Baseline model\n",
    "baseline_model_acc = baseline_model_val_dict['accuracy'] \n",
    "baseline_model_val_acc = baseline_model_val_dict['val_accuracy']\n",
    "\n",
    "# Plot the accuracy for these models\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "epochs = range(1, len(L2_acc_values) + 1)\n",
    "ax.plot(epochs, L2_acc_values, label='Training acc L2')\n",
    "ax.plot(epochs, L2_val_acc_values, label='Validation acc L2')\n",
    "ax.plot(epochs, baseline_model_acc, label='Training acc')\n",
    "ax.plot(epochs, baseline_model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better.  \n",
    "\n",
    "\n",
    "## L1 Regularization\n",
    "\n",
    "Now have a look at L1 regularization. Will this work better? \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L1 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 13.6476 - accuracy: 0.2299 - val_loss: 11.1246 - val_accuracy: 0.3300\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 8.9742 - accuracy: 0.4506 - val_loss: 7.0282 - val_accuracy: 0.5190\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 5.4870 - accuracy: 0.5946 - val_loss: 4.1749 - val_accuracy: 0.6190\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 3.2593 - accuracy: 0.6516 - val_loss: 2.5716 - val_accuracy: 0.6530\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 2.2284 - accuracy: 0.6737 - val_loss: 2.0609 - val_accuracy: 0.6550\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 1.9690 - accuracy: 0.6815 - val_loss: 1.9158 - val_accuracy: 0.6640\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 1.8470 - accuracy: 0.6876 - val_loss: 1.8078 - val_accuracy: 0.6830\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 1.7516 - accuracy: 0.6938 - val_loss: 1.7212 - val_accuracy: 0.6840\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 1.6720 - accuracy: 0.6995 - val_loss: 1.6443 - val_accuracy: 0.6860\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 3s 51us/step - loss: 1.6034 - accuracy: 0.7030 - val_loss: 1.5823 - val_accuracy: 0.6980\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 3s 55us/step - loss: 1.5424 - accuracy: 0.7081 - val_loss: 1.5220 - val_accuracy: 0.6980\n",
      "Epoch 12/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 1.4873 - accuracy: 0.7125 - val_loss: 1.4697 - val_accuracy: 0.7000\n",
      "Epoch 13/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 1.4374 - accuracy: 0.7156 - val_loss: 1.4251 - val_accuracy: 0.6970\n",
      "Epoch 14/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 1.3921 - accuracy: 0.7185 - val_loss: 1.3803 - val_accuracy: 0.7040\n",
      "Epoch 15/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 1.3509 - accuracy: 0.7209 - val_loss: 1.3406 - val_accuracy: 0.7060\n",
      "Epoch 16/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 1.3128 - accuracy: 0.7232 - val_loss: 1.3018 - val_accuracy: 0.7080\n",
      "Epoch 17/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 1.2776 - accuracy: 0.7260 - val_loss: 1.2675 - val_accuracy: 0.7120\n",
      "Epoch 18/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 1.2453 - accuracy: 0.7268 - val_loss: 1.2402 - val_accuracy: 0.7190\n",
      "Epoch 19/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 1.2159 - accuracy: 0.7295 - val_loss: 1.2092 - val_accuracy: 0.7170\n",
      "Epoch 20/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 1.1899 - accuracy: 0.7308 - val_loss: 1.1905 - val_accuracy: 0.7190\n",
      "Epoch 21/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 1.1665 - accuracy: 0.7322 - val_loss: 1.1631 - val_accuracy: 0.7140\n",
      "Epoch 22/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 1.1459 - accuracy: 0.7335 - val_loss: 1.1415 - val_accuracy: 0.7230\n",
      "Epoch 23/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 1.1276 - accuracy: 0.7351 - val_loss: 1.1296 - val_accuracy: 0.7180\n",
      "Epoch 24/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 1.1114 - accuracy: 0.7365 - val_loss: 1.1140 - val_accuracy: 0.7210\n",
      "Epoch 25/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 1.0977 - accuracy: 0.7374 - val_loss: 1.1050 - val_accuracy: 0.7230\n",
      "Epoch 26/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 1.0856 - accuracy: 0.7382 - val_loss: 1.0954 - val_accuracy: 0.7220\n",
      "Epoch 27/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 1.0745 - accuracy: 0.7397 - val_loss: 1.0832 - val_accuracy: 0.7200\n",
      "Epoch 28/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 1.0644 - accuracy: 0.7407 - val_loss: 1.0696 - val_accuracy: 0.7230\n",
      "Epoch 29/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 1.0549 - accuracy: 0.7418 - val_loss: 1.0642 - val_accuracy: 0.7200\n",
      "Epoch 30/150\n",
      "57500/57500 [==============================] - 3s 54us/step - loss: 1.0463 - accuracy: 0.7425 - val_loss: 1.0537 - val_accuracy: 0.7260\n",
      "Epoch 31/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 1.0385 - accuracy: 0.7441 - val_loss: 1.0457 - val_accuracy: 0.7310\n",
      "Epoch 32/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 1.0308 - accuracy: 0.7448 - val_loss: 1.0394 - val_accuracy: 0.7330\n",
      "Epoch 33/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 1.0234 - accuracy: 0.7457 - val_loss: 1.0338 - val_accuracy: 0.7240\n",
      "Epoch 34/150\n",
      "57500/57500 [==============================] - 4s 65us/step - loss: 1.0167 - accuracy: 0.7449 - val_loss: 1.0285 - val_accuracy: 0.7330\n",
      "Epoch 35/150\n",
      "57500/57500 [==============================] - 4s 62us/step - loss: 1.0103 - accuracy: 0.7471 - val_loss: 1.0250 - val_accuracy: 0.7290\n",
      "Epoch 36/150\n",
      "57500/57500 [==============================] - 3s 57us/step - loss: 1.0041 - accuracy: 0.7483 - val_loss: 1.0156 - val_accuracy: 0.7290\n",
      "Epoch 37/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 0.9984 - accuracy: 0.7490 - val_loss: 1.0103 - val_accuracy: 0.7300\n",
      "Epoch 38/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.9930 - accuracy: 0.7492 - val_loss: 1.0052 - val_accuracy: 0.7320\n",
      "Epoch 39/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.9877 - accuracy: 0.7498 - val_loss: 1.0046 - val_accuracy: 0.7280\n",
      "Epoch 40/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.9831 - accuracy: 0.7506 - val_loss: 0.9979 - val_accuracy: 0.7300\n",
      "Epoch 41/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.9784 - accuracy: 0.7512 - val_loss: 0.9942 - val_accuracy: 0.7290\n",
      "Epoch 42/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.9741 - accuracy: 0.7518 - val_loss: 0.9902 - val_accuracy: 0.7320\n",
      "Epoch 43/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.9702 - accuracy: 0.7526 - val_loss: 0.9874 - val_accuracy: 0.7330\n",
      "Epoch 44/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.9664 - accuracy: 0.7528 - val_loss: 0.9808 - val_accuracy: 0.7320\n",
      "Epoch 45/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.9627 - accuracy: 0.7536 - val_loss: 0.9832 - val_accuracy: 0.7280\n",
      "Epoch 46/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.9590 - accuracy: 0.7543 - val_loss: 0.9793 - val_accuracy: 0.7370\n",
      "Epoch 47/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 0.9557 - accuracy: 0.7545 - val_loss: 0.9703 - val_accuracy: 0.7380\n",
      "Epoch 48/150\n",
      "57500/57500 [==============================] - 3s 51us/step - loss: 0.9523 - accuracy: 0.7547 - val_loss: 0.9685 - val_accuracy: 0.7340\n",
      "Epoch 49/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.9496 - accuracy: 0.7556 - val_loss: 0.9804 - val_accuracy: 0.7250\n",
      "Epoch 50/150\n",
      "57500/57500 [==============================] - 3s 51us/step - loss: 0.9464 - accuracy: 0.7561 - val_loss: 0.9614 - val_accuracy: 0.7390\n",
      "Epoch 51/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.9433 - accuracy: 0.7564 - val_loss: 0.9653 - val_accuracy: 0.7410\n",
      "Epoch 52/150\n",
      "57500/57500 [==============================] - 3s 60us/step - loss: 0.9406 - accuracy: 0.7572 - val_loss: 0.9626 - val_accuracy: 0.7340\n",
      "Epoch 53/150\n",
      "57500/57500 [==============================] - 3s 54us/step - loss: 0.9381 - accuracy: 0.7571 - val_loss: 0.9585 - val_accuracy: 0.7340\n",
      "Epoch 54/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.9357 - accuracy: 0.7573 - val_loss: 0.9532 - val_accuracy: 0.7340\n",
      "Epoch 55/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.9336 - accuracy: 0.7577 - val_loss: 0.9543 - val_accuracy: 0.7370\n",
      "Epoch 56/150\n",
      "57500/57500 [==============================] - 3s 56us/step - loss: 0.9309 - accuracy: 0.7582 - val_loss: 0.9576 - val_accuracy: 0.7390\n",
      "Epoch 57/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.9289 - accuracy: 0.7583 - val_loss: 0.9495 - val_accuracy: 0.7370\n",
      "Epoch 58/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.9267 - accuracy: 0.7589 - val_loss: 0.9455 - val_accuracy: 0.7400\n",
      "Epoch 59/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.9248 - accuracy: 0.7591 - val_loss: 0.9434 - val_accuracy: 0.7480\n",
      "Epoch 60/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.9230 - accuracy: 0.7590 - val_loss: 0.9411 - val_accuracy: 0.7390\n",
      "Epoch 61/150\n",
      "57500/57500 [==============================] - 3s 57us/step - loss: 0.9213 - accuracy: 0.7595 - val_loss: 0.9382 - val_accuracy: 0.7410\n",
      "Epoch 62/150\n",
      "57500/57500 [==============================] - 3s 54us/step - loss: 0.9194 - accuracy: 0.7602 - val_loss: 0.9372 - val_accuracy: 0.7400\n",
      "Epoch 63/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 0.9174 - accuracy: 0.7600 - val_loss: 0.9390 - val_accuracy: 0.7400\n",
      "Epoch 64/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.9161 - accuracy: 0.7595 - val_loss: 0.9378 - val_accuracy: 0.7370\n",
      "Epoch 65/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.9146 - accuracy: 0.7601 - val_loss: 0.9347 - val_accuracy: 0.7450\n",
      "Epoch 66/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.9126 - accuracy: 0.7607 - val_loss: 0.9323 - val_accuracy: 0.7420\n",
      "Epoch 67/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.9116 - accuracy: 0.7605 - val_loss: 0.9328 - val_accuracy: 0.7430\n",
      "Epoch 68/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.9094 - accuracy: 0.7612 - val_loss: 0.9358 - val_accuracy: 0.7420\n",
      "Epoch 69/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.9079 - accuracy: 0.7618 - val_loss: 0.9476 - val_accuracy: 0.7300\n",
      "Epoch 70/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.9068 - accuracy: 0.7614 - val_loss: 0.9295 - val_accuracy: 0.7430\n",
      "Epoch 71/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.9050 - accuracy: 0.7623 - val_loss: 0.9268 - val_accuracy: 0.7380\n",
      "Epoch 72/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.9037 - accuracy: 0.7624 - val_loss: 0.9268 - val_accuracy: 0.7420\n",
      "Epoch 73/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.9023 - accuracy: 0.7625 - val_loss: 0.9250 - val_accuracy: 0.7450\n",
      "Epoch 74/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.9008 - accuracy: 0.7627 - val_loss: 0.9262 - val_accuracy: 0.7440\n",
      "Epoch 75/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8996 - accuracy: 0.7621 - val_loss: 0.9236 - val_accuracy: 0.7450\n",
      "Epoch 76/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8982 - accuracy: 0.7619 - val_loss: 0.9277 - val_accuracy: 0.7370\n",
      "Epoch 77/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.8967 - accuracy: 0.7630 - val_loss: 0.9217 - val_accuracy: 0.7460\n",
      "Epoch 78/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.8951 - accuracy: 0.7644 - val_loss: 0.9188 - val_accuracy: 0.7490\n",
      "Epoch 79/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.8946 - accuracy: 0.7639 - val_loss: 0.9190 - val_accuracy: 0.7420\n",
      "Epoch 80/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.8929 - accuracy: 0.7634 - val_loss: 0.9225 - val_accuracy: 0.7420\n",
      "Epoch 81/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.8916 - accuracy: 0.7643 - val_loss: 0.9165 - val_accuracy: 0.7450\n",
      "Epoch 82/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.8908 - accuracy: 0.7645 - val_loss: 0.9126 - val_accuracy: 0.7510\n",
      "Epoch 83/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.8894 - accuracy: 0.7643 - val_loss: 0.9180 - val_accuracy: 0.7490\n",
      "Epoch 84/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8889 - accuracy: 0.7648 - val_loss: 0.9116 - val_accuracy: 0.7480\n",
      "Epoch 85/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.8874 - accuracy: 0.7642 - val_loss: 0.9120 - val_accuracy: 0.7430\n",
      "Epoch 86/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.8863 - accuracy: 0.7649 - val_loss: 0.9148 - val_accuracy: 0.7430\n",
      "Epoch 87/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.8853 - accuracy: 0.7654 - val_loss: 0.9078 - val_accuracy: 0.7510\n",
      "Epoch 88/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.8843 - accuracy: 0.7653 - val_loss: 0.9114 - val_accuracy: 0.7410\n",
      "Epoch 89/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.8833 - accuracy: 0.7662 - val_loss: 0.9135 - val_accuracy: 0.7450\n",
      "Epoch 90/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.8825 - accuracy: 0.7653 - val_loss: 0.9154 - val_accuracy: 0.7420\n",
      "Epoch 91/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.8811 - accuracy: 0.7661 - val_loss: 0.9041 - val_accuracy: 0.7400\n",
      "Epoch 92/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8805 - accuracy: 0.7662 - val_loss: 0.9079 - val_accuracy: 0.7470\n",
      "Epoch 93/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8799 - accuracy: 0.7663 - val_loss: 0.9038 - val_accuracy: 0.7420\n",
      "Epoch 94/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.8785 - accuracy: 0.7660 - val_loss: 0.9057 - val_accuracy: 0.7500\n",
      "Epoch 95/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.8779 - accuracy: 0.7662 - val_loss: 0.9058 - val_accuracy: 0.7450\n",
      "Epoch 96/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8765 - accuracy: 0.7664 - val_loss: 0.9001 - val_accuracy: 0.7460\n",
      "Epoch 97/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.8758 - accuracy: 0.7677 - val_loss: 0.8993 - val_accuracy: 0.7500\n",
      "Epoch 98/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.8748 - accuracy: 0.7673 - val_loss: 0.9094 - val_accuracy: 0.7420\n",
      "Epoch 99/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.8739 - accuracy: 0.7676 - val_loss: 0.9005 - val_accuracy: 0.7480\n",
      "Epoch 100/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.8729 - accuracy: 0.7677 - val_loss: 0.8972 - val_accuracy: 0.7470\n",
      "Epoch 101/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.8726 - accuracy: 0.7671 - val_loss: 0.8983 - val_accuracy: 0.7420\n",
      "Epoch 102/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8718 - accuracy: 0.7673 - val_loss: 0.8951 - val_accuracy: 0.7520\n",
      "Epoch 103/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.8702 - accuracy: 0.7671 - val_loss: 0.8939 - val_accuracy: 0.7500\n",
      "Epoch 104/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.8696 - accuracy: 0.7684 - val_loss: 0.8981 - val_accuracy: 0.7540\n",
      "Epoch 105/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.8687 - accuracy: 0.7675 - val_loss: 0.8940 - val_accuracy: 0.7420\n",
      "Epoch 106/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.8683 - accuracy: 0.7691 - val_loss: 0.8969 - val_accuracy: 0.7470\n",
      "Epoch 107/150\n",
      "57500/57500 [==============================] - 3s 50us/step - loss: 0.8675 - accuracy: 0.7686 - val_loss: 0.8973 - val_accuracy: 0.7450\n",
      "Epoch 108/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 0.8667 - accuracy: 0.7682 - val_loss: 0.8899 - val_accuracy: 0.7540\n",
      "Epoch 109/150\n",
      "57500/57500 [==============================] - 3s 54us/step - loss: 0.8654 - accuracy: 0.7685 - val_loss: 0.8918 - val_accuracy: 0.7520\n",
      "Epoch 110/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 3s 54us/step - loss: 0.8651 - accuracy: 0.7687 - val_loss: 0.8893 - val_accuracy: 0.7420\n",
      "Epoch 111/150\n",
      "57500/57500 [==============================] - 3s 55us/step - loss: 0.8639 - accuracy: 0.7693 - val_loss: 0.8987 - val_accuracy: 0.7410\n",
      "Epoch 112/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.8628 - accuracy: 0.7687 - val_loss: 0.8927 - val_accuracy: 0.7430\n",
      "Epoch 113/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.8623 - accuracy: 0.7694 - val_loss: 0.8898 - val_accuracy: 0.7450\n",
      "Epoch 114/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.8617 - accuracy: 0.7691 - val_loss: 0.8849 - val_accuracy: 0.7480\n",
      "Epoch 115/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.8610 - accuracy: 0.7690 - val_loss: 0.8850 - val_accuracy: 0.7470\n",
      "Epoch 116/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.8598 - accuracy: 0.7695 - val_loss: 0.8891 - val_accuracy: 0.7480\n",
      "Epoch 117/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.8591 - accuracy: 0.7697 - val_loss: 0.8889 - val_accuracy: 0.7430\n",
      "Epoch 118/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.8592 - accuracy: 0.7694 - val_loss: 0.8852 - val_accuracy: 0.7430\n",
      "Epoch 119/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.8579 - accuracy: 0.7701 - val_loss: 0.8803 - val_accuracy: 0.7540\n",
      "Epoch 120/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.8572 - accuracy: 0.7706 - val_loss: 0.8783 - val_accuracy: 0.7500\n",
      "Epoch 121/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.8562 - accuracy: 0.7706 - val_loss: 0.8893 - val_accuracy: 0.7420\n",
      "Epoch 122/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.8552 - accuracy: 0.7712 - val_loss: 0.8826 - val_accuracy: 0.7530\n",
      "Epoch 123/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.8549 - accuracy: 0.7705 - val_loss: 0.8863 - val_accuracy: 0.7400\n",
      "Epoch 124/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8541 - accuracy: 0.7697 - val_loss: 0.8816 - val_accuracy: 0.7440\n",
      "Epoch 125/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8535 - accuracy: 0.7703 - val_loss: 0.8837 - val_accuracy: 0.7510\n",
      "Epoch 126/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8530 - accuracy: 0.7713 - val_loss: 0.8849 - val_accuracy: 0.7440\n",
      "Epoch 127/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.8520 - accuracy: 0.7708 - val_loss: 0.8759 - val_accuracy: 0.7450\n",
      "Epoch 128/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.8511 - accuracy: 0.7705 - val_loss: 0.8885 - val_accuracy: 0.7470\n",
      "Epoch 129/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.8516 - accuracy: 0.7701 - val_loss: 0.8786 - val_accuracy: 0.7480\n",
      "Epoch 130/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.8502 - accuracy: 0.7709 - val_loss: 0.8755 - val_accuracy: 0.7500\n",
      "Epoch 131/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.8497 - accuracy: 0.7703 - val_loss: 0.8791 - val_accuracy: 0.7440\n",
      "Epoch 132/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.8486 - accuracy: 0.7717 - val_loss: 0.8835 - val_accuracy: 0.7510\n",
      "Epoch 133/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.8490 - accuracy: 0.7698 - val_loss: 0.8788 - val_accuracy: 0.7450\n",
      "Epoch 134/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.8473 - accuracy: 0.7713 - val_loss: 0.8827 - val_accuracy: 0.7540\n",
      "Epoch 135/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.8477 - accuracy: 0.7713 - val_loss: 0.8826 - val_accuracy: 0.7530\n",
      "Epoch 136/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.8469 - accuracy: 0.7717 - val_loss: 0.8730 - val_accuracy: 0.7530\n",
      "Epoch 137/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.8457 - accuracy: 0.7720 - val_loss: 0.8814 - val_accuracy: 0.7510\n",
      "Epoch 138/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.8456 - accuracy: 0.7714 - val_loss: 0.8885 - val_accuracy: 0.7520\n",
      "Epoch 139/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.8451 - accuracy: 0.7718 - val_loss: 0.8704 - val_accuracy: 0.7460\n",
      "Epoch 140/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.8451 - accuracy: 0.7715 - val_loss: 0.8657 - val_accuracy: 0.7580\n",
      "Epoch 141/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.8443 - accuracy: 0.7718 - val_loss: 0.8665 - val_accuracy: 0.7520\n",
      "Epoch 142/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8435 - accuracy: 0.7715 - val_loss: 0.8674 - val_accuracy: 0.7540\n",
      "Epoch 143/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.8433 - accuracy: 0.7721 - val_loss: 0.8882 - val_accuracy: 0.7500\n",
      "Epoch 144/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.8431 - accuracy: 0.7718 - val_loss: 0.8700 - val_accuracy: 0.7530\n",
      "Epoch 145/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.8423 - accuracy: 0.7717 - val_loss: 0.8678 - val_accuracy: 0.7530\n",
      "Epoch 146/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8421 - accuracy: 0.7725 - val_loss: 0.8734 - val_accuracy: 0.7480\n",
      "Epoch 147/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.8415 - accuracy: 0.7716 - val_loss: 0.8731 - val_accuracy: 0.7530\n",
      "Epoch 148/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.8417 - accuracy: 0.7711 - val_loss: 0.8764 - val_accuracy: 0.7500\n",
      "Epoch 149/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.8409 - accuracy: 0.7723 - val_loss: 0.8626 - val_accuracy: 0.7480\n",
      "Epoch 150/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.8398 - accuracy: 0.7724 - val_loss: 0.8722 - val_accuracy: 0.7380\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random.seed(123)\n",
    "L1_model = models.Sequential()\n",
    "lambda_coef = .005 \n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L1_model.add(layers.Dense(50, activation='relu', \n",
    "                          kernel_regularizer=regularizers.l1(lambda_coef), \n",
    "                          input_shape=(2000,)))\n",
    "\n",
    "# Add a hidden layer\n",
    "L1_model.add(layers.Dense(25, activation='relu', \n",
    "                         kernel_regularizer=regularizers.l1(0.005)))\n",
    "\n",
    "# Add an output layer\n",
    "L1_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L1_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L1_model_val = L1_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training as well as the validation accuracy for the L1 model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model_val.history\n",
    "\n",
    "acc_values = L1_model_dict['accuracy'] \n",
    "val_acc_values = L1_model_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy isn't still that good. Next, experiment with dropout regularization to see if it offers any advantages. \n",
    "\n",
    "\n",
    "## Dropout Regularization \n",
    "\n",
    "It's time to try another technique: applying dropout to layers. As discussed in the earlier lesson, this involves setting a certain proportion of units in each layer to zero. In the following cell: \n",
    "\n",
    "- Apply a dropout rate of 30% to the input layer \n",
    "- Add a first hidden layer with 50 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the first hidden layer \n",
    "- Add a second hidden layer with 25 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the second hidden layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 8s 132us/step - loss: 1.9386 - accuracy: 0.1747 - val_loss: 1.8971 - val_accuracy: 0.2250\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 4s 75us/step - loss: 1.8833 - accuracy: 0.2265 - val_loss: 1.8286 - val_accuracy: 0.2620\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 1.8171 - accuracy: 0.2721 - val_loss: 1.7189 - val_accuracy: 0.3570\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 4s 75us/step - loss: 1.7122 - accuracy: 0.3296 - val_loss: 1.5557 - val_accuracy: 0.4650\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 1.5892 - accuracy: 0.3882 - val_loss: 1.3704 - val_accuracy: 0.5340\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 1.4676 - accuracy: 0.4375 - val_loss: 1.2126 - val_accuracy: 0.6040\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 4s 75us/step - loss: 1.3702 - accuracy: 0.4761 - val_loss: 1.0977 - val_accuracy: 0.6520\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 1.2821 - accuracy: 0.5147 - val_loss: 1.0030 - val_accuracy: 0.6750\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 1.2194 - accuracy: 0.5404 - val_loss: 0.9305 - val_accuracy: 0.6880\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 1.1703 - accuracy: 0.5619 - val_loss: 0.8758 - val_accuracy: 0.7080\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 1.1199 - accuracy: 0.5825 - val_loss: 0.8325 - val_accuracy: 0.7130\n",
      "Epoch 12/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 1.0758 - accuracy: 0.6032 - val_loss: 0.7934 - val_accuracy: 0.7260\n",
      "Epoch 13/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 1.0453 - accuracy: 0.6143 - val_loss: 0.7695 - val_accuracy: 0.7280\n",
      "Epoch 14/150\n",
      "57500/57500 [==============================] - 5s 83us/step - loss: 1.0142 - accuracy: 0.6261 - val_loss: 0.7406 - val_accuracy: 0.7400\n",
      "Epoch 15/150\n",
      "57500/57500 [==============================] - 5s 84us/step - loss: 0.9901 - accuracy: 0.6366 - val_loss: 0.7218 - val_accuracy: 0.7470\n",
      "Epoch 16/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.9685 - accuracy: 0.6426 - val_loss: 0.7058 - val_accuracy: 0.7490\n",
      "Epoch 17/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.9481 - accuracy: 0.6517 - val_loss: 0.6929 - val_accuracy: 0.7500\n",
      "Epoch 18/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.9358 - accuracy: 0.6551 - val_loss: 0.6810 - val_accuracy: 0.7570\n",
      "Epoch 19/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.9193 - accuracy: 0.6615 - val_loss: 0.6700 - val_accuracy: 0.7560\n",
      "Epoch 20/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.9006 - accuracy: 0.6687 - val_loss: 0.6572 - val_accuracy: 0.7610\n",
      "Epoch 21/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.8953 - accuracy: 0.6725 - val_loss: 0.6506 - val_accuracy: 0.7580\n",
      "Epoch 22/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.8796 - accuracy: 0.6760 - val_loss: 0.6413 - val_accuracy: 0.7620\n",
      "Epoch 23/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.8755 - accuracy: 0.6789 - val_loss: 0.6365 - val_accuracy: 0.7610\n",
      "Epoch 24/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.8585 - accuracy: 0.6838 - val_loss: 0.6312 - val_accuracy: 0.7590\n",
      "Epoch 25/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.8491 - accuracy: 0.6879 - val_loss: 0.6286 - val_accuracy: 0.7580\n",
      "Epoch 26/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 0.8452 - accuracy: 0.6895 - val_loss: 0.6191 - val_accuracy: 0.7620\n",
      "Epoch 27/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.8353 - accuracy: 0.6966 - val_loss: 0.6158 - val_accuracy: 0.7660\n",
      "Epoch 28/150\n",
      "57500/57500 [==============================] - 5s 78us/step - loss: 0.8292 - accuracy: 0.6957 - val_loss: 0.6112 - val_accuracy: 0.7630\n",
      "Epoch 29/150\n",
      "57500/57500 [==============================] - 5s 78us/step - loss: 0.8231 - accuracy: 0.6979 - val_loss: 0.6069 - val_accuracy: 0.7640\n",
      "Epoch 30/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.8140 - accuracy: 0.7025 - val_loss: 0.6019 - val_accuracy: 0.7620\n",
      "Epoch 31/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.8118 - accuracy: 0.7021 - val_loss: 0.6011 - val_accuracy: 0.7630\n",
      "Epoch 32/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.8039 - accuracy: 0.7041 - val_loss: 0.5961 - val_accuracy: 0.7620\n",
      "Epoch 33/150\n",
      "57500/57500 [==============================] - 5s 78us/step - loss: 0.7992 - accuracy: 0.7064 - val_loss: 0.5959 - val_accuracy: 0.7610\n",
      "Epoch 34/150\n",
      "57500/57500 [==============================] - 5s 78us/step - loss: 0.7978 - accuracy: 0.7076 - val_loss: 0.5950 - val_accuracy: 0.7620\n",
      "Epoch 35/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 0.7933 - accuracy: 0.7066 - val_loss: 0.5908 - val_accuracy: 0.7650\n",
      "Epoch 36/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.7850 - accuracy: 0.7091 - val_loss: 0.5909 - val_accuracy: 0.7600\n",
      "Epoch 37/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.7840 - accuracy: 0.7123 - val_loss: 0.5869 - val_accuracy: 0.7630\n",
      "Epoch 38/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.7771 - accuracy: 0.7139 - val_loss: 0.5879 - val_accuracy: 0.7620\n",
      "Epoch 39/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.7738 - accuracy: 0.7143 - val_loss: 0.5844 - val_accuracy: 0.7640\n",
      "Epoch 40/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.7712 - accuracy: 0.7175 - val_loss: 0.5835 - val_accuracy: 0.7660\n",
      "Epoch 41/150\n",
      "57500/57500 [==============================] - 5s 82us/step - loss: 0.7636 - accuracy: 0.7173 - val_loss: 0.5815 - val_accuracy: 0.7640\n",
      "Epoch 42/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 0.7625 - accuracy: 0.7185 - val_loss: 0.5825 - val_accuracy: 0.7660\n",
      "Epoch 43/150\n",
      "57500/57500 [==============================] - 5s 78us/step - loss: 0.7561 - accuracy: 0.7198 - val_loss: 0.5759 - val_accuracy: 0.7700\n",
      "Epoch 44/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.7539 - accuracy: 0.7210 - val_loss: 0.5766 - val_accuracy: 0.7660\n",
      "Epoch 45/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.7517 - accuracy: 0.7241 - val_loss: 0.5781 - val_accuracy: 0.7650\n",
      "Epoch 46/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.7526 - accuracy: 0.7217 - val_loss: 0.5753 - val_accuracy: 0.7660\n",
      "Epoch 47/150\n",
      "57500/57500 [==============================] - 5s 78us/step - loss: 0.7467 - accuracy: 0.7217 - val_loss: 0.5740 - val_accuracy: 0.7670\n",
      "Epoch 48/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 0.7453 - accuracy: 0.7225 - val_loss: 0.5750 - val_accuracy: 0.7640\n",
      "Epoch 49/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.7430 - accuracy: 0.7254 - val_loss: 0.5731 - val_accuracy: 0.7740\n",
      "Epoch 50/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.7395 - accuracy: 0.7285 - val_loss: 0.5715 - val_accuracy: 0.7700\n",
      "Epoch 51/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.7378 - accuracy: 0.7257 - val_loss: 0.5696 - val_accuracy: 0.7720\n",
      "Epoch 52/150\n",
      "57500/57500 [==============================] - 5s 82us/step - loss: 0.7295 - accuracy: 0.7271 - val_loss: 0.5694 - val_accuracy: 0.7700\n",
      "Epoch 53/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.7353 - accuracy: 0.7277 - val_loss: 0.5669 - val_accuracy: 0.7750\n",
      "Epoch 54/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.7310 - accuracy: 0.7300 - val_loss: 0.5672 - val_accuracy: 0.7690\n",
      "Epoch 55/150\n",
      "57500/57500 [==============================] - 5s 83us/step - loss: 0.7221 - accuracy: 0.7299 - val_loss: 0.5667 - val_accuracy: 0.7700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.7249 - accuracy: 0.7305 - val_loss: 0.5667 - val_accuracy: 0.7670\n",
      "Epoch 57/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.7210 - accuracy: 0.7286 - val_loss: 0.5649 - val_accuracy: 0.7730\n",
      "Epoch 58/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.7213 - accuracy: 0.7323 - val_loss: 0.5652 - val_accuracy: 0.7740\n",
      "Epoch 59/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.7146 - accuracy: 0.7357 - val_loss: 0.5610 - val_accuracy: 0.7740\n",
      "Epoch 60/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.7221 - accuracy: 0.7332 - val_loss: 0.5660 - val_accuracy: 0.7640\n",
      "Epoch 61/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.7161 - accuracy: 0.7338 - val_loss: 0.5645 - val_accuracy: 0.7710\n",
      "Epoch 62/150\n",
      "57500/57500 [==============================] - 5s 82us/step - loss: 0.7092 - accuracy: 0.7351 - val_loss: 0.5616 - val_accuracy: 0.7710\n",
      "Epoch 63/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 0.7124 - accuracy: 0.7354 - val_loss: 0.5610 - val_accuracy: 0.7750\n",
      "Epoch 64/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.7032 - accuracy: 0.7398 - val_loss: 0.5612 - val_accuracy: 0.7800\n",
      "Epoch 65/150\n",
      "57500/57500 [==============================] - 5s 82us/step - loss: 0.7072 - accuracy: 0.7351 - val_loss: 0.5632 - val_accuracy: 0.7750\n",
      "Epoch 66/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.6985 - accuracy: 0.7369 - val_loss: 0.5609 - val_accuracy: 0.7740\n",
      "Epoch 67/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.7053 - accuracy: 0.7369 - val_loss: 0.5596 - val_accuracy: 0.7790\n",
      "Epoch 68/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.7083 - accuracy: 0.7377 - val_loss: 0.5569 - val_accuracy: 0.7820\n",
      "Epoch 69/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.7039 - accuracy: 0.7359 - val_loss: 0.5591 - val_accuracy: 0.7750\n",
      "Epoch 70/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.7015 - accuracy: 0.7408 - val_loss: 0.5593 - val_accuracy: 0.7780\n",
      "Epoch 71/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 0.6983 - accuracy: 0.7395 - val_loss: 0.5565 - val_accuracy: 0.7820\n",
      "Epoch 72/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6945 - accuracy: 0.7404 - val_loss: 0.5540 - val_accuracy: 0.7830\n",
      "Epoch 73/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6961 - accuracy: 0.7431 - val_loss: 0.5577 - val_accuracy: 0.7710\n",
      "Epoch 74/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6963 - accuracy: 0.7394 - val_loss: 0.5577 - val_accuracy: 0.7800\n",
      "Epoch 75/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.6914 - accuracy: 0.7411 - val_loss: 0.5540 - val_accuracy: 0.7830\n",
      "Epoch 76/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6892 - accuracy: 0.7436 - val_loss: 0.5551 - val_accuracy: 0.7850\n",
      "Epoch 77/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.6885 - accuracy: 0.7425 - val_loss: 0.5565 - val_accuracy: 0.7790\n",
      "Epoch 78/150\n",
      "57500/57500 [==============================] - 5s 83us/step - loss: 0.6886 - accuracy: 0.7450 - val_loss: 0.5569 - val_accuracy: 0.7800\n",
      "Epoch 79/150\n",
      "57500/57500 [==============================] - 5s 91us/step - loss: 0.6828 - accuracy: 0.7445 - val_loss: 0.5548 - val_accuracy: 0.7740\n",
      "Epoch 80/150\n",
      "57500/57500 [==============================] - 5s 85us/step - loss: 0.6832 - accuracy: 0.7448 - val_loss: 0.5539 - val_accuracy: 0.7830\n",
      "Epoch 81/150\n",
      "57500/57500 [==============================] - 5s 90us/step - loss: 0.6850 - accuracy: 0.7420 - val_loss: 0.5509 - val_accuracy: 0.7830\n",
      "Epoch 82/150\n",
      "57500/57500 [==============================] - 5s 89us/step - loss: 0.6853 - accuracy: 0.7457 - val_loss: 0.5533 - val_accuracy: 0.7810\n",
      "Epoch 83/150\n",
      "57500/57500 [==============================] - 5s 86us/step - loss: 0.6882 - accuracy: 0.7422 - val_loss: 0.5508 - val_accuracy: 0.7860\n",
      "Epoch 84/150\n",
      "57500/57500 [==============================] - 5s 87us/step - loss: 0.6815 - accuracy: 0.7457 - val_loss: 0.5507 - val_accuracy: 0.7890\n",
      "Epoch 85/150\n",
      "57500/57500 [==============================] - 5s 87us/step - loss: 0.6804 - accuracy: 0.7461 - val_loss: 0.5516 - val_accuracy: 0.7710\n",
      "Epoch 86/150\n",
      "57500/57500 [==============================] - 5s 85us/step - loss: 0.6782 - accuracy: 0.7468 - val_loss: 0.5516 - val_accuracy: 0.7880\n",
      "Epoch 87/150\n",
      "57500/57500 [==============================] - 5s 89us/step - loss: 0.6763 - accuracy: 0.7474 - val_loss: 0.5498 - val_accuracy: 0.7840\n",
      "Epoch 88/150\n",
      "57500/57500 [==============================] - 6s 99us/step - loss: 0.6826 - accuracy: 0.7472 - val_loss: 0.5496 - val_accuracy: 0.7940\n",
      "Epoch 89/150\n",
      "57500/57500 [==============================] - 6s 102us/step - loss: 0.6736 - accuracy: 0.7488 - val_loss: 0.5498 - val_accuracy: 0.7890\n",
      "Epoch 90/150\n",
      "57500/57500 [==============================] - 5s 86us/step - loss: 0.6763 - accuracy: 0.7497 - val_loss: 0.5493 - val_accuracy: 0.7790\n",
      "Epoch 91/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6734 - accuracy: 0.7506 - val_loss: 0.5481 - val_accuracy: 0.7850\n",
      "Epoch 92/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.6699 - accuracy: 0.7512 - val_loss: 0.5488 - val_accuracy: 0.7760- loss: 0.6695 - accura\n",
      "Epoch 93/150\n",
      "57500/57500 [==============================] - 5s 84us/step - loss: 0.6677 - accuracy: 0.7523 - val_loss: 0.5461 - val_accuracy: 0.7940\n",
      "Epoch 94/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6713 - accuracy: 0.7493 - val_loss: 0.5485 - val_accuracy: 0.7910\n",
      "Epoch 95/150\n",
      "57500/57500 [==============================] - 5s 78us/step - loss: 0.6665 - accuracy: 0.7523 - val_loss: 0.5502 - val_accuracy: 0.7980\n",
      "Epoch 96/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6634 - accuracy: 0.7541 - val_loss: 0.5457 - val_accuracy: 0.7880\n",
      "Epoch 97/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.6705 - accuracy: 0.7517 - val_loss: 0.5448 - val_accuracy: 0.8000\n",
      "Epoch 98/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6645 - accuracy: 0.7556 - val_loss: 0.5473 - val_accuracy: 0.7980\n",
      "Epoch 99/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.6650 - accuracy: 0.7526 - val_loss: 0.5449 - val_accuracy: 0.7880\n",
      "Epoch 100/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.6634 - accuracy: 0.7534 - val_loss: 0.5481 - val_accuracy: 0.7930\n",
      "Epoch 101/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.6646 - accuracy: 0.7551 - val_loss: 0.5436 - val_accuracy: 0.7990\n",
      "Epoch 102/150\n",
      "57500/57500 [==============================] - 4s 76us/step - loss: 0.6599 - accuracy: 0.7566 - val_loss: 0.5419 - val_accuracy: 0.7980\n",
      "Epoch 103/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.6665 - accuracy: 0.7532 - val_loss: 0.5453 - val_accuracy: 0.7950\n",
      "Epoch 104/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6607 - accuracy: 0.7567 - val_loss: 0.5427 - val_accuracy: 0.8040\n",
      "Epoch 105/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.6582 - accuracy: 0.7565 - val_loss: 0.5423 - val_accuracy: 0.7980\n",
      "Epoch 106/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.6550 - accuracy: 0.7560 - val_loss: 0.5419 - val_accuracy: 0.8060\n",
      "Epoch 107/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6551 - accuracy: 0.7563 - val_loss: 0.5411 - val_accuracy: 0.8020\n",
      "Epoch 108/150\n",
      "57500/57500 [==============================] - 5s 78us/step - loss: 0.6527 - accuracy: 0.7573 - val_loss: 0.5440 - val_accuracy: 0.7930\n",
      "Epoch 109/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.6527 - accuracy: 0.7564 - val_loss: 0.5376 - val_accuracy: 0.7980\n",
      "Epoch 110/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.6557 - accuracy: 0.7588 - val_loss: 0.5386 - val_accuracy: 0.8030\n",
      "Epoch 111/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.6593 - accuracy: 0.7595 - val_loss: 0.5406 - val_accuracy: 0.7990\n",
      "Epoch 112/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.6578 - accuracy: 0.7551 - val_loss: 0.5412 - val_accuracy: 0.8010\n",
      "Epoch 113/150\n",
      "57500/57500 [==============================] - 5s 83us/step - loss: 0.6545 - accuracy: 0.7573 - val_loss: 0.5422 - val_accuracy: 0.7960\n",
      "Epoch 114/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.6535 - accuracy: 0.7574 - val_loss: 0.5407 - val_accuracy: 0.8020\n",
      "Epoch 115/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.6458 - accuracy: 0.7598 - val_loss: 0.5377 - val_accuracy: 0.8040s - loss: 0.6462 - accuracy: 0.\n",
      "Epoch 116/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 0.6476 - accuracy: 0.7608 - val_loss: 0.5386 - val_accuracy: 0.8040\n",
      "Epoch 117/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.6472 - accuracy: 0.7602 - val_loss: 0.5398 - val_accuracy: 0.8090\n",
      "Epoch 118/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 0.6505 - accuracy: 0.7615 - val_loss: 0.5406 - val_accuracy: 0.8020\n",
      "Epoch 119/150\n",
      "57500/57500 [==============================] - 5s 82us/step - loss: 0.6466 - accuracy: 0.7611 - val_loss: 0.5371 - val_accuracy: 0.8070\n",
      "Epoch 120/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.6472 - accuracy: 0.7621 - val_loss: 0.5357 - val_accuracy: 0.8020\n",
      "Epoch 121/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.6466 - accuracy: 0.7615 - val_loss: 0.5377 - val_accuracy: 0.8040\n",
      "Epoch 122/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6444 - accuracy: 0.7618 - val_loss: 0.5356 - val_accuracy: 0.8150\n",
      "Epoch 123/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.6442 - accuracy: 0.7625 - val_loss: 0.5381 - val_accuracy: 0.8120\n",
      "Epoch 124/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.6385 - accuracy: 0.7646 - val_loss: 0.5354 - val_accuracy: 0.8060\n",
      "Epoch 125/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6445 - accuracy: 0.7652 - val_loss: 0.5382 - val_accuracy: 0.8070\n",
      "Epoch 126/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.6395 - accuracy: 0.7630 - val_loss: 0.5352 - val_accuracy: 0.8020\n",
      "Epoch 127/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6433 - accuracy: 0.7639 - val_loss: 0.5365 - val_accuracy: 0.8050\n",
      "Epoch 128/150\n",
      "57500/57500 [==============================] - 5s 82us/step - loss: 0.6400 - accuracy: 0.7650 - val_loss: 0.5330 - val_accuracy: 0.8130\n",
      "Epoch 129/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.6396 - accuracy: 0.7653 - val_loss: 0.5369 - val_accuracy: 0.8040\n",
      "Epoch 130/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.6392 - accuracy: 0.7634 - val_loss: 0.5340 - val_accuracy: 0.8140\n",
      "Epoch 131/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 0.6399 - accuracy: 0.7660 - val_loss: 0.5314 - val_accuracy: 0.8100\n",
      "Epoch 132/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.6397 - accuracy: 0.7647 - val_loss: 0.5376 - val_accuracy: 0.8130\n",
      "Epoch 133/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 0.6316 - accuracy: 0.7665 - val_loss: 0.5362 - val_accuracy: 0.8060\n",
      "Epoch 134/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.6349 - accuracy: 0.7675 - val_loss: 0.5322 - val_accuracy: 0.8110\n",
      "Epoch 135/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6289 - accuracy: 0.7671 - val_loss: 0.5313 - val_accuracy: 0.8030\n",
      "Epoch 136/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6365 - accuracy: 0.7658 - val_loss: 0.5356 - val_accuracy: 0.8090\n",
      "Epoch 137/150\n",
      "57500/57500 [==============================] - 5s 84us/step - loss: 0.6302 - accuracy: 0.7669 - val_loss: 0.5331 - val_accuracy: 0.8080\n",
      "Epoch 138/150\n",
      "57500/57500 [==============================] - 5s 85us/step - loss: 0.6326 - accuracy: 0.7687 - val_loss: 0.5336 - val_accuracy: 0.8100\n",
      "Epoch 139/150\n",
      "57500/57500 [==============================] - 5s 86us/step - loss: 0.6318 - accuracy: 0.7685 - val_loss: 0.5315 - val_accuracy: 0.8160\n",
      "Epoch 140/150\n",
      "57500/57500 [==============================] - 5s 82us/step - loss: 0.6299 - accuracy: 0.7714 - val_loss: 0.5310 - val_accuracy: 0.8120\n",
      "Epoch 141/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6325 - accuracy: 0.7681 - val_loss: 0.5295 - val_accuracy: 0.8110\n",
      "Epoch 142/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6261 - accuracy: 0.7709 - val_loss: 0.5324 - val_accuracy: 0.8110\n",
      "Epoch 143/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6256 - accuracy: 0.7713 - val_loss: 0.5286 - val_accuracy: 0.8130\n",
      "Epoch 144/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6310 - accuracy: 0.7680 - val_loss: 0.5305 - val_accuracy: 0.8070\n",
      "Epoch 145/150\n",
      "57500/57500 [==============================] - 5s 84us/step - loss: 0.6266 - accuracy: 0.7714 - val_loss: 0.5308 - val_accuracy: 0.8080\n",
      "Epoch 146/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.6253 - accuracy: 0.7707 - val_loss: 0.5281 - val_accuracy: 0.8050\n",
      "Epoch 147/150\n",
      "57500/57500 [==============================] - 5s 82us/step - loss: 0.6219 - accuracy: 0.7723 - val_loss: 0.5321 - val_accuracy: 0.8090\n",
      "Epoch 148/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.6294 - accuracy: 0.7689 - val_loss: 0.5332 - val_accuracy: 0.8090\n",
      "Epoch 149/150\n",
      "57500/57500 [==============================] - 5s 79us/step - loss: 0.6218 - accuracy: 0.7712 - val_loss: 0.5310 - val_accuracy: 0.8060\n",
      "Epoch 150/150\n",
      "57500/57500 [==============================] - 5s 80us/step - loss: 0.6248 - accuracy: 0.7707 - val_loss: 0.5296 - val_accuracy: 0.8070\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take about a minute to run\n",
    "random.seed(123)\n",
    "dropout_model = models.Sequential()\n",
    "\n",
    "# Implement dropout to the input layer\n",
    "# NOTE: This is where you define the number of units in the input layer\n",
    "\n",
    "dropout_model.add(layers.Dropout(0.3, input_shape=(2000,)))\n",
    "\n",
    "# Add the first hidden layer\n",
    "\n",
    "dropout_model.add(layers.Dense(50, activation='relu'))\n",
    "# Implement dropout to the first hidden layer \n",
    "dropout_model.add(layers.Dropout(.3))\n",
    "# Add the second hidden layer\n",
    "\n",
    "dropout_model.add(layers.Dense(25, activation='relu'))\n",
    "# Implement dropout to the second hidden layer \n",
    "dropout_model.add(layers.Dropout(.3))\n",
    "\n",
    "# Add the output layer\n",
    "dropout_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "dropout_model.compile(optimizer='SGD', \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "dropout_model_val = dropout_model.fit(X_train_tokens, \n",
    "                                      y_train_lb, \n",
    "                                      epochs=150, \n",
    "                                      batch_size=256, \n",
    "                                      validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 3s 50us/step\n",
      "Training Loss: 0.406 \n",
      "Training Accuracy: 0.859\n",
      "----------\n",
      "1500/1500 [==============================] - 0s 65us/step\n",
      "Test Loss: 0.506 \n",
      "Test Accuracy: 0.799\n"
     ]
    }
   ],
   "source": [
    "results_train = dropout_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = dropout_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again, and the training and test accuracy are very close!  \n",
    "\n",
    "## Bigger Data? \n",
    "\n",
    "Finally, let's examine if we can improve the model's performance just by adding more data. We've quadrapled the sample dataset from 10,000 to 40,000 observations, and all you need to do is run the code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigger_sample = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df['Consumer complaint narrative']\n",
    "y = df['Product']\n",
    "\n",
    "# Train-test split\n",
    "X_train_bigger, X_test_bigger, y_train_bigger, y_test_bigger = train_test_split(X, \n",
    "                                                                                y, \n",
    "                                                                                test_size=6000, \n",
    "                                                                                random_state=42)\n",
    "\n",
    "# Validation set\n",
    "X_train_final_bigger, X_val_bigger, y_train_final_bigger, y_val_bigger = train_test_split(X_train_bigger, \n",
    "                                                                                          y_train_bigger, \n",
    "                                                                                          test_size=4000, \n",
    "                                                                                          random_state=42)\n",
    "\n",
    "\n",
    "# One-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_bigger)\n",
    "\n",
    "X_train_tokens_bigger = tokenizer.texts_to_matrix(X_train_final_bigger, mode='binary')\n",
    "X_val_tokens_bigger = tokenizer.texts_to_matrix(X_val_bigger, mode='binary')\n",
    "X_test_tokens_bigger = tokenizer.texts_to_matrix(X_test_bigger, mode='binary')\n",
    "\n",
    "# One-hot encoding of products\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final_bigger)\n",
    "\n",
    "y_train_lb_bigger = to_categorical(lb.transform(y_train_final_bigger))[:, :, 1]\n",
    "y_val_lb_bigger = to_categorical(lb.transform(y_val_bigger))[:, :, 1]\n",
    "y_test_lb_bigger = to_categorical(lb.transform(y_test_bigger))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 4000 samples\n",
      "Epoch 1/150\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.8710 - accuracy: 0.2510 - val_loss: 1.7648 - val_accuracy: 0.3565\n",
      "Epoch 2/150\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.6071 - accuracy: 0.4486 - val_loss: 1.4440 - val_accuracy: 0.5293\n",
      "Epoch 3/150\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.2770 - accuracy: 0.5956 - val_loss: 1.1423 - val_accuracy: 0.6420\n",
      "Epoch 4/150\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.0270 - accuracy: 0.6681 - val_loss: 0.9514 - val_accuracy: 0.6870\n",
      "Epoch 5/150\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.8769 - accuracy: 0.7019 - val_loss: 0.8427 - val_accuracy: 0.7105\n",
      "Epoch 6/150\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.7864 - accuracy: 0.7238 - val_loss: 0.7777 - val_accuracy: 0.7262\n",
      "Epoch 7/150\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.7276 - accuracy: 0.7406 - val_loss: 0.7309 - val_accuracy: 0.7405\n",
      "Epoch 8/150\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.6857 - accuracy: 0.7517 - val_loss: 0.6997 - val_accuracy: 0.7490\n",
      "Epoch 9/150\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.6544 - accuracy: 0.7615 - val_loss: 0.6754 - val_accuracy: 0.7550\n",
      "Epoch 10/150\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.6296 - accuracy: 0.7715 - val_loss: 0.6593 - val_accuracy: 0.7648\n",
      "Epoch 11/150\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.6095 - accuracy: 0.7769 - val_loss: 0.6423 - val_accuracy: 0.7673\n",
      "Epoch 12/150\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.5927 - accuracy: 0.7843 - val_loss: 0.6305 - val_accuracy: 0.7695\n",
      "Epoch 13/150\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.5783 - accuracy: 0.7890 - val_loss: 0.6228 - val_accuracy: 0.7747\n",
      "Epoch 14/150\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.5658 - accuracy: 0.7945 - val_loss: 0.6093 - val_accuracy: 0.7768\n",
      "Epoch 15/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.5545 - accuracy: 0.7992 - val_loss: 0.6021 - val_accuracy: 0.7800\n",
      "Epoch 16/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.5448 - accuracy: 0.8031 - val_loss: 0.5958 - val_accuracy: 0.7837\n",
      "Epoch 17/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.5358 - accuracy: 0.8059 - val_loss: 0.5906 - val_accuracy: 0.7855\n",
      "Epoch 18/150\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.5274 - accuracy: 0.8098 - val_loss: 0.5864 - val_accuracy: 0.7860\n",
      "Epoch 19/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.5196 - accuracy: 0.8127 - val_loss: 0.5804 - val_accuracy: 0.7912\n",
      "Epoch 20/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.5127 - accuracy: 0.8156 - val_loss: 0.5843 - val_accuracy: 0.7908\n",
      "Epoch 21/150\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.5061 - accuracy: 0.8176 - val_loss: 0.5753 - val_accuracy: 0.7903\n",
      "Epoch 22/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.5000 - accuracy: 0.8205 - val_loss: 0.5747 - val_accuracy: 0.7905\n",
      "Epoch 23/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.4942 - accuracy: 0.8220 - val_loss: 0.5695 - val_accuracy: 0.7955\n",
      "Epoch 24/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.4885 - accuracy: 0.8254 - val_loss: 0.5646 - val_accuracy: 0.7940\n",
      "Epoch 25/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.4834 - accuracy: 0.8270 - val_loss: 0.5609 - val_accuracy: 0.7968\n",
      "Epoch 26/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.4785 - accuracy: 0.8294 - val_loss: 0.5576 - val_accuracy: 0.7965\n",
      "Epoch 27/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.4742 - accuracy: 0.8310 - val_loss: 0.5566 - val_accuracy: 0.7997\n",
      "Epoch 28/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.4697 - accuracy: 0.8324 - val_loss: 0.5545 - val_accuracy: 0.7972\n",
      "Epoch 29/150\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.4654 - accuracy: 0.8344 - val_loss: 0.5551 - val_accuracy: 0.8023\n",
      "Epoch 30/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.4615 - accuracy: 0.8360 - val_loss: 0.5514 - val_accuracy: 0.7980 \n",
      "Epoch 31/150\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.4579 - accuracy: 0.8372 - val_loss: 0.5507 - val_accuracy: 0.8030\n",
      "Epoch 32/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.4540 - accuracy: 0.8385 - val_loss: 0.5503 - val_accuracy: 0.8015\n",
      "Epoch 33/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.4507 - accuracy: 0.8396 - val_loss: 0.5508 - val_accuracy: 0.8030\n",
      "Epoch 34/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.4474 - accuracy: 0.8409 - val_loss: 0.5468 - val_accuracy: 0.8050\n",
      "Epoch 35/150\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.4443 - accuracy: 0.8422 - val_loss: 0.5472 - val_accuracy: 0.8060\n",
      "Epoch 36/150\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.4406 - accuracy: 0.8444 - val_loss: 0.5456 - val_accuracy: 0.8048\n",
      "Epoch 37/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.4378 - accuracy: 0.8449 - val_loss: 0.5442 - val_accuracy: 0.8023\n",
      "Epoch 38/150\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.4348 - accuracy: 0.8466 - val_loss: 0.5449 - val_accuracy: 0.8073\n",
      "Epoch 39/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.4322 - accuracy: 0.8472 - val_loss: 0.5452 - val_accuracy: 0.8035\n",
      "Epoch 40/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.4293 - accuracy: 0.8487 - val_loss: 0.5423 - val_accuracy: 0.8080\n",
      "Epoch 41/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.4265 - accuracy: 0.8486 - val_loss: 0.5415 - val_accuracy: 0.8048\n",
      "Epoch 42/150\n",
      "50000/50000 [==============================] - 3s 61us/step - loss: 0.4243 - accuracy: 0.8502 - val_loss: 0.5430 - val_accuracy: 0.8087\n",
      "Epoch 43/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.4217 - accuracy: 0.8505 - val_loss: 0.5449 - val_accuracy: 0.8085\n",
      "Epoch 44/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.4194 - accuracy: 0.8519 - val_loss: 0.5388 - val_accuracy: 0.8083\n",
      "Epoch 45/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.4172 - accuracy: 0.8528 - val_loss: 0.5392 - val_accuracy: 0.8080\n",
      "Epoch 46/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.4149 - accuracy: 0.8538 - val_loss: 0.5422 - val_accuracy: 0.8075\n",
      "Epoch 47/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.4125 - accuracy: 0.8551 - val_loss: 0.5409 - val_accuracy: 0.8080\n",
      "Epoch 48/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.4102 - accuracy: 0.8552 - val_loss: 0.5405 - val_accuracy: 0.8083\n",
      "Epoch 49/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.4083 - accuracy: 0.8562 - val_loss: 0.5418 - val_accuracy: 0.8080\n",
      "Epoch 50/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.4062 - accuracy: 0.8575 - val_loss: 0.5400 - val_accuracy: 0.8080\n",
      "Epoch 51/150\n",
      "50000/50000 [==============================] - 3s 61us/step - loss: 0.4044 - accuracy: 0.8578 - val_loss: 0.5378 - val_accuracy: 0.8092\n",
      "Epoch 52/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.4023 - accuracy: 0.8582 - val_loss: 0.5409 - val_accuracy: 0.8115\n",
      "Epoch 53/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.4006 - accuracy: 0.8589 - val_loss: 0.5387 - val_accuracy: 0.8100\n",
      "Epoch 54/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.3983 - accuracy: 0.8602 - val_loss: 0.5397 - val_accuracy: 0.8110\n",
      "Epoch 55/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3964 - accuracy: 0.8608 - val_loss: 0.5397 - val_accuracy: 0.8120\n",
      "Epoch 56/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3949 - accuracy: 0.8615 - val_loss: 0.5464 - val_accuracy: 0.8050\n",
      "Epoch 57/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3934 - accuracy: 0.8614 - val_loss: 0.5442 - val_accuracy: 0.8098\n",
      "Epoch 58/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3912 - accuracy: 0.8623 - val_loss: 0.5455 - val_accuracy: 0.8060\n",
      "Epoch 59/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3899 - accuracy: 0.8634 - val_loss: 0.5410 - val_accuracy: 0.8110\n",
      "Epoch 60/150\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.3881 - accuracy: 0.8642 - val_loss: 0.5469 - val_accuracy: 0.8052\n",
      "Epoch 61/150\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.3865 - accuracy: 0.8641 - val_loss: 0.5564 - val_accuracy: 0.8050\n",
      "Epoch 62/150\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.3848 - accuracy: 0.8647 - val_loss: 0.5453 - val_accuracy: 0.8115\n",
      "Epoch 63/150\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.3833 - accuracy: 0.8652 - val_loss: 0.5401 - val_accuracy: 0.8133\n",
      "Epoch 64/150\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.3818 - accuracy: 0.8657 - val_loss: 0.5419 - val_accuracy: 0.8115\n",
      "Epoch 65/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3805 - accuracy: 0.8659 - val_loss: 0.5414 - val_accuracy: 0.8160\n",
      "Epoch 66/150\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.3792 - accuracy: 0.8666 - val_loss: 0.5427 - val_accuracy: 0.8130\n",
      "Epoch 67/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3774 - accuracy: 0.8681 - val_loss: 0.5425 - val_accuracy: 0.8145\n",
      "Epoch 68/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3764 - accuracy: 0.8682 - val_loss: 0.5425 - val_accuracy: 0.8130\n",
      "Epoch 69/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3744 - accuracy: 0.8685 - val_loss: 0.5424 - val_accuracy: 0.8138\n",
      "Epoch 70/150\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.3734 - accuracy: 0.8681 - val_loss: 0.5488 - val_accuracy: 0.8080\n",
      "Epoch 71/150\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.3720 - accuracy: 0.8697 - val_loss: 0.5443 - val_accuracy: 0.8127\n",
      "Epoch 72/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3708 - accuracy: 0.8707 - val_loss: 0.5461 - val_accuracy: 0.8075\n",
      "Epoch 73/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.3694 - accuracy: 0.8702 - val_loss: 0.5438 - val_accuracy: 0.8080\n",
      "Epoch 74/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3683 - accuracy: 0.8705 - val_loss: 0.5452 - val_accuracy: 0.8130\n",
      "Epoch 75/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3667 - accuracy: 0.8716 - val_loss: 0.5454 - val_accuracy: 0.8110\n",
      "Epoch 76/150\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.3658 - accuracy: 0.8719 - val_loss: 0.5485 - val_accuracy: 0.8080\n",
      "Epoch 77/150\n",
      "50000/50000 [==============================] - 3s 61us/step - loss: 0.3644 - accuracy: 0.8725 - val_loss: 0.5460 - val_accuracy: 0.8150\n",
      "Epoch 78/150\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.3630 - accuracy: 0.8729 - val_loss: 0.5475 - val_accuracy: 0.8120\n",
      "Epoch 79/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3618 - accuracy: 0.8733 - val_loss: 0.5464 - val_accuracy: 0.8135ura\n",
      "Epoch 80/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.3606 - accuracy: 0.8745 - val_loss: 0.5465 - val_accuracy: 0.8133\n",
      "Epoch 81/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3596 - accuracy: 0.8733 - val_loss: 0.5512 - val_accuracy: 0.8110\n",
      "Epoch 82/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.3586 - accuracy: 0.8737 - val_loss: 0.5507 - val_accuracy: 0.8075\n",
      "Epoch 83/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.3572 - accuracy: 0.8744 - val_loss: 0.5490 - val_accuracy: 0.8120\n",
      "Epoch 84/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3563 - accuracy: 0.8748 - val_loss: 0.5569 - val_accuracy: 0.8073\n",
      "Epoch 85/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3551 - accuracy: 0.8753 - val_loss: 0.5522 - val_accuracy: 0.8112\n",
      "Epoch 86/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3539 - accuracy: 0.8763 - val_loss: 0.5511 - val_accuracy: 0.8115\n",
      "Epoch 87/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3529 - accuracy: 0.8762 - val_loss: 0.5654 - val_accuracy: 0.8077\n",
      "Epoch 88/150\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.3520 - accuracy: 0.8764 - val_loss: 0.5585 - val_accuracy: 0.8083\n",
      "Epoch 89/150\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.3507 - accuracy: 0.8770 - val_loss: 0.5557 - val_accuracy: 0.8120\n",
      "Epoch 90/150\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.3496 - accuracy: 0.8773 - val_loss: 0.5534 - val_accuracy: 0.8075\n",
      "Epoch 91/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3489 - accuracy: 0.8778 - val_loss: 0.5544 - val_accuracy: 0.8130\n",
      "Epoch 92/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3477 - accuracy: 0.8785 - val_loss: 0.5570 - val_accuracy: 0.8100\n",
      "Epoch 93/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.3467 - accuracy: 0.8787 - val_loss: 0.5589 - val_accuracy: 0.8105\n",
      "Epoch 94/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.3455 - accuracy: 0.8783 - val_loss: 0.5541 - val_accuracy: 0.8100\n",
      "Epoch 95/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3446 - accuracy: 0.8792 - val_loss: 0.5571 - val_accuracy: 0.8060\n",
      "Epoch 96/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3436 - accuracy: 0.8789 - val_loss: 0.5557 - val_accuracy: 0.8117\n",
      "Epoch 97/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3426 - accuracy: 0.8800 - val_loss: 0.5596 - val_accuracy: 0.8087\n",
      "Epoch 98/150\n",
      "50000/50000 [==============================] - 3s 61us/step - loss: 0.3416 - accuracy: 0.8809 - val_loss: 0.5605 - val_accuracy: 0.8110\n",
      "Epoch 99/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.3411 - accuracy: 0.8805 - val_loss: 0.5588 - val_accuracy: 0.8108\n",
      "Epoch 100/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.3400 - accuracy: 0.8806 - val_loss: 0.5574 - val_accuracy: 0.8092\n",
      "Epoch 101/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3388 - accuracy: 0.8815 - val_loss: 0.5609 - val_accuracy: 0.8125\n",
      "Epoch 102/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3380 - accuracy: 0.8813 - val_loss: 0.5624 - val_accuracy: 0.8092\n",
      "Epoch 103/150\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.3371 - accuracy: 0.8815 - val_loss: 0.5629 - val_accuracy: 0.8070\n",
      "Epoch 104/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3362 - accuracy: 0.8817 - val_loss: 0.5609 - val_accuracy: 0.8112\n",
      "Epoch 105/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.3353 - accuracy: 0.8824 - val_loss: 0.5709 - val_accuracy: 0.8058\n",
      "Epoch 106/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.3344 - accuracy: 0.8826 - val_loss: 0.5648 - val_accuracy: 0.8098\n",
      "Epoch 107/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3337 - accuracy: 0.8831 - val_loss: 0.5647 - val_accuracy: 0.8120\n",
      "Epoch 108/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3327 - accuracy: 0.8837 - val_loss: 0.5640 - val_accuracy: 0.8070\n",
      "Epoch 109/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3316 - accuracy: 0.8845 - val_loss: 0.5650 - val_accuracy: 0.8087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3309 - accuracy: 0.8836 - val_loss: 0.5647 - val_accuracy: 0.8080\n",
      "Epoch 111/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3297 - accuracy: 0.8840 - val_loss: 0.5672 - val_accuracy: 0.8075\n",
      "Epoch 112/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3288 - accuracy: 0.8854 - val_loss: 0.5661 - val_accuracy: 0.8065\n",
      "Epoch 113/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3278 - accuracy: 0.8846 - val_loss: 0.5713 - val_accuracy: 0.8073\n",
      "Epoch 114/150\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.3273 - accuracy: 0.8847 - val_loss: 0.5675 - val_accuracy: 0.8077\n",
      "Epoch 115/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3263 - accuracy: 0.8860 - val_loss: 0.5730 - val_accuracy: 0.8087\n",
      "Epoch 116/150\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.3253 - accuracy: 0.8863 - val_loss: 0.5700 - val_accuracy: 0.8085\n",
      "Epoch 117/150\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.3246 - accuracy: 0.8866 - val_loss: 0.5856 - val_accuracy: 0.7993\n",
      "Epoch 118/150\n",
      "50000/50000 [==============================] - 3s 61us/step - loss: 0.3236 - accuracy: 0.8866 - val_loss: 0.5739 - val_accuracy: 0.8090\n",
      "Epoch 119/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3227 - accuracy: 0.8873 - val_loss: 0.5747 - val_accuracy: 0.8008\n",
      "Epoch 120/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3220 - accuracy: 0.8871 - val_loss: 0.5786 - val_accuracy: 0.8052\n",
      "Epoch 121/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3208 - accuracy: 0.8878 - val_loss: 0.5720 - val_accuracy: 0.8098\n",
      "Epoch 122/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3200 - accuracy: 0.8884 - val_loss: 0.5753 - val_accuracy: 0.8055\n",
      "Epoch 123/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.3194 - accuracy: 0.8876 - val_loss: 0.5758 - val_accuracy: 0.8050\n",
      "Epoch 124/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.3186 - accuracy: 0.8885 - val_loss: 0.5804 - val_accuracy: 0.8075\n",
      "Epoch 125/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.3175 - accuracy: 0.8889 - val_loss: 0.5778 - val_accuracy: 0.8062\n",
      "Epoch 126/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.3166 - accuracy: 0.8889 - val_loss: 0.5800 - val_accuracy: 0.8087\n",
      "Epoch 127/150\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.3163 - accuracy: 0.8880 - val_loss: 0.5792 - val_accuracy: 0.8045\n",
      "Epoch 128/150\n",
      "50000/50000 [==============================] - 3s 61us/step - loss: 0.3151 - accuracy: 0.8891 - val_loss: 0.5800 - val_accuracy: 0.8075\n",
      "Epoch 129/150\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.3145 - accuracy: 0.8895 - val_loss: 0.5833 - val_accuracy: 0.8070\n",
      "Epoch 130/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3131 - accuracy: 0.8911 - val_loss: 0.5836 - val_accuracy: 0.8067\n",
      "Epoch 131/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3126 - accuracy: 0.8907 - val_loss: 0.5876 - val_accuracy: 0.8043\n",
      "Epoch 132/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3116 - accuracy: 0.8910 - val_loss: 0.5894 - val_accuracy: 0.8067\n",
      "Epoch 133/150\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.3113 - accuracy: 0.8914 - val_loss: 0.5840 - val_accuracy: 0.8050\n",
      "Epoch 134/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3099 - accuracy: 0.8916 - val_loss: 0.5881 - val_accuracy: 0.8052\n",
      "Epoch 135/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3092 - accuracy: 0.8922 - val_loss: 0.5834 - val_accuracy: 0.8030\n",
      "Epoch 136/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3080 - accuracy: 0.8927 - val_loss: 0.5871 - val_accuracy: 0.8067\n",
      "Epoch 137/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.3075 - accuracy: 0.8925 - val_loss: 0.5891 - val_accuracy: 0.8065\n",
      "Epoch 138/150\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.3068 - accuracy: 0.8929 - val_loss: 0.5889 - val_accuracy: 0.8065\n",
      "Epoch 139/150\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.3055 - accuracy: 0.8938 - val_loss: 0.5881 - val_accuracy: 0.8058\n",
      "Epoch 140/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3049 - accuracy: 0.8934 - val_loss: 0.5881 - val_accuracy: 0.8073\n",
      "Epoch 141/150\n",
      "50000/50000 [==============================] - 3s 61us/step - loss: 0.3038 - accuracy: 0.8939 - val_loss: 0.5888 - val_accuracy: 0.8045\n",
      "Epoch 142/150\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.3031 - accuracy: 0.8945 - val_loss: 0.5941 - val_accuracy: 0.8033\n",
      "Epoch 143/150\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.3023 - accuracy: 0.8939 - val_loss: 0.5933 - val_accuracy: 0.8030\n",
      "Epoch 144/150\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.3014 - accuracy: 0.8952 - val_loss: 0.6011 - val_accuracy: 0.8012\n",
      "Epoch 145/150\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.3007 - accuracy: 0.8949 - val_loss: 0.5960 - val_accuracy: 0.8060\n",
      "Epoch 146/150\n",
      "50000/50000 [==============================] - 3s 62us/step - loss: 0.2994 - accuracy: 0.8955 - val_loss: 0.5988 - val_accuracy: 0.7975\n",
      "Epoch 147/150\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.2991 - accuracy: 0.8958 - val_loss: 0.5949 - val_accuracy: 0.8075\n",
      "Epoch 148/150\n",
      "50000/50000 [==============================] - 3s 61us/step - loss: 0.2981 - accuracy: 0.8954 - val_loss: 0.6002 - val_accuracy: 0.8048\n",
      "Epoch 149/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.2972 - accuracy: 0.8962 - val_loss: 0.5957 - val_accuracy: 0.8065\n",
      "Epoch 150/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.2966 - accuracy: 0.8965 - val_loss: 0.6020 - val_accuracy: 0.8020\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "bigger_data_model = models.Sequential()\n",
    "bigger_data_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "bigger_data_model.add(layers.Dense(25, activation='relu'))\n",
    "bigger_data_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "bigger_data_model.compile(optimizer='SGD', \n",
    "                          loss='categorical_crossentropy', \n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "bigger_data_model_val = bigger_data_model.fit(X_train_tokens_bigger,  \n",
    "                                              y_train_lb_bigger,  \n",
    "                                              epochs=150,  \n",
    "                                              batch_size=256,  \n",
    "                                              validation_data=(X_val_tokens_bigger, y_val_lb_bigger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 53us/step\n",
      "Training Loss: 0.293 \n",
      "Training Accuracy: 0.899\n",
      "----------\n",
      "4000/4000 [==============================] - 0s 42us/step\n",
      "Test Loss: 0.602 \n",
      "Test Accuracy: 0.802\n"
     ]
    }
   ],
   "source": [
    "results_train = bigger_data_model.evaluate(X_train_tokens_bigger, y_train_lb_bigger)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = bigger_data_model.evaluate(X_val_tokens_bigger, y_val_lb_bigger)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs and no regularization technique, you were able to get both better test accuracy and loss. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance! \n",
    "\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database \n",
    "\n",
    "\n",
    "## Summary  \n",
    "\n",
    "In this lesson, you built deep learning models using a validation set and used several techniques such as L2 and L1 regularization, dropout regularization, and early stopping to improve the accuracy of your models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
